

        *** GPGPU-Sim Simulator Version 3.2.1  [build 15629] ***


               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim: Configuration options:

-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   20 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  4:128:24,L:R:m:N,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 64:64:2,L:R:f:N,A:2:32,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     4:128:4,L:R:f:N,A:2:32,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     32:128:4,L:L:m:N,A:32:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                32768 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_shader_cta                       8 # Maximum number of concurrent CTAs in shader (default 8)
-gpgpu_n_clusters                      14 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_size                   16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   16 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_operand_collector_num_units_sp                    6 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_sfu                    8 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (default = 13, anything else is off for now)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths        2,1,1,2,1,1,2 # Pipeline widths ID_OC_SP,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_SFU,OC_EX_MEM,EX_WB
-gpgpu_num_sp_units                     2 # Number of SP units (default=1)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      lrr # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     64:128:16,L:B:m:W,A:32:4,4 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            5 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_mem_per_ctrlr                    2 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   16 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                    0 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=4:CCDL=3:RTPL=2 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-rop_latency                          100 # ROP queue latency (default 85)
-dram_latency                          83 # DRAM latency (default 30)
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.BBBBCCCC.CCSSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpuwattch_xml_file         gpuwattch.xml # GPUWattch XML file
-power_simulation_enabled                    1 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-power_trace_enabled                    1 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 500.0:1000.0:500.0:900.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                    8 # maximum kernels that can run concurrently on GPU
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,19,25,145
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_initiation_int            1,2,2,1,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,4,4,32
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default3b82a684c102d6ef208a92e82788225e  /tmp/tmp.bUL3hNGAm1/bicg__SIZE1_1
 1,1,1,1,5
-ptx_opcode_initiation_dp         8,16,8,8,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    3 # column to column delay between accesses to different bank groups
RTPL                                    2 # read to precharge delay between accesses to different bank groups
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 000000000000f000 	high:16 low:12
addr_dec_mask[ROW]   = 000000000fff0000 	high:28 low:16
addr_dec_mask[COL]   = 0000000000000fff 	high:12 low:0
addr_dec_mask[BURST] = 000000000000003f 	high:6 low:0
*** Initializing Memory Statistics ***
self exe links to: /tmp/tmp.bUL3hNGAm1/bicg__SIZE1_1
Running md5sum using "md5sum /tmp/tmp.bUL3hNGAm1/bicg__SIZE1_1 "
Running cuobjdump using "$CUDA_INSTALL_PATH/bin/cuobjdump -ptx -elf -sass /tmp/tmp.bUL3hNGAm1/bicg__SIZE1_1 > _cuobjdump_complete_output_r7dWWi"
Parsing file _cuobjdump_complete_output_r7dWWi
######### cuobjdump parser ########
## Adding new section PTX
Adding ptx filename: _cuobjdump_1.ptx
Adding arch: sm_13
Adding identifier: benchmarks/bicg/bicg.cu
## Adding new section ELF
Adding arch: sm_13
Adding identifier: benchmarks/bicg/bicg.cu
Done parsing!!!
Adding _cuobjdump_1.ptx with cubin handle 1
Running: cat _ptx_kPhT5l | sed 's/.version 1.5/.version 1.4/' | sed 's/, texmode_independent//' | sed 's/\(\.extern \.const\[1\] .b8 \w\+\)\[\]/\1\[1\]/' | sed 's/const\[.\]/const\[0\]/g' > _ptx2_bx9Qep

kernel '_Z12bicg_kernel1PfS_S_' transfer to GPU hardware scheduler
kernel_name = _Z12bicg_kernel1PfS_S_ 
kernel_launch_uid = 1 
gpu_sim_cycle = 249827
gpu_sim_insn = 8407040
gpu_ipc =      33.6514
gpu_tot_sim_cycle = 249827
gpu_tot_sim_insn = 8407040
gpu_tot_ipc =      33.6514
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 0
gpu_stall_icnt2sh    = 24
gpu_total_sim_rate=247265
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 65536, Miss = 32800 (0.5), PendingHit = 224 (0.00342)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
total_dl1_misses=32800
total_dl1_accesses=65536
total_dl1_miss_rate= 0.500488
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:

distro:

gpgpu_n_tot_thrd_icount = 8409088
gpgpu_n_tot_w_icount = 262784
gpgpu_n_icache_hits = 164128
gpgpu_n_icache_misses = 64
gpgpu_n_l1dcache_read_hits = 32512
gpgpu_n_l1dcache_read_misses = 33024
gpgpu_n_l1dcache_write_accesses = 32
gpgpu_n_l1dcache_wirte_misses = 32
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 64
gpgpu_n_ccache_misses = 32
gpgpu_n_stall_shd_mem = 3735
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 32800
gpgpu_n_mem_write_global = 32
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 1
gpgpu_n_load_insn  = 4194304
gpgpu_n_store_insn = 2048
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 6144
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 132
gpgpu_stall_shd_mem[c_mem][bk_conf] = 132
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 3603
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:9039	W0_Idle:1518	W0_Scoreboard:226339	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:262784
maxmrqlatency = 65 
maxdqlatency = 0 
maxmflatency = 260 
averagemflatency = 203 
max_icnt2mem_latency = 5 
max_icnt2sh_latency = 249826 
mrq_lat_table:31064 	712 	408 	650 	27 	5 	1 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	32832 	1 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:2 	32801 	32 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	28320 	4166 	256 	57 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	32 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	498 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[1]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[2]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[3]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[4]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
maximum service time to same row:
dram[0]:     19448     19447     19467     19483     19484     19477     19471     19454     19467     19469     19468     19474     19476     19468     19480     19483 
dram[1]:     19508     19465     19460     19465     19480     19490     19443     19463     19475     19465     19435     19469     19500     19506     19482     19494 
dram[2]:     19492     19457     19459     19461     19467     19473     19477     19472     19472     19473     19468     19480     19480     19450     19494     19500 
dram[3]:     19492     19443     19441     19446     19473     19473     19483     19452     19462     19478     19450     19470     19492     19483     19489     19500 
dram[4]:     19482     19515     19510     19505     19509     19504     19487     19500     19498     19512     19512     19544     19552     19507     19510     19497 
average row accesses per activate:
dram[0]: 32.230770 32.000000 32.000000 32.000000 32.000000 32.000000 18.909090 32.000000 32.000000 30.461538 32.000000 32.000000 32.000000 32.000000 32.000000 32.000000 
dram[1]: 32.000000 32.000000 32.000000 32.000000 32.000000 32.000000 26.000000 32.000000 32.000000 30.461538 32.000000 32.000000 32.000000 32.000000 32.000000 32.000000 
dram[2]: 32.000000 32.000000 32.000000 32.000000 32.000000 32.000000 26.000000 32.000000 32.000000 30.461538 32.000000 32.000000 32.000000 32.000000 32.000000 32.000000 
dram[3]: 32.000000 32.000000 32.000000 32.000000 32.000000 32.000000 19.000000 32.000000 32.000000 30.615385 32.000000 32.000000 32.000000 32.000000 32.000000 32.000000 
dram[4]: 32.000000 32.000000 32.000000 32.000000 32.000000 32.000000 21.789474 32.000000 32.000000 30.615385 32.000000 32.000000 32.000000 32.000000 32.000000 32.000000 
average row locality = 32867/1060 = 31.006603
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       419       416       416       416       416       416       410       384       384       396       416       416       416       416       416       416 
dram[1]:       416       416       416       416       416       416       410       384       384       396       416       416       416       416       416       416 
dram[2]:       416       416       416       416       416       416       410       384       384       396       416       416       416       416       416       416 
dram[3]:       416       416       416       416       416       416       410       384       384       398       416       416       416       416       416       416 
dram[4]:       416       416       416       416       416       416       408       384       384       398       416       416       416       416       416       416 
total reads: 32835
bank skew: 419/384 = 1.09
chip skew: 6569/6566 = 1.00
number of total write accesses:
dram[0]:         0         0         0         0         0         0         6         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         6         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         6         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         8         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         6         0         0         0         0         0         0         0         0         0 
total reads: 32
min_bank_accesses = 0!
chip skew: 8/6 = 1.33
average mf latency per bank:
dram[0]:        203       202       202       203       202       202       200       202       202       203       202       202       203       202       202       202
dram[1]:        203       203       203       203       203       203       200       203       203       203       203       202       203       203       203       203
dram[2]:        203       202       203       203       202       202       200       203       203       203       203       203       203       203       202       203
dram[3]:        203       202       202       203       202       203       199       203       203       204       203       202       203       203       202       203
dram[4]:        203       202       202       203       202       202       200       202       202       203       202       202       203       202       202       202
maximum mf latency per bank:
dram[0]:        240       218       219       218       219       217       231       219       216       224       220       221       218       219       220       220
dram[1]:        224       223       218       221       222       222       221       221       219       226       222       220       221       219       222       219
dram[2]:        217       219       219       219       220       217       231       220       221       232       222       219       219       220       224       219
dram[3]:        224       222       218       223       219       220       228       222       222       234       223       219       221       219       219       223
dram[4]:        238       218       216       219       220       216       260       221       220       223       217       219       223       220       218       219

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents
MSHR: tag=0x80401780, atomic=0 1 entries : 0x2ae2947f7ba0 :  mf: uid=233623, sid01:w15, part=0, addr=0x80401780, load , size=128, unknown  status = IN_PARTITION_DRAM (249826), 

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=449687 n_nop=436123 n_act=216 n_pre=200 n_req=6575 n_rd=13136 n_write=12 bw_util=0.05848
n_activity=92400 dram_eff=0.2846
bk0: 838a 447867i bk1: 832a 447995i bk2: 832a 447987i bk3: 832a 448011i bk4: 832a 448004i bk5: 832a 447956i bk6: 818a 447961i bk7: 768a 447946i bk8: 768a 448000i bk9: 792a 448011i bk10: 832a 447821i bk11: 832a 448156i bk12: 832a 447886i bk13: 832a 447798i bk14: 832a 447592i bk15: 832a 443082i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=4 avg=0.00844365
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=449687 n_nop=436141 n_act=209 n_pre=193 n_req=6572 n_rd=13132 n_write=12 bw_util=0.05846
n_activity=91473 dram_eff=0.2874
bk0: 832a 447919i bk1: 832a 448010i bk2: 832a 447885i bk3: 832a 448088i bk4: 832a 447996i bk5: 832a 447966i bk6: 820a 447935i bk7: 768a 447638i bk8: 768a 448126i bk9: 792a 448000i bk10: 832a 448173i bk11: 832a 447839i bk12: 832a 447951i bk13: 832a 447746i bk14: 832a 447523i bk15: 832a 443313i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=3 avg=0.0105496
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=449687 n_nop=436141 n_act=209 n_pre=193 n_req=6572 n_rd=13132 n_write=12 bw_util=0.05846
n_activity=91358 dram_eff=0.2877
bk0: 832a 447949i bk1: 832a 448019i bk2: 832a 448002i bk3: 832a 448015i bk4: 832a 447972i bk5: 832a 448000i bk6: 820a 447947i bk7: 768a 447875i bk8: 768a 447766i bk9: 792a 447779i bk10: 832a 447834i bk11: 832a 448177i bk12: 832a 448200i bk13: 832a 447706i bk14: 832a 447448i bk15: 832a 443343i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=2 avg=0.00846811
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=449687 n_nop=436121 n_act=215 n_pre=199 n_req=6576 n_rd=13136 n_write=16 bw_util=0.05849
n_activity=91559 dram_eff=0.2873
bk0: 832a 447931i bk1: 832a 447968i bk2: 832a 447868i bk3: 832a 447930i bk4: 832a 448128i bk5: 832a 448025i bk6: 820a 448000i bk7: 768a 448009i bk8: 768a 447931i bk9: 796a 447723i bk10: 832a 447741i bk11: 832a 447911i bk12: 832a 448198i bk13: 832a 447791i bk14: 832a 447473i bk15: 832a 443143i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=3 avg=0.00935984
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=449687 n_nop=436135 n_act=212 n_pre=196 n_req=6572 n_rd=13132 n_write=12 bw_util=0.05846
n_activity=93282 dram_eff=0.2818
bk0: 832a 447912i bk1: 832a 448017i bk2: 832a 447995i bk3: 832a 447971i bk4: 832a 447988i bk5: 832a 447800i bk6: 816a 448120i bk7: 768a 448001i bk8: 768a 447977i bk9: 796a 447966i bk10: 832a 447725i bk11: 832a 447817i bk12: 832a 448258i bk13: 832a 447875i bk14: 832a 447677i bk15: 832a 443204i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=9 avg=0.00832579
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 6569, Miss = 6569 (1), PendingHit = 0 (0)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 6566, Miss = 6566 (1), PendingHit = 0 (0)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 6566, Miss = 6566 (1), PendingHit = 0 (0)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 6568, Miss = 6568 (1), PendingHit = 0 (0)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 6566, Miss = 6566 (1), PendingHit = 0 (0)
L2 Cache Total Miss Rate = 1.000

icnt_total_pkts_mem_to_simt=164045
icnt_total_pkts_simt_to_mem=32963

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 1.00429
% Accepted packets = 0 at node 0 (avg = 0.00286834)
lat(1) = 1.00429;
thru(1,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.0131952 0.0131892 0.0131892 0.0132092 0.0131892 0 0 0 0 ];
% latency change    = 1
% throughput change = 1
Traffic 1 Stat
%=================================
% Average latency = 5.68732
% Accepted packets = 0 at node 0 (avg = 0.0142747)
lat(2) = 5.68732;
thru(2,:) = [ 0 0.328319 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
% latency change    = 0.823415
% throughput change = 0.799061
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 1.00429 (1 samples)
Traffic[0]class0Overall average accepted rate = 0.00286834 (1 samples)
Traffic[0]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 32800 1 0 2 30 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (32835 samples)
traffic_manager/hop_stats_freq = [ 0 32835 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 5.68732 (1 samples)
Traffic[1]class0Overall average accepted rate = 0.0142747 (1 samples)
Traffic[1]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 30 0 1 2 26113 2208 555 2507 433 303 131 74 92 71 35 23 27 27 17 20 14 9 19 9 5 13 12 5 10 11 4 8 10 6 3 3 3 1 1 2 2 0 3 2 2 3 2 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (32835 samples)
traffic_manager/hop_stats_freq = [ 0 32835 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 34 sec (34 sec)
gpgpu_simulation_rate = 247265 (inst/sec)
gpgpu_simulation_rate = 7347 (cycle/sec)
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread

kernel '_Z12bicg_kernel2PfS_S_' transfer to GPU hardware scheduler
kernel_name = _Z12bicg_kernel2PfS_S_ 
kernel_launch_uid = 2 
gpu_sim_cycle = 56667913
gpu_sim_insn = 8410112
gpu_ipc =       0.1484
gpu_tot_sim_cycle = 56917740
gpu_tot_sim_insn = 16817152
gpu_tot_ipc =       0.2955
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 0
gpu_stall_icnt2sh    = 24
gpu_total_sim_rate=4374
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 65536, Miss = 32800 (0.5), PendingHit = 224 (0.00342)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 1081344, Miss = 1054953 (0.976), PendingHit = 26131 (0.0242)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 0, Miss = 0 (-nan), PendingHit = 0 (-nan)
total_dl1_misses=1087753
total_dl1_accesses=1146880
total_dl1_miss_rate= 0.948445
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:

distro:

gpgpu_n_tot_thrd_icount = 16821248
gpgpu_n_tot_w_icount = 525664
gpgpu_n_icache_hits = 328288
gpgpu_n_icache_misses = 130
gpgpu_n_l1dcache_read_hits = 32772
gpgpu_n_l1dcache_read_misses = 1114108
gpgpu_n_l1dcache_write_accesses = 64
gpgpu_n_l1dcache_wirte_misses = 64
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 128
gpgpu_n_ccache_misses = 64
gpgpu_n_stall_shd_mem = 56602032
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 1087753
gpgpu_n_mem_write_global = 64
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 2
gpgpu_n_load_insn  = 8388608
gpgpu_n_store_insn = 4096
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 12288
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 272
gpgpu_stall_shd_mem[c_mem][bk_conf] = 272
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 56601760
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:84756862	W0_Idle:28326589	W0_Scoreboard:226417	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:525664
maxmrqlatency = 65 
maxdqlatency = 0 
maxmflatency = 260 
averagemflatency = 214 
max_icnt2mem_latency = 8 
max_icnt2sh_latency = 56917739 
mrq_lat_table:1084653 	721 	409 	670 	29 	5 	1 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	1400 	1086418 	1 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:5 	1087753 	64 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	1081814 	5531 	351 	57 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	32 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:16 	16 	0 	0 	0 	0 	0 	113833 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[1]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[2]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[3]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[4]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
maximum service time to same row:
dram[0]:     19448     19447     19467     19483     19484     19477     19471     19454     19467     19469     19468     19474     19476     19468     19480     19483 
dram[1]:     19508     19465     19460     19465     19480     19490     19443     19463     19475     19465     19435     19469     19500     19506     19482     19494 
dram[2]:     19492     19457     19459     19461     19467     19473     19477     19472     19472     19473     19468     19480     19480     19450     19494     19500 
dram[3]:     19492     19443     19441     19446     19473     19473     19483     19452     19462     19478     19450     19470     19492     19483     19489     19500 
dram[4]:     19482     19515     19510     19505     19509     19504     19487     19500     19498     19512     19512     19544     19552     19507     19510     19497 
average row accesses per activate:
dram[0]:  1.030542  1.030244  1.030244  1.030244  1.030244  1.030244  1.028753  1.031209  1.030244  1.030193  1.030244  1.030244  1.030244  1.030244  1.030244  1.030244 
dram[1]:  1.030239  1.030244  1.030244  1.030244  1.030244  1.030244  1.029204  1.030884  1.030244  1.030193  1.030244  1.030244  1.030244  1.030244  1.030244  1.030244 
dram[2]:  1.030244  1.030244  1.030244  1.030244  1.030244  1.030244  1.029341  1.030884  1.030244  1.030193  1.030244  1.030244  1.030244  1.030244  1.030244  1.030244 
dram[3]:  1.030244  1.030244  1.030244  1.030244  1.030244  1.030244  1.029034  1.030884  1.030244  1.030198  1.030244  1.030244  1.030244  1.030244  1.030244  1.030244 
dram[4]:  1.030244  1.030244  1.030244  1.030244  1.030244  1.030244  1.028590  1.030884  1.030244  1.030198  1.030244  1.030244  1.030244  1.030244  1.030244  1.030244 
average row locality = 1086488/1054634 = 1.030204
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:     13733     13728     13728     13728     13728     13728     14091     12680     12672     13068     13728     13728     13728     13728     13728     13728 
dram[1]:     13730     13728     13728     13728     13728     13728     14091     12678     12672     13068     13728     13728     13728     13728     13728     13728 
dram[2]:     13728     13728     13728     13728     13728     13728     14027     12678     12672     13068     13728     13728     13728     13728     13728     13728 
dram[3]:     13728     13728     13728     13728     13728     13728     14027     12678     12672     13134     13728     13728     13728     13728     13728     13728 
dram[4]:     13728     13728     13728     13728     13728     13728     14277     12678     12672     13134     13728     13728     13728     13728     13728     13728 
total reads: 1086424
bank skew: 14277/12672 = 1.13
chip skew: 217497/217181 = 1.00
number of total write accesses:
dram[0]:         0         0         0         0         0         0         6         8         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         6         6         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         6         6         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         8         6         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         6         6         0         0         0         0         0         0         0         0 
total reads: 64
min_bank_accesses = 0!
chip skew: 14/12 = 1.17
average mf latency per bank:
dram[0]:        214       214       214       214       214       214       216       214       214       214       214       214       214       214       214       214
dram[1]:        214       214       214       214       214       214       216       214       214       214       214       214       214       214       214       214
dram[2]:        214       214       214       214       214       214       216       214       214       214       214       214       214       214       214       214
dram[3]:        214       214       214       214       214       214       216       214       214       214       214       214       214       214       214       214
dram[4]:        214       214       214       214       214       214       217       214       214       214       214       214       214       214       214       214
maximum mf latency per bank:
dram[0]:        240       218       223       223       219       219       231       219       216       224       220       221       218       219       220       220
dram[1]:        224       223       223       221       222       222       223       221       219       226       222       220       221       219       222       219
dram[2]:        217       219       223       219       220       219       231       220       221       232       222       219       222       220       224       219
dram[3]:        224       222       223       223       219       220       228       222       222       234       223       219       221       219       219       223
dram[4]:        238       218       223       219       220       220       260       221       220       223       217       219       223       220       218       219

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents
MSHR: tag=0x80403f80, atomic=0 1 entries : 0x2ae294c00810 :  mf: uid=57061842, sid02:w31, part=0, addr=0x80403f80, load , size=128, unknown  status = IN_PARTITION_DRAM (56917739), 

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=102451929 n_nop=101595627 n_act=210894 n_pre=210878 n_req=217266 n_rd=434502 n_write=28 bw_util=0.008483
n_activity=10949541 dram_eff=0.07937
bk0: 27466a 102426058i bk1: 27456a 102443938i bk2: 27456a 102439624i bk3: 27456a 102448537i bk4: 27456a 102449462i bk5: 27456a 102449706i bk6: 28182a 102448208i bk7: 25358a 102449910i bk8: 25344a 102448055i bk9: 26136a 102449094i bk10: 27456a 102449909i bk11: 27456a 102449888i bk12: 27456a 102434088i bk13: 27456a 102272858i bk14: 27456a 102449427i bk15: 27456a 96577833i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=4 avg=3.82521e-05
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=102451929 n_nop=101595651 n_act=210888 n_pre=210872 n_req=217259 n_rd=434494 n_write=24 bw_util=0.008482
n_activity=10948684 dram_eff=0.07937
bk0: 27460a 102426096i bk1: 27456a 102443936i bk2: 27456a 102439539i bk3: 27456a 102448619i bk4: 27456a 102449453i bk5: 27456a 102449721i bk6: 28182a 102448211i bk7: 25356a 102449588i bk8: 25344a 102448201i bk9: 26136a 102449111i bk10: 27456a 102450261i bk11: 27456a 102449578i bk12: 27456a 102434173i bk13: 27456a 102272810i bk14: 27456a 102449331i bk15: 27456a 96578045i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=3 avg=4.72612e-05
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=102451929 n_nop=101595915 n_act=210822 n_pre=210806 n_req=217193 n_rd=434362 n_write=24 bw_util=0.00848
n_activity=10945289 dram_eff=0.07937
bk0: 27456a 102426143i bk1: 27456a 102443961i bk2: 27456a 102439661i bk3: 27456a 102448476i bk4: 27456a 102449480i bk5: 27456a 102449766i bk6: 28054a 102448222i bk7: 25356a 102449825i bk8: 25344a 102447842i bk9: 26136a 102448888i bk10: 27456a 102449938i bk11: 27456a 102449907i bk12: 27456a 102434409i bk13: 27456a 102272834i bk14: 27456a 102449297i bk15: 27456a 96579859i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=2 avg=3.82911e-05
Cache L2_bank_003:
MSHR contents
MSHR: tag=0x80403d80, atomic=0 1 entries : 0x2ae294bf0a50 :  mf: uid=57061840, sid02:w27, part=3, addr=0x80403d80, load , size=128, unknown  status = IN_PARTITION_DRAM (56917737), 

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=102451929 n_nop=101595639 n_act=210892 n_pre=210876 n_req=217261 n_rd=434494 n_write=28 bw_util=0.008482
n_activity=10949446 dram_eff=0.07937
bk0: 27456a 102426105i bk1: 27456a 102443926i bk2: 27456a 102439545i bk3: 27456a 102448447i bk4: 27456a 102449573i bk5: 27456a 102449791i bk6: 28054a 102448277i bk7: 25356a 102449958i bk8: 25344a 102448007i bk9: 26268a 102448834i bk10: 27456a 102449822i bk11: 27456a 102449654i bk12: 27456a 102434463i bk13: 27456a 102272856i bk14: 27456a 102449308i bk15: 27456a 96577852i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=3 avg=4.20099e-05
Cache L2_bank_004:
MSHR contents
MSHR: tag=0x80403e80, atomic=0 1 entries : 0x2ae294bde720 :  mf: uid=57061841, sid02:w29, part=4, addr=0x80403e80, load , size=128, unknown  status = IN_PARTITION_DRAM (56917739), 

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=102451929 n_nop=101594649 n_act=211139 n_pre=211123 n_req=217509 n_rd=434994 n_write=24 bw_util=0.008492
n_activity=10960138 dram_eff=0.07938
bk0: 27456a 102426219i bk1: 27456a 102443934i bk2: 27456a 102439632i bk3: 27456a 102448401i bk4: 27456a 102449471i bk5: 27456a 102449488i bk6: 28554a 102447863i bk7: 25356a 102449881i bk8: 25344a 102447513i bk9: 26268a 102449038i bk10: 27456a 102449809i bk11: 27456a 102449399i bk12: 27456a 102434281i bk13: 27456a 102272888i bk14: 27456a 102449484i bk15: 27456a 96572382i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=9 avg=3.78519e-05
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 217516, Miss = 217252 (0.999), PendingHit = 0 (0)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 217511, Miss = 217247 (0.999), PendingHit = 0 (0)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 217445, Miss = 217181 (0.999), PendingHit = 0 (0)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 217511, Miss = 217247 (0.999), PendingHit = 0 (0)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 217841, Miss = 217497 (0.998), PendingHit = 0 (0)
L2 Cache Total Miss Rate = 0.999

icnt_total_pkts_mem_to_simt=5438860
icnt_total_pkts_simt_to_mem=1088080

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 1.0002
% Accepted packets = 0 at node 0 (avg = 0.000404767)
lat(3) = 1.0002;
thru(3,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.00186154 0.00186145 0.00186087 0.00186143 0.00186436 0 0 0 0 ];
% latency change    = 4.68616
% throughput change = 34.2665
Traffic 1 Stat
%=================================
% Average latency = 5.00623
% Accepted packets = 0 at node 0 (avg = 0.00202354)
lat(4) = 5.00623;
thru(4,:) = [ 0 0 0.0465415 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
% latency change    = 0.800208
% throughput change = 0.799971
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 1.00225 (2 samples)
Traffic[0]class0Overall average accepted rate = 0.00163656 (2 samples)
Traffic[0]class0Overall min accepted rate = 0 (2 samples)
traffic_manager/latency_stat_0_freq = [ 0 1054954 0 1 0 11 1 1 12 7 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (1087824 samples)
traffic_manager/hop_stats_freq = [ 0 1087824 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 5.34677 (2 samples)
Traffic[1]class0Overall average accepted rate = 0.00814913 (2 samples)
Traffic[1]class0Overall min accepted rate = 0 (2 samples)
traffic_manager/latency_stat_0_freq = [ 0 27 3 1 2 1052541 954 17 1250 1 1 3 46 46 2 1 0 31 48 15 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (1087824 samples)
traffic_manager/hop_stats_freq = [ 0 1087824 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 1 hrs, 4 min, 4 sec (3844 sec)
gpgpu_simulation_rate = 4374 (inst/sec)
gpgpu_simulation_rate = 14806 (cycle/sec)
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
GPU Runtime: 3842.927674s
