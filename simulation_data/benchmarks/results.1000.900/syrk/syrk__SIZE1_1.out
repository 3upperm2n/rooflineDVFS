

        *** GPGPU-Sim Simulator Version 3.2.1  [build 15629] ***


               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim: Configuration options:

-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   20 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  4:128:24,L:R:m:N,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 64:64:2,L:R:f:N,A:2:32,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     4:128:4,L:R:f:N,A:2:32,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     32:128:4,L:L:m:N,A:32:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                32768 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_shader_cta                       8 # Maximum number of concurrent CTAs in shader (default 8)
-gpgpu_n_clusters                      14 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_size                   16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   16 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_operand_collector_num_units_sp                    6 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_sfu                    8 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (default = 13, anything else is off for now)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths        2,1,1,2,1,1,2 # Pipeline widths ID_OC_SP,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_SFU,OC_EX_MEM,EX_WB
-gpgpu_num_sp_units                     2 # Number of SP units (default=1)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      lrr # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     64:128:16,L:B:m:W,A:32:4,4 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            5 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_mem_per_ctrlr                    2 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   16 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                    0 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=4:CCDL=3:RTPL=2 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-rop_latency                          100 # ROP queue latency (default 85)
-dram_latency                          83 # DRAM latency (default 30)
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.BBBBCCCC.CCSSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpuwattch_xml_file         gpuwattch.xml # GPUWattch XML file
-power_simulation_enabled                    1 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-power_trace_enabled                    1 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 500.0:1000.0:500.0:900.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                    8 # maximum kernels that can run concurrently on GPU
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,19,25,145
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_initiation_int            1,2,2,1,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,4,4,32
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default4b67ba5cea00eeb014054e30a0048b70  /tmp/tmp.97pZ4fVp5q/syrk__SIZE1_1
 1,1,1,1,5
-ptx_opcode_initiation_dp         8,16,8,8,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    3 # column to column delay between accesses to different bank groups
RTPL                                    2 # read to precharge delay between accesses to different bank groups
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 000000000000f000 	high:16 low:12
addr_dec_mask[ROW]   = 000000000fff0000 	high:28 low:16
addr_dec_mask[COL]   = 0000000000000fff 	high:12 low:0
addr_dec_mask[BURST] = 000000000000003f 	high:6 low:0
*** Initializing Memory Statistics ***
self exe links to: /tmp/tmp.97pZ4fVp5q/syrk__SIZE1_1
Running md5sum using "md5sum /tmp/tmp.97pZ4fVp5q/syrk__SIZE1_1 "
Running cuobjdump using "$CUDA_INSTALL_PATH/bin/cuobjdump -ptx -elf -sass /tmp/tmp.97pZ4fVp5q/syrk__SIZE1_1 > _cuobjdump_complete_output_nh0tvd"
Parsing file _cuobjdump_complete_output_nh0tvd
######### cuobjdump parser ########
## Adding new section PTX
Adding ptx filename: _cuobjdump_1.ptx
Adding arch: sm_13
Adding identifier: benchmarks/syrk/syrk.cu
## Adding new section ELF
Adding arch: sm_13
Adding identifier: benchmarks/syrk/syrk.cu
Done parsing!!!
Adding _cuobjdump_1.ptx with cubin handle 1
Running: cat _ptx_LjluCD | sed 's/.version 1.5/.version 1.4/' | sed 's/, texmode_independent//' | sed 's/\(\.extern \.const\[1\] .b8 \w\+\)\[\]/\1\[1\]/' | sed 's/const\[.\]/const\[0\]/g' > _ptx2_NMevJ3

kernel '_Z11syrk_kernelffPfS_' transfer to GPU hardware scheduler
kernel_name = _Z11syrk_kernelffPfS_ 
kernel_launch_uid = 1 
gpu_sim_cycle = 140868169
gpu_sim_insn = 1488453632
gpu_ipc =      10.5663
gpu_tot_sim_cycle = 140868169
gpu_tot_sim_insn = 1488453632
gpu_tot_ipc =      10.5663
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 3414330
gpu_stall_icnt2sh    = 51723121
gpu_total_sim_rate=22959
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10135109 (0.987), PendingHit = 129983 (0.0127)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9603014 (0.987), PendingHit = 121720 (0.0125)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9601774 (0.987), PendingHit = 123072 (0.0126)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9604039 (0.987), PendingHit = 120966 (0.0124)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10132668 (0.986), PendingHit = 131373 (0.0128)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9597567 (0.986), PendingHit = 126323 (0.013)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9605718 (0.987), PendingHit = 119330 (0.0123)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10134138 (0.986), PendingHit = 130460 (0.0127)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9604401 (0.987), PendingHit = 120576 (0.0124)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9604036 (0.987), PendingHit = 120855 (0.0124)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9601401 (0.987), PendingHit = 122859 (0.0126)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9602255 (0.987), PendingHit = 122461 (0.0126)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10133482 (0.986), PendingHit = 131573 (0.0128)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9604616 (0.987), PendingHit = 120134 (0.0123)
total_dl1_misses=136564218
total_dl1_accesses=138420224
total_dl1_miss_rate= 0.986592
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 
distro:
5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 
gpgpu_n_tot_thrd_icount = 1488977920
gpgpu_n_tot_w_icount = 46530560
gpgpu_n_icache_hits = 25362432
gpgpu_n_icache_misses = 1375
gpgpu_n_l1dcache_read_hits = 114321
gpgpu_n_l1dcache_read_misses = 138305903
gpgpu_n_l1dcache_write_accesses = 4202496
gpgpu_n_l1dcache_wirte_misses = 4194330
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 15936
gpgpu_n_ccache_misses = 448
gpgpu_n_stall_shd_mem = 1888492350
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 136564218
gpgpu_n_mem_write_global = 4202496
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 14
gpgpu_n_load_insn  = 537395200
gpgpu_n_store_insn = 268959744
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 1048576
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 0
gpgpu_stall_shd_mem[c_mem][bk_conf] = 0
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 1888492350
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:-1366746230	W0_Idle:830073025	W0_Scoreboard:1956571	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:46530560
maxmrqlatency = 79 
maxdqlatency = 0 
maxmflatency = 584 
averagemflatency = 111 
max_icnt2mem_latency = 346 
max_icnt2sh_latency = 140868168 
mrq_lat_table:1492754 	20309 	18181 	59449 	7089 	477 	15 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	137403905 	3203545 	159270 	8 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:28 	133321710 	6163308 	968122 	112345 	88966 	102373 	9907 	25 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	57933534 	56831361 	20508721 	1290607 	9 	0 	0 	0 	0 	207 	109 	20 	297 	452 	681 	1624 	2885 	7629 	16445 	33018 	66289 	127677 	261320 	
mf_lat_pw_table:521353 	1037111 	2060555 	64824 	0 	0 	272270 	9453 	11 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        28        42        28        20        20        24        14        42        29        59        15        54        29        49        41        20 
dram[1]:        28        36        28        24        20        26        14        47        28        54        14        54        35        50        58        21 
dram[2]:        29        38        28        22        20        26        29        45        28        49        14        52        36        45        61        20 
dram[3]:        28        50        28        22        21        27        12        52        28        49        20        52        40        51        63        21 
dram[4]:        33        41        28        24        18        26        14        44        28        53        22        56        36        52        59        20 
maximum service time to same row:
dram[0]:   3473739   3473812   3473235    652370   2064186   2064371    670255   3408477   3490246    677980   1687264   1436726    475113   2066260   3234727   2066329 
dram[1]:   3473610   3473432   3473232   1023415   2064572   2064586    653967   3408445   3418665    717452   1687259   1036900    473291   2066489   3234707   2066403 
dram[2]:   3473439   3473612   3473237   1027667   2064379   2064373    660228   3408365   3408277    692731   1436677   1191029    471140   2066264   3234705   2066310 
dram[3]:   3473793   3473622   3473237   1146010   2064373   2064370    740135   3408458   3408581    686299    929798   1687272    431983   2066301   3234724   2066330 
dram[4]:   3473440   3473544   3473239   1007366   2064374   2064162    694631   3408366   3418647    679335    976211   1794350    473853   2066223   3234705   2066309 
average row accesses per activate:
dram[0]:  1.991464  2.021200  1.924768  1.333932  2.049853  2.060568  1.302143  1.938350  1.993523  1.842680  1.767673  1.831032  1.827319  2.102003  2.031930  1.965886 
dram[1]:  2.010531  1.969211  1.927136  1.954639  2.076609  1.970886  1.294250  2.031974  2.003127  1.253988  1.773293  1.930969  1.848118  2.020198  2.035647  2.056767 
dram[2]:  1.933496  1.975183  1.977747  1.958547  1.972479  1.939433  1.821493  2.027720  1.921199  1.252283  1.861405  1.947535  1.287290  2.032726  2.138126  2.065139 
dram[3]:  1.996898  1.951659  1.922055  1.341231  2.059685  1.941183  1.313738  1.948315  1.996990  1.248646  1.768107  1.831711  1.841116  2.019042  2.038893  1.958805 
dram[4]:  1.933472  1.968119  1.926277  1.948765  1.945703  1.938771  1.315948  2.019917  1.932616  1.247674  1.781844  1.945426  1.267028  2.029834  2.028487  2.050134 
average row locality = 1598274/884369 = 1.807248
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:     18740     17408     18571     17202     18010     17121     18394     17885     18613     17932     24248     22601     23796     18040     18440     17336 
dram[1]:     18700     17504     18488     17421     18021     17533     18317     17897     18488     20660     24157     23025     23688     18361     18284     17591 
dram[2]:     18430     17483     18167     17404     17554     17487     18514     17811     18485     20630     23644     22860     21392     18306     18295     17593 
dram[3]:     18716     17756     18538     17589     18051     17502     18391     18174     18502     21105     24239     23434     23864     18587     18457     17789 
dram[4]:     18035     17528     17805     17404     17591     17505     18031     17783     18060     20750     23284     23040     20988     18419     17981     17648 
total reads: 1529073
bank skew: 24248/17121 = 1.42
chip skew: 310694/301852 = 1.03
number of total write accesses:
dram[0]:       623       611       694       626       781       740       685       791       776       797       807      1131       966      1372      1351       701 
dram[1]:       583       788       687       634       791       745       592       787       728       960       795      1311       916      1443      1246       706 
dram[2]:       584       823       675       550       794       701       690       769       800       903       813      1194      1133      1446      1395       700 
dram[3]:       598       654       696       582       791       716       649       787       741      1021       808      1404      1015      1559      1359       708 
dram[4]:       536       807       668       587       792       702       741       776       812       977       819      1307       981      1516      1245       713 
total reads: 69201
bank skew: 1559/536 = 2.91
chip skew: 14088/13452 = 1.05
average mf latency per bank:
dram[0]:       9528     10224      9593     10313      9760     10275      9672      9869      9526     11049      9706     10232      9449      9539      9364     10317
dram[1]:       9564     10068      9635     10169      9751     10053      9758      9866      9603      9573      9746      9990      9524      9354      9487     10190
dram[2]:       9696     10056      9800     10220      9995     10096      9619      9916      9567      9611      9940     10094     10375      9376      9414     10208
dram[3]:       9560     10020      9631     10134      9736     10091      9692      9730      9594      9523      9715      9790      9418      9200      9357     10082
dram[4]:       9919     10036      9988     10205      9979     10103      9831      9924      9772      9681     10079      9974     10456      9289      9635     10156
maximum mf latency per bank:
dram[0]:        439       460       431       480       416       459       448       504       466       462       453       461       456       477       474       470
dram[1]:        424       503       515       430       427       421       475       427       417       452       459       429       505       490       438       467
dram[2]:        445       436       470       454       431       466       426       421       462       483       443       485       486       429       519       473
dram[3]:        507       427       484       450       531       445       519       447       441       450       458       527       497       452       449       467
dram[4]:        453       517       459       584       479       485       435       466       496       445       469       516       430       452       497       458

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=253562703 n_nop=252581419 n_act=172861 n_pre=172845 n_req=317789 n_rd=608674 n_write=26904 bw_util=0.005013
n_activity=9451404 dram_eff=0.1345
bk0: 37480a 253498282i bk1: 34816a 253505727i bk2: 37142a 253505026i bk3: 34404a 253503361i bk4: 36020a 253508796i bk5: 34242a 253506594i bk6: 36788a 253503950i bk7: 35770a 253505185i bk8: 37226a 253505274i bk9: 35864a 253501265i bk10: 48496a 253501819i bk11: 45202a 253492432i bk12: 47592a 253472005i bk13: 36080a 253440182i bk14: 36880a 253086295i bk15: 34672a 249167804i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.00134769
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=253562703 n_nop=252568385 n_act=175320 n_pre=175304 n_req=321847 n_rd=616270 n_write=27424 bw_util=0.005077
n_activity=9489588 dram_eff=0.1357
bk0: 37400a 253492811i bk1: 35008a 253506219i bk2: 36976a 253504836i bk3: 34842a 253505041i bk4: 36042a 253509475i bk5: 35066a 253506885i bk6: 36634a 253505047i bk7: 35794a 253504877i bk8: 36976a 253506404i bk9: 41320a 253502170i bk10: 48314a 253502322i bk11: 46050a 253493213i bk12: 47376a 253472385i bk13: 36722a 253437384i bk14: 36568a 253057109i bk15: 35182a 249107641i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.00150854
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=253562703 n_nop=252578295 n_act=174187 n_pre=174171 n_req=318025 n_rd=608110 n_write=27940 bw_util=0.005017
n_activity=9404659 dram_eff=0.1353
bk0: 36860a 253499843i bk1: 34966a 253507364i bk2: 36334a 253507044i bk3: 34808a 253506514i bk4: 35108a 253512582i bk5: 34974a 253508897i bk6: 37028a 253505579i bk7: 35622a 253506157i bk8: 36970a 253508287i bk9: 41260a 253503818i bk10: 47288a 253504398i bk11: 45720a 253495311i bk12: 42784a 253474850i bk13: 36612a 253442117i bk14: 36590a 253049441i bk15: 35186a 249123722i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.0015653
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=253562703 n_nop=252546849 n_act=183153 n_pre=183137 n_req=324782 n_rd=621388 n_write=28176 bw_util=0.005123
n_activity=9762248 dram_eff=0.1331
bk0: 37432a 253477294i bk1: 35512a 253502129i bk2: 37076a 253499739i bk3: 35178a 253500068i bk4: 36102a 253502773i bk5: 35004a 253496562i bk6: 36782a 253501041i bk7: 36348a 253500831i bk8: 37004a 253497090i bk9: 42210a 253494090i bk10: 48478a 253496884i bk11: 46868a 253488445i bk12: 47728a 253463738i bk13: 37174a 253434872i bk14: 36914a 253104225i bk15: 35578a 248949058i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.00131213
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=253562703 n_nop=252573357 n_act=178850 n_pre=178834 n_req=315831 n_rd=603704 n_write=27958 bw_util=0.004982
n_activity=9562929 dram_eff=0.1321
bk0: 36070a 253481260i bk1: 35056a 253505459i bk2: 35610a 253504568i bk3: 34808a 253504923i bk4: 35182a 253507666i bk5: 35010a 253502590i bk6: 36062a 253506887i bk7: 35566a 253504601i bk8: 36120a 253504768i bk9: 41500a 253499662i bk10: 46568a 253501045i bk11: 46080a 253493358i bk12: 41976a 253470111i bk13: 36838a 253439718i bk14: 35962a 253110929i bk15: 35296a 249027576i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.00129133
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28146852, Miss = 304337 (0.0108), PendingHit = 116476 (0.00414)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28146938, Miss = 308135 (0.0109), PendingHit = 114182 (0.00406)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28146254, Miss = 304055 (0.0108), PendingHit = 113483 (0.00403)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28179958, Miss = 310694 (0.011), PendingHit = 117723 (0.00418)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28146782, Miss = 301852 (0.0107), PendingHit = 109427 (0.00389)
L2 Cache Total Miss Rate = 0.011

icnt_total_pkts_mem_to_simt=687023908
icnt_total_pkts_simt_to_mem=157576768

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 1.38522
% Accepted packets = 0 at node 0 (avg = 0.0243176)
lat(1) = 1.38522;
thru(1,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.111835 0.111835 0.111833 0.111953 0.111849 0 0 0 0 ];
% latency change    = 1
% throughput change = 1
Traffic 1 Stat
%=================================
% Average latency = 9.38922
% Accepted packets = 0 at node 14 (avg = 0.106023)
lat(2) = 9.38922;
thru(2,:) = [ 0.180976 0.171474 0.171452 0.171493 0.180933 0.171378 0.171522 0.180959 0.171499 0.171493 0.171446 0.171461 0.180947 0.171503 0 0 0 0 0 0 0 0 0 ];
% latency change    = 0.852467
% throughput change = 0.770639
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 1.38522 (1 samples)
Traffic[0]class0Overall average accepted rate = 0.0243176 (1 samples)
Traffic[0]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 124353907 8523098 904304 864627 1895347 622887 364029 1198561 933015 662023 222997 97097 40222 26416 15153 10935 6322 3009 1833 1056 891 460 534 223 411 158 331 130 300 101 270 121 265 81 250 68 211 93 236 65 233 57 213 81 205 70 197 71 187 64 180 48 143 62 170 58 186 44 156 56 152 47 178 50 156 45 146 66 122 47 132 51 136 54 136 42 138 43 137 36 122 46 126 53 156 57 145 38 105 46 112 46 132 36 131 47 106 37 146 37 125 41 123 40 132 43 135 41 125 43 139 38 137 36 137 45 129 41 118 41 128 38 127 53 137 42 138 50 133 48 136 38 113 52 136 46 119 41 125 36 125 46 127 40 108 47 131 44 115 50 143 48 129 43 114 46 128 45 128 48 119 37 103 36 102 50 114 34 95 39 106 38 107 28 94 39 99 23 89 31 73 33 65 38 73 25 77 37 78 18 65 32 67 23 64 21 41 24 59 22 51 19 45 24 34 20 49 14 25 18 29 11 15 14 29 15 24 10 20 13 17 10 19 13 13 10 19 8 14 7 18 6 14 6 14 7 17 4 13 10 9 6 9 8 6 6 13 6 8 5 9 7 9 8 6 2 10 0 8 6 10 8 6 1 3 4 6 3 7 2 5 2 6 4 7 2 7 3 5 2 4 6 4 0 4 1 2 4 4 1 1 2 3 1 10 2 3 1 3 0 3 1 2 0 2 0 1 1 4 3 0 1 3 1 0 2 2 1 2 0 3 0 1 2 1 1 2 2 0 2 4 0 2 3 5 1 2 3 4 1 2 3 1 0 2 0 1 0 0 1 1 2 3 0 4 0 7 1 4 0 5 0 5 1 1 1 2 3 3 1 2 1 1 0 2 0 2 0 3 0 0 0 1 0 1 0 0 0 1 0 1 0 0 2 1 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (140766784 samples)
traffic_manager/hop_stats_freq = [ 0 140766784 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 9.38922 (1 samples)
Traffic[1]class0Overall average accepted rate = 0.106023 (1 samples)
Traffic[1]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 1978692 365968 309105 181807 41005706 17358164 5198000 13235205 11748768 8133260 6249594 5145014 3871867 4300283 2765189 4486672 1851864 1440204 1454709 1407079 1905764 844554 718951 820844 630263 896117 352333 299439 293887 249336 364538 153181 135809 119403 94114 141707 54951 42456 37456 28311 38487 14443 9937 7865 6425 8220 2943 2002 1547 1205 1512 467 313 224 192 242 53 37 34 22 34 5 3 3 3 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (140766784 samples)
traffic_manager/hop_stats_freq = [ 0 140766784 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 18 hrs, 0 min, 29 sec (64829 sec)
gpgpu_simulation_rate = 22959 (inst/sec)
gpgpu_simulation_rate = 2172 (cycle/sec)
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
GPU Runtime: 64829.257895s
