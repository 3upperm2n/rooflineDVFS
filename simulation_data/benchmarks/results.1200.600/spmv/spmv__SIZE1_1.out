

        *** GPGPU-Sim Simulator Version 3.2.1  [build 15629] ***


               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim: Configuration options:

-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   20 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  4:128:24,L:R:m:N,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 64:64:2,L:R:f:N,A:2:32,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     4:128:4,L:R:f:N,A:2:32,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     32:128:4,L:L:m:N,A:32:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                32768 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_shader_cta                       8 # Maximum number of concurrent CTAs in shader (default 8)
-gpgpu_n_clusters                      14 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_size                   16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   16 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_operand_collector_num_units_sp                    6 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_sfu                    8 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (default = 13, anything else is off for now)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths        2,1,1,2,1,1,2 # Pipeline widths ID_OC_SP,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_SFU,OC_EX_MEM,EX_WB
-gpgpu_num_sp_units                     2 # Number of SP units (default=1)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      lrr # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     64:128:16,L:B:m:W,A:32:4,4 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            5 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_mem_per_ctrlr                    2 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   16 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                    0 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=4:CCDL=3:RTPL=2 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-rop_latency                          120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.BBBBCCCC.CCSSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpuwattch_xml_file         gpuwattch.xml # GPUWattch XML file
-power_simulation_enabled                    1 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-power_trace_enabled                    1 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 600.0:1200.0:600.0:600.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                    8 # maximum kernels that can run concurrently on GPU
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,19,25,145
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_initiation_int            1,2,2,1,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,4,4,32
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default6493d10bd32708775379eef4f7ff926f  /tmp/tmp.jdjmAbUF10/spmv__SIZE1_1
 1,1,1,1,5
-ptx_opcode_initiation_dp         8,16,8,8,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    3 # column to column delay between accesses to different bank groups
RTPL                                    2 # read to precharge delay between accesses to different bank groups
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 000000000000f000 	high:16 low:12
addr_dec_mask[ROW]   = 000000000fff0000 	high:28 low:16
addr_dec_mask[COL]   = 0000000000000fff 	high:12 low:0
addr_dec_mask[BURST] = 000000000000003f 	high:6 low:0
*** Initializing Memory Statistics ***
self exe links to: /tmp/tmp.jdjmAbUF10/spmv__SIZE1_1
Running md5sum using "md5sum /tmp/tmp.jdjmAbUF10/spmv__SIZE1_1 "
Running cuobjdump using "$CUDA_INSTALL_PATH/bin/cuobjdump -ptx -elf -sass /tmp/tmp.jdjmAbUF10/spmv__SIZE1_1 > _cuobjdump_complete_output_sYubQg"
Parsing file _cuobjdump_complete_output_sYubQg
######### cuobjdump parser ########
## Adding new section PTX
Adding ptx filename: _cuobjdump_1.ptx
Adding arch: sm_13
Adding identifier: benchmarks/spmv/spmv.cu
## Adding new section ELF
Adding arch: sm_13
Adding identifier: benchmarks/spmv/spmv.cu
Done parsing!!!
Adding _cuobjdump_1.ptx with cubin handle 1
Running: cat _ptx_c7I7Hk | sed 's/.version 1.5/.version 1.4/' | sed 's/, texmode_independent//' | sed 's/\(\.extern \.const\[1\] .b8 \w\+\)\[\]/\1\[1\]/' | sed 's/const\[.\]/const\[0\]/g' > _ptx2_95G4zo
GPGPU-Sim PTX registering constant jds_ptr_int (20000 bytes) to name mapping
GPGPU-Sim PTX registering constant sh_zcnt_int (20000 bytes) to name mapping
CUDA accelerated sparse matrix vector multiplication****
Original version by Li-Wen Chang <lchang20@illinois.edu> and Shengzhao Wu<wu14@illinois.edu>
This version maintained by Chris Rodrigues  ***********
Input file /home/cnugteren/software/parboil-2.5/datasets/spmv/medium/input/bcsstk18.mtx
Converting COO to JDS format (11948x11948)
149090 matrix entries, warp size = 32, row padding align = 1, pack size = 1

Padding data....11968 rows, 374 groups
Allocating data space: 150144 entries (0.701993% padding)
Finished converting.
JDS format has 11968 columns, 49 rows.
nz_count_len = 374
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread

kernel '_Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i' transfer to GPU hardware scheduler
kernel_name = _Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i 
kernel_launch_uid = 1 
gpu_sim_cycle = 45717
gpu_sim_insn = 4941796
gpu_ipc =     108.0954
gpu_tot_sim_cycle = 45717
gpu_tot_sim_insn = 4941796
gpu_tot_ipc =     108.0954
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 39018
gpu_stall_icnt2sh    = 196612
gpu_total_sim_rate=274544
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6446, Miss = 3549 (0.551), PendingHit = 72 (0.0112)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6188, Miss = 3327 (0.538), PendingHit = 111 (0.0179)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6334, Miss = 3595 (0.568), PendingHit = 144 (0.0227)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6490, Miss = 3497 (0.539), PendingHit = 109 (0.0168)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6483, Miss = 3225 (0.497), PendingHit = 160 (0.0247)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6331, Miss = 3176 (0.502), PendingHit = 146 (0.0231)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6084, Miss = 3538 (0.582), PendingHit = 78 (0.0128)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6862, Miss = 3627 (0.529), PendingHit = 157 (0.0229)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6647, Miss = 3533 (0.532), PendingHit = 152 (0.0229)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6414, Miss = 3272 (0.51), PendingHit = 185 (0.0288)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6797, Miss = 3590 (0.528), PendingHit = 202 (0.0297)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6459, Miss = 3711 (0.575), PendingHit = 155 (0.024)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6471, Miss = 3799 (0.587), PendingHit = 124 (0.0192)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6321, Miss = 3678 (0.582), PendingHit = 142 (0.0225)
total_dl1_misses=49117
total_dl1_accesses=90327
total_dl1_miss_rate= 0.543769
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 
distro:
877, 815, 753, 692, 629, 629, 598, 567, 567, 505, 505, 474, 443, 412, 412, 381, 319, 288, 257, 226, 226, 226, 195, 195, 133, 133, 71, 
gpgpu_n_tot_thrd_icount = 5134880
gpgpu_n_tot_w_icount = 160465
gpgpu_n_icache_hits = 87254
gpgpu_n_icache_misses = 464
gpgpu_n_l1dcache_read_hits = 39273
gpgpu_n_l1dcache_read_misses = 51054
gpgpu_n_l1dcache_write_accesses = 5416
gpgpu_n_l1dcache_wirte_misses = 5416
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 25110
gpgpu_n_ccache_misses = 594
gpgpu_n_stall_shd_mem = 172517
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 49117
gpgpu_n_mem_write_global = 5416
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 336
gpgpu_n_load_insn  = 922550
gpgpu_n_store_insn = 23896
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 324144
gpgpu_n_param_mem_insn = 1318422
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 9613
gpgpu_stall_shd_mem[c_mem][bk_conf] = 9613
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 162904
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:73697	W0_Idle:40381	W0_Scoreboard:929647	W1:31	W2:21	W3:27	W4:19	W5:30	W6:7	W7:12	W8:7	W9:13	W10:6	W11:18	W12:69	W13:8	W14:20	W15:7	W16:0	W17:7	W18:15	W19:13	W20:7	W21:3	W22:1	W23:8	W24:7	W25:2	W26:7	W27:5	W28:9	W29:22	W30:21	W31:11	W32:160032
maxmrqlatency = 399 
maxdqlatency = 0 
maxmflatency = 898 
averagemflatency = 208 
max_icnt2mem_latency = 264 
max_icnt2sh_latency = 45716 
mrq_lat_table:8174 	296 	403 	425 	689 	392 	364 	166 	52 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	1856 	38247 	14664 	102 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:41 	31574 	4801 	3506 	3156 	3647 	5179 	3022 	13 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	4423 	7335 	35023 	2668 	4 	0 	0 	0 	0 	0 	0 	0 	0 	1926 	3490 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	79 	11 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        32        32        32        10        32        22        30        32        54        61        24        22        12        26        26 
dram[1]:        32        28        32        32        10        31        22        30        32        62        58        25        20        18        23        24 
dram[2]:        23        32        32        32        17        32        23        32        32        57        55        26        19        20        24        24 
dram[3]:        32        26        32        30        18        32        19        31        32        59        69        20        19        18        22        26 
dram[4]:        27        32        32        32        15        32        20        31        32        56        58        20        20        17        24        26 
maximum service time to same row:
dram[0]:      7997      8958      8633      9802     10066     11884     13975      7735     12961     11429      7364      8371      8716      9718      8608      7637 
dram[1]:      8256      9178      9068     10046      9939     11925     13247      7366     12692      8561      7332      8443      8175     10584      7438      7781 
dram[2]:      8281      8414      9015      9957     10020     12319     14346      9900     13343      7619      7567      8977      7971     10547      7648      7675 
dram[3]:      8260      8780      8854      9516     10323     12287     13741      9208     13354      7316      7234      8953      7843     10880      7456      7764 
dram[4]:      8434      8839      8975      9651      9302     12230     14188      8374     13483      6960      7341      8767      8177     10863      7967      7896 
average row accesses per activate:
dram[0]: 10.076923  8.533334  8.666667  4.000000  2.800000  6.095238  3.230769  6.095238  5.333333  4.275000  3.648148  5.066667  3.459460  3.368421  6.400000  5.333333 
dram[1]: 10.000000  6.190476  8.125000  3.555556  2.370370  5.565217  3.000000  7.529412  4.923077  6.357143  3.174603  4.371428  3.200000  3.200000  4.266667  5.818182 
dram[2]:  6.789474  7.647059  9.214286  3.459460  2.909091  6.095238  3.705882  5.333333  6.095238  7.695652  3.062500  4.617647  3.282051  3.555556  5.565217  5.333333 
dram[3]:  7.277778  5.200000  7.111111  3.657143  3.282051  8.000000  3.100000  5.120000  6.736842  6.629630  3.295082  5.285714  2.509804  2.909091  6.400000  4.923077 
dram[4]:  6.400000  5.909091 10.666667  3.878788  2.782609  4.740741  2.863636  5.333333  5.333333  5.454545  3.062500  5.920000  3.282051  3.282051  4.571429  5.120000 
average row locality = 10961/2445 = 4.483027
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       131       128       130       128       126       128       126       128       128       140       160       140       128       128       128       128 
dram[1]:       130       130       130       128       128       128       126       128       128       140       160       140       128       128       128       128 
dram[2]:       129       130       129       128       128       128       126       128       128       140       160       141       128       128       128       128 
dram[3]:       131       130       128       128       128       128       124       128       128       142       160       138       128       128       128       128 
dram[4]:       128       130       128       128       128       128       126       128       128       142       160       138       128       128       128       128 
total reads: 10529
bank skew: 160/124 = 1.29
chip skew: 2108/2104 = 1.00
number of total write accesses:
dram[0]:         0         0         0         0         0         0         0         0         0        31        37        12         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0        38        40        13         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0        37        36        16         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0        37        41        10         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0        38        36        10         0         0         0         0 
total reads: 432
min_bank_accesses = 0!
chip skew: 91/80 = 1.14
average mf latency per bank:
dram[0]:        345       309       382       311       323       305      1728      5463      6307       760       643       461       323       302       318       315
dram[1]:        311       384       379       328       334       300      1891      5469      5736       636       631       455       315       288       298       291
dram[2]:        313       391       327       299       309       287      1590      4779      5451       637       652       428       304       291       305       300
dram[3]:        367       351       311       303       295       293      1893      4802      5145       612       609       423       321       302       319       297
dram[4]:        302       342       301       289       293       278      1586      4805      5200       589       610       434       306       296       290       295
maximum mf latency per bank:
dram[0]:        522       488       540       523       492       499       540       569       600       767       597       641       512       465       463       485
dram[1]:        500       512       478       506       516       474       539       526       542       898       762       536       488       413       451       447
dram[2]:        480       463       475       462       495       464       552       534       566       732       533       490       507       461       463       427
dram[3]:        486       459       460       454       492       451       485       479       494       805       504       478       523       445       446       440
dram[4]:        444       368       449       411       431       370       486       552       531       588       653       546       503       478       447       448

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=45717 n_nop=40485 n_act=469 n_pre=453 n_req=2185 n_rd=4210 n_write=100 bw_util=0.1886
n_activity=26484 dram_eff=0.3255
bk0: 262a 44824i bk1: 256a 44928i bk2: 260a 44897i bk3: 256a 44840i bk4: 252a 44865i bk5: 256a 44930i bk6: 252a 44905i bk7: 256a 45151i bk8: 256a 44787i bk9: 280a 44639i bk10: 320a 44501i bk11: 280a 44422i bk12: 256a 44228i bk13: 256a 43489i bk14: 256a 42234i bk15: 256a 36401i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.48249
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=45717 n_nop=40386 n_act=508 n_pre=492 n_req=2199 n_rd=4216 n_write=115 bw_util=0.1895
n_activity=26887 dram_eff=0.3222
bk0: 260a 44762i bk1: 260a 44768i bk2: 260a 44855i bk3: 256a 44918i bk4: 256a 44672i bk5: 256a 44706i bk6: 252a 44873i bk7: 256a 44904i bk8: 256a 44842i bk9: 280a 44694i bk10: 320a 44757i bk11: 280a 44383i bk12: 256a 43957i bk13: 256a 43467i bk14: 256a 42080i bk15: 256a 35791i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.574272
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=45717 n_nop=40449 n_act=475 n_pre=459 n_req=2196 n_rd=4214 n_write=120 bw_util=0.1896
n_activity=26481 dram_eff=0.3273
bk0: 258a 44887i bk1: 260a 44809i bk2: 258a 44847i bk3: 256a 44739i bk4: 256a 44893i bk5: 256a 44882i bk6: 252a 44914i bk7: 256a 44932i bk8: 256a 44715i bk9: 280a 44740i bk10: 320a 44563i bk11: 282a 44353i bk12: 256a 44173i bk13: 256a 43497i bk14: 256a 42110i bk15: 256a 36592i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.485312
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=45717 n_nop=40422 n_act=493 n_pre=477 n_req=2193 n_rd=4210 n_write=115 bw_util=0.1892
n_activity=26535 dram_eff=0.326
bk0: 262a 44703i bk1: 260a 44837i bk2: 256a 44885i bk3: 256a 44842i bk4: 256a 44791i bk5: 256a 44850i bk6: 248a 44821i bk7: 256a 44828i bk8: 256a 44775i bk9: 284a 44607i bk10: 320a 44658i bk11: 276a 44449i bk12: 256a 44053i bk13: 256a 43530i bk14: 256a 42123i bk15: 256a 36058i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.500055
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=45717 n_nop=40408 n_act=505 n_pre=489 n_req=2188 n_rd=4208 n_write=107 bw_util=0.1888
n_activity=26964 dram_eff=0.3201
bk0: 256a 44729i bk1: 260a 44734i bk2: 256a 44817i bk3: 256a 44849i bk4: 256a 44885i bk5: 256a 44897i bk6: 252a 44950i bk7: 256a 44995i bk8: 256a 44830i bk9: 284a 44663i bk10: 320a 44699i bk11: 276a 44553i bk12: 256a 44220i bk13: 256a 43533i bk14: 256a 42022i bk15: 256a 35761i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.482818
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 11215, Miss = 2105 (0.188), PendingHit = 67 (0.00597)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 11171, Miss = 2108 (0.189), PendingHit = 82 (0.00734)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 10893, Miss = 2107 (0.193), PendingHit = 71 (0.00652)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 10836, Miss = 2105 (0.194), PendingHit = 68 (0.00628)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 10824, Miss = 2104 (0.194), PendingHit = 61 (0.00564)
L2 Cache Total Miss Rate = 0.192

icnt_total_pkts_mem_to_simt=252359
icnt_total_pkts_simt_to_mem=65160

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 25.3209
% Accepted packets = 0 at node 0 (avg = 0.0309849)
lat(1) = 25.3209;
thru(1,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.144456 0.144663 0.142202 0.140518 0.140813 0 0 0 0 ];
% latency change    = 1
% throughput change = 1
Traffic 1 Stat
%=================================
% Average latency = 16.7515
% Accepted packets = 0 at node 14 (avg = 0.120002)
lat(2) = 16.7515;
thru(2,:) = [ 0.199512 0.186716 0.201765 0.196472 0.181379 0.179049 0.198495 0.204434 0.198648 0.184025 0.201579 0.208481 0.213369 0.206118 0 0 0 0 0 0 0 0 0 ];
% latency change    = 0.511559
% throughput change = 0.741796
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 25.3209 (1 samples)
Traffic[0]class0Overall average accepted rate = 0.0309849 (1 samples)
Traffic[0]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 32169 5012 1134 513 594 431 419 390 591 531 518 392 375 234 280 242 309 149 257 152 206 104 167 85 159 87 126 58 144 64 126 64 112 62 124 39 106 39 91 51 92 43 96 53 93 37 78 50 102 31 86 34 79 40 91 34 69 24 85 28 96 25 83 34 76 23 55 28 83 21 76 26 63 28 78 18 66 18 59 29 47 21 44 26 70 28 56 23 49 11 53 24 66 21 53 22 56 21 58 24 49 21 42 17 35 13 46 16 51 23 50 21 52 11 37 14 47 18 62 23 60 18 53 9 36 14 44 25 34 20 45 9 39 16 58 16 48 22 40 15 53 17 38 18 35 21 57 15 32 9 40 8 48 17 38 21 37 15 50 13 52 14 41 25 57 19 43 20 41 14 41 16 53 10 41 18 49 15 54 16 42 12 39 16 30 15 35 12 40 13 50 20 47 17 38 22 40 26 46 18 49 13 50 20 46 11 40 26 40 16 27 6 35 14 41 11 31 15 34 7 32 14 28 13 27 8 28 9 20 14 31 12 36 9 25 15 38 7 35 6 29 11 28 5 23 14 32 5 25 8 25 6 32 9 32 5 23 3 15 8 24 3 22 8 36 10 20 6 20 9 21 7 30 5 15 4 13 3 16 5 15 8 17 5 20 2 17 0 17 5 20 0 20 1 11 4 13 6 9 1 13 1 18 2 13 2 12 3 11 3 13 1 5 3 9 2 9 2 11 5 14 3 14 2 12 2 6 8 5 1 10 1 5 1 5 2 7 3 5 1 7 1 7 2 6 1 5 2 5 2 7 0 8 1 6 1 1 0 6 2 3 5 3 0 8 0 2 1 3 1 3 2 4 1 3 0 4 0 2 0 3 1 1 0 4 1 2 0 3 2 6 0 2 1 2 0 6 1 5 0 1 0 2 0 0 0 2 0 3 0 2 0 0 0 1 0 1 0 1 0 2 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (54939 samples)
traffic_manager/hop_stats_freq = [ 0 54939 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 16.7515 (1 samples)
Traffic[1]class0Overall average accepted rate = 0.120002 (1 samples)
Traffic[1]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 1466 171 130 190 3833 753 496 1064 2283 917 801 877 778 1337 785 17245 1239 1070 1247 1114 7805 632 518 596 575 3063 302 256 273 265 1197 125 136 120 117 490 51 50 60 51 174 25 27 31 12 62 19 9 11 11 25 4 1 3 9 11 2 3 3 5 7 1 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (54939 samples)
traffic_manager/hop_stats_freq = [ 0 54939 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 19 sec (19 sec)
gpgpu_simulation_rate = 260094 (inst/sec)
gpgpu_simulation_rate = 2406 (cycle/sec)

kernel '_Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i' transfer to GPU hardware scheduler
kernel_name = _Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i 
kernel_launch_uid = 2 
gpu_sim_cycle = 44617
gpu_sim_insn = 4941796
gpu_ipc =     110.7604
gpu_tot_sim_cycle = 90334
gpu_tot_sim_insn = 9883592
gpu_tot_ipc =     109.4117
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 84192
gpu_stall_icnt2sh    = 399048
gpu_total_sim_rate=267124
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13003, Miss = 6920 (0.532), PendingHit = 212 (0.0163)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12170, Miss = 6715 (0.552), PendingHit = 205 (0.0168)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12841, Miss = 6932 (0.54), PendingHit = 250 (0.0195)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13187, Miss = 7154 (0.543), PendingHit = 247 (0.0187)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13027, Miss = 6665 (0.512), PendingHit = 349 (0.0268)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13076, Miss = 6714 (0.513), PendingHit = 310 (0.0237)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12559, Miss = 7182 (0.572), PendingHit = 172 (0.0137)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13298, Miss = 7356 (0.553), PendingHit = 296 (0.0223)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13124, Miss = 6957 (0.53), PendingHit = 241 (0.0184)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12380, Miss = 6705 (0.542), PendingHit = 341 (0.0275)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13148, Miss = 7103 (0.54), PendingHit = 309 (0.0235)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12999, Miss = 7554 (0.581), PendingHit = 305 (0.0235)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13078, Miss = 7512 (0.574), PendingHit = 253 (0.0193)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12764, Miss = 7379 (0.578), PendingHit = 269 (0.0211)
total_dl1_misses=98848
total_dl1_accesses=180654
total_dl1_miss_rate= 0.547168
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 
distro:
877, 815, 753, 692, 629, 629, 598, 567, 567, 505, 505, 474, 443, 412, 412, 381, 319, 288, 257, 226, 226, 226, 195, 195, 133, 133, 71, 1001, 877, 784, 722, 660, 629, 598, 598, 536, 536, 536, 443, 443, 412, 381, 350, 319, 288, 226, 226, 226, 226, 195, 133, 133, 102, 102, 
gpgpu_n_tot_thrd_icount = 10269760
gpgpu_n_tot_w_icount = 320930
gpgpu_n_icache_hits = 174508
gpgpu_n_icache_misses = 464
gpgpu_n_l1dcache_read_hits = 78047
gpgpu_n_l1dcache_read_misses = 102607
gpgpu_n_l1dcache_write_accesses = 10832
gpgpu_n_l1dcache_wirte_misses = 10832
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 50770
gpgpu_n_ccache_misses = 638
gpgpu_n_stall_shd_mem = 339723
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 98848
gpgpu_n_mem_write_global = 10832
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 373
gpgpu_n_load_insn  = 1845100
gpgpu_n_store_insn = 47792
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 648288
gpgpu_n_param_mem_insn = 2636844
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 9613
gpgpu_stall_shd_mem[c_mem][bk_conf] = 9613
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 330110
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:112116	W0_Idle:59391	W0_Scoreboard:1855445	W1:62	W2:42	W3:54	W4:38	W5:60	W6:14	W7:24	W8:14	W9:26	W10:12	W11:36	W12:138	W13:16	W14:40	W15:14	W16:0	W17:14	W18:30	W19:26	W20:14	W21:6	W22:2	W23:16	W24:14	W25:4	W26:14	W27:10	W28:18	W29:44	W30:42	W31:22	W32:320064
maxmrqlatency = 399 
maxdqlatency = 0 
maxmflatency = 898 
averagemflatency = 210 
max_icnt2mem_latency = 264 
max_icnt2sh_latency = 90333 
mrq_lat_table:16244 	558 	794 	746 	1311 	730 	496 	180 	52 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	3421 	76639 	29876 	117 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:41 	60957 	9716 	7180 	6816 	7538 	11091 	6771 	13 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	8550 	14056 	71462 	5148 	5 	0 	0 	0 	0 	0 	0 	0 	0 	1926 	4126 	4780 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	162 	18 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        32        32        32        18        32        22        30        32        54        61        24        22        20        26        26 
dram[1]:        32        28        32        32        15        31        23        30        32        62        58        25        20        18        23        24 
dram[2]:        32        32        32        32        19        32        23        32        32        57        55        26        24        20        25        24 
dram[3]:        32        26        32        30        18        32        22        31        32        59        69        23        19        20        23        26 
dram[4]:        30        32        32        32        15        32        20        31        32        56        58        22        20        20        25        26 
maximum service time to same row:
dram[0]:      7997      9256      8674     10084     10066     12616     14827      9861     12961     11429      7520     15601      8716     10109      8608      7768 
dram[1]:      8256      9178      9068     10048     10533     12528     14174      9935     13414     10466      7752     11358      8175     10584      7476      7795 
dram[2]:      8281      9225      9133      9957     10298     12422     14508     10068     13696      7619      7567     14949      7971     10812      7790      7765 
dram[3]:      8670      8780      9374      9516     10626     12601     14813      9930     13810      7316      7392     16112      7843     11628      7702      7764 
dram[4]:      8446      8839      8975      9651      9782     13319     14943     10079     13885      6960      7341     15792      8177     11364      7967      7896 
average row accesses per activate:
dram[0]:  9.592592  8.258064  8.125000  3.878788  2.709677  5.446808  3.102564  5.894737  4.226415  3.780488  3.254545  4.666667  3.240506  3.160494  5.818182  5.224490 
dram[1]: 10.320000  7.371428  7.222222  3.657143  2.509804  5.120000  2.987654  6.222222  3.929825  5.508772  3.141667  3.944444  3.368421  3.121951  4.000000  5.953488 
dram[2]:  7.342857  6.972973  7.818182  3.820895  2.876405  5.565217  3.611940  5.743590  4.765957  5.526316  3.128205  4.500000  3.506849  3.240506  4.830189  5.333333 
dram[3]:  7.428571  5.416667  7.314286  4.063492  3.084337  6.918919  3.131579  4.869565  5.463415  6.072727  3.136752  4.758621  2.438095  2.976744  5.446808  4.923077 
dram[4]:  6.400000  6.166667 11.130435  4.491228  2.723404  4.063492  2.857143  4.869565  5.090909  4.794117  2.816794  5.750000  2.909091  3.459460  4.654545  5.019608 
average row locality = 21111/4919 = 4.291726
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       259       256       260       256       252       256       242       224       224       258       299       268       256       256       256       256 
dram[1]:       258       258       260       256       256       256       242       224       224       257       304       269       256       256       256       256 
dram[2]:       257       258       258       256       256       256       242       224       224       258       302       270       256       256       256       256 
dram[3]:       260       260       256       256       256       256       238       224       224       267       300       266       256       256       256       256 
dram[4]:       256       259       256       256       256       256       240       224       224       264       302       266       256       256       256       256 
total reads: 20421
bank skew: 304/224 = 1.36
chip skew: 4088/4078 = 1.00
number of total write accesses:
dram[0]:         0         0         0         0         0         0         0         0         0        52        59        12         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0        57        73        15         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0        57        64        18         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0        67        67        10         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0        62        67        10         0         0         0         0 
total reads: 690
min_bank_accesses = 0!
chip skew: 145/123 = 1.18
average mf latency per bank:
dram[0]:        344       321       372       320       332       309      1818      6481      7396       850       710       500       323       304       328       321
dram[1]:        320       354       363       329       328       305      1964      6373      6824       702       661       490       324       295       312       303
dram[2]:        303       343       319       301       304       295      1601      5488      6166       708       685       462       303       291       303       293
dram[3]:        343       334       308       301       300       296      2022      5640      6140       649       654       452       322       304       317       302
dram[4]:        301       320       305       293       303       286      1661      5547      6069       644       649       462       315       296       295       295
maximum mf latency per bank:
dram[0]:        527       499       540       523       515       505       540       569       600       767       597       641       512       472       487       486
dram[1]:        500       512       494       506       517       474       539       526       542       898       762       536       488       514       501       473
dram[2]:        480       463       475       465       495       464       552       534       566       732       533       490       507       461       463       427
dram[3]:        491       472       460       483       560       451       485       479       494       805       504       478       523       487       460       456
dram[4]:        444       411       449       437       496       433       486       552       531       588       653       546       503       478       461       448

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=90334 n_nop=80082 n_act=971 n_pre=955 n_req=4201 n_rd=8156 n_write=170 bw_util=0.1843
n_activity=51845 dram_eff=0.3212
bk0: 518a 88556i bk1: 512a 88758i bk2: 520a 88862i bk3: 512a 88832i bk4: 504a 88783i bk5: 512a 88882i bk6: 484a 88922i bk7: 448a 88977i bk8: 448a 88656i bk9: 516a 88339i bk10: 598a 88190i bk11: 536a 87943i bk12: 512a 87426i bk13: 512a 86115i bk14: 512a 83259i bk15: 512a 71462i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.337038
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=90334 n_nop=79957 n_act=1008 n_pre=992 n_req=4233 n_rd=8176 n_write=201 bw_util=0.1855
n_activity=51999 dram_eff=0.3222
bk0: 516a 88535i bk1: 516a 88530i bk2: 520a 88734i bk3: 512a 88925i bk4: 512a 88566i bk5: 512a 88589i bk6: 484a 88903i bk7: 448a 88822i bk8: 448a 88710i bk9: 514a 88457i bk10: 608a 88399i bk11: 538a 87863i bk12: 512a 87037i bk13: 512a 85915i bk14: 512a 83035i bk15: 512a 70800i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.387041
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=90334 n_nop=80070 n_act=952 n_pre=936 n_req=4224 n_rd=8170 n_write=206 bw_util=0.1854
n_activity=52119 dram_eff=0.3214
bk0: 514a 88815i bk1: 516a 88562i bk2: 516a 88733i bk3: 512a 88656i bk4: 512a 88951i bk5: 512a 88761i bk6: 484a 88855i bk7: 448a 88665i bk8: 448a 88500i bk9: 516a 88485i bk10: 604a 88353i bk11: 540a 87749i bk12: 512a 87351i bk13: 512a 86048i bk14: 512a 83474i bk15: 512a 72147i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.330274
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=90334 n_nop=79999 n_act=985 n_pre=969 n_req=4231 n_rd=8174 n_write=207 bw_util=0.1856
n_activity=52000 dram_eff=0.3223
bk0: 520a 88480i bk1: 520a 88586i bk2: 512a 88704i bk3: 512a 88569i bk4: 512a 88671i bk5: 512a 88782i bk6: 476a 88758i bk7: 448a 88673i bk8: 448a 88853i bk9: 534a 88431i bk10: 600a 88254i bk11: 532a 87925i bk12: 512a 87145i bk13: 512a 86065i bk14: 512a 82985i bk15: 512a 71325i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.373071
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=90334 n_nop=79970 n_act=1008 n_pre=992 n_req=4222 n_rd=8166 n_write=198 bw_util=0.1852
n_activity=52601 dram_eff=0.318
bk0: 512a 88489i bk1: 518a 88402i bk2: 512a 88560i bk3: 512a 88741i bk4: 512a 88798i bk5: 512a 88745i bk6: 480a 88945i bk7: 448a 88963i bk8: 448a 88657i bk9: 528a 88301i bk10: 604a 88295i bk11: 532a 88029i bk12: 512a 87442i bk13: 512a 86043i bk14: 512a 83055i bk15: 512a 70677i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.365698
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 22526, Miss = 4078 (0.181), PendingHit = 70 (0.00311)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 22298, Miss = 4088 (0.183), PendingHit = 85 (0.00381)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 21819, Miss = 4085 (0.187), PendingHit = 73 (0.00335)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 21840, Miss = 4087 (0.187), PendingHit = 70 (0.00321)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 21640, Miss = 4083 (0.189), PendingHit = 64 (0.00296)
L2 Cache Total Miss Rate = 0.185

icnt_total_pkts_mem_to_simt=506541
icnt_total_pkts_simt_to_mem=130565

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 28.7021
% Accepted packets = 0 at node 0 (avg = 0.0318682)
lat(3) = 28.7021;
thru(3,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.149093 0.147737 0.146078 0.145865 0.144196 0 0 0 0 ];
% latency change    = 0.416367
% throughput change = 2.76557
Traffic 1 Stat
%=================================
% Average latency = 16.9114
% Accepted packets = 0 at node 14 (avg = 0.123849)
lat(4) = 16.9114;
thru(4,:) = [ 0.193606 0.193729 0.191342 0.209351 0.197248 0.203131 0.208925 0.213699 0.196407 0.196732 0.200643 0.21965 0.212343 0.211715 0 0 0 0 0 0 0 0 0 ];
% latency change    = 0.697203
% throughput change = 0.742684
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 27.0115 (2 samples)
Traffic[0]class0Overall average accepted rate = 0.0314266 (2 samples)
Traffic[0]class0Overall min accepted rate = 0 (2 samples)
traffic_manager/latency_stat_0_freq = [ 0 30699 5077 1205 532 664 421 404 415 642 572 525 321 330 187 252 211 353 199 292 154 244 158 177 120 186 103 158 85 143 83 123 98 113 67 137 85 98 47 115 60 115 48 99 47 70 54 94 48 91 44 100 41 93 36 87 33 77 34 84 40 84 22 75 33 82 17 85 35 69 26 87 26 50 37 54 23 60 33 86 31 68 30 75 26 67 27 67 26 63 23 49 15 52 20 68 32 66 26 66 16 52 23 69 24 57 15 62 28 64 18 59 12 46 26 68 18 53 19 54 23 65 19 55 20 51 22 65 15 46 16 49 20 43 19 51 23 52 12 57 16 63 19 41 26 48 16 69 34 53 28 65 28 57 20 56 11 71 16 49 16 50 17 50 27 50 25 47 15 42 16 54 22 48 18 50 17 43 14 56 15 48 18 51 18 59 13 40 12 48 16 52 17 50 12 48 14 40 14 43 14 38 17 40 26 38 10 65 15 38 9 42 5 38 11 49 13 42 8 41 7 34 7 43 11 40 19 35 13 25 5 38 9 36 7 34 12 36 10 21 8 25 7 25 9 31 9 41 6 29 8 37 11 32 7 32 13 43 15 29 5 32 9 20 11 32 4 24 7 22 7 28 3 19 8 28 5 17 7 20 8 21 4 32 16 33 5 29 6 27 3 18 4 12 8 15 9 21 12 21 4 29 5 17 5 26 4 11 3 8 2 15 3 17 4 13 3 12 1 11 2 17 4 16 2 8 3 9 3 9 1 10 4 8 2 8 3 10 4 10 1 9 2 6 1 3 0 2 2 7 1 2 1 8 1 8 1 3 1 10 3 5 0 4 0 5 2 3 0 3 2 2 0 3 0 4 0 2 0 0 0 4 1 5 1 4 0 2 1 1 0 2 0 2 0 2 0 1 0 2 1 3 1 2 0 0 0 2 0 1 0 0 0 0 2 3 0 2 0 1 0 1 0 1 0 1 0 1 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (110123 samples)
traffic_manager/hop_stats_freq = [ 0 110123 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 16.8315 (2 samples)
Traffic[1]class0Overall average accepted rate = 0.121925 (2 samples)
Traffic[1]class0Overall min accepted rate = 0 (2 samples)
traffic_manager/latency_stat_0_freq = [ 0 1369 117 71 130 3652 664 453 923 2088 779 737 764 764 1198 698 18412 1432 1081 1217 1357 8118 634 530 558 615 3120 332 239 250 251 1189 153 84 106 95 438 59 32 33 40 177 20 20 17 20 63 5 6 7 7 26 2 4 4 5 8 1 1 0 2 5 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (110123 samples)
traffic_manager/hop_stats_freq = [ 0 110123 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 37 sec (37 sec)
gpgpu_simulation_rate = 267124 (inst/sec)
gpgpu_simulation_rate = 2441 (cycle/sec)
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
