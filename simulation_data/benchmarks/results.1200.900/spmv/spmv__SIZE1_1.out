

        *** GPGPU-Sim Simulator Version 3.2.1  [build 15629] ***


               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim: Configuration options:

-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   20 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  4:128:24,L:R:m:N,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 64:64:2,L:R:f:N,A:2:32,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     4:128:4,L:R:f:N,A:2:32,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     32:128:4,L:L:m:N,A:32:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                32768 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_shader_cta                       8 # Maximum number of concurrent CTAs in shader (default 8)
-gpgpu_n_clusters                      14 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_size                   16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   16 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_operand_collector_num_units_sp                    6 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_sfu                    8 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (default = 13, anything else is off for now)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths        2,1,1,2,1,1,2 # Pipeline widths ID_OC_SP,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_SFU,OC_EX_MEM,EX_WB
-gpgpu_num_sp_units                     2 # Number of SP units (default=1)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      lrr # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     64:128:16,L:B:m:W,A:32:4,4 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            5 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_mem_per_ctrlr                    2 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   16 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                    0 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=4:CCDL=3:RTPL=2 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-rop_latency                          120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.BBBBCCCC.CCSSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpuwattch_xml_file         gpuwattch.xml # GPUWattch XML file
-power_simulation_enabled                    1 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-power_trace_enabled                    1 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 600.0:1200.0:600.0:900.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                    8 # maximum kernels that can run concurrently on GPU
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,19,25,145
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_initiation_int            1,2,2,1,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,4,4,32
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default0157d18b6b126df64931eb1930c1283b  /tmp/tmp.apHDfTOMz8/spmv__SIZE1_1
 1,1,1,1,5
-ptx_opcode_initiation_dp         8,16,8,8,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    3 # column to column delay between accesses to different bank groups
RTPL                                    2 # read to precharge delay between accesses to different bank groups
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 000000000000f000 	high:16 low:12
addr_dec_mask[ROW]   = 000000000fff0000 	high:28 low:16
addr_dec_mask[COL]   = 0000000000000fff 	high:12 low:0
addr_dec_mask[BURST] = 000000000000003f 	high:6 low:0
*** Initializing Memory Statistics ***
self exe links to: /tmp/tmp.apHDfTOMz8/spmv__SIZE1_1
Running md5sum using "md5sum /tmp/tmp.apHDfTOMz8/spmv__SIZE1_1 "
Running cuobjdump using "$CUDA_INSTALL_PATH/bin/cuobjdump -ptx -elf -sass /tmp/tmp.apHDfTOMz8/spmv__SIZE1_1 > _cuobjdump_complete_output_A4Yaja"
Parsing file _cuobjdump_complete_output_A4Yaja
######### cuobjdump parser ########
## Adding new section PTX
Adding ptx filename: _cuobjdump_1.ptx
Adding arch: sm_13
Adding identifier: benchmarks/spmv/spmv.cu
## Adding new section ELF
Adding arch: sm_13
Adding identifier: benchmarks/spmv/spmv.cu
Done parsing!!!
Adding _cuobjdump_1.ptx with cubin handle 1
Running: cat _ptx_n44aTH | sed 's/.version 1.5/.version 1.4/' | sed 's/, texmode_independent//' | sed 's/\(\.extern \.const\[1\] .b8 \w\+\)\[\]/\1\[1\]/' | sed 's/const\[.\]/const\[0\]/g' > _ptx2_TZVbtf
GPGPU-Sim PTX registering constant jds_ptr_int (20000 bytes) to name mapping
GPGPU-Sim PTX registering constant sh_zcnt_int (20000 bytes) to name mapping
CUDA accelerated sparse matrix vector multiplication****
Original version by Li-Wen Chang <lchang20@illinois.edu> and Shengzhao Wu<wu14@illinois.edu>
This version maintained by Chris Rodrigues  ***********
Input file /home/cnugteren/software/parboil-2.5/datasets/spmv/medium/input/bcsstk18.mtx
Converting COO to JDS format (11948x11948)
149090 matrix entries, warp size = 32, row padding align = 1, pack size = 1

Padding data....11968 rows, 374 groups
Allocating data space: 150144 entries (0.701993% padding)
Finished converting.
JDS format has 11968 columns, 49 rows.
nz_count_len = 374
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread

kernel '_Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i' transfer to GPU hardware scheduler
kernel_name = _Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i 
kernel_launch_uid = 1 
gpu_sim_cycle = 45463
gpu_sim_insn = 4941796
gpu_ipc =     108.6993
gpu_tot_sim_cycle = 45463
gpu_tot_sim_insn = 4941796
gpu_tot_ipc =     108.6993
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 44425
gpu_stall_icnt2sh    = 199854
gpu_total_sim_rate=329453
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6075, Miss = 3647 (0.6), PendingHit = 154 (0.0253)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6227, Miss = 3423 (0.55), PendingHit = 123 (0.0198)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6462, Miss = 3539 (0.548), PendingHit = 141 (0.0218)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6581, Miss = 3788 (0.576), PendingHit = 126 (0.0191)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6512, Miss = 3785 (0.581), PendingHit = 117 (0.018)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6423, Miss = 3297 (0.513), PendingHit = 158 (0.0246)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6453, Miss = 3695 (0.573), PendingHit = 60 (0.0093)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6423, Miss = 3304 (0.514), PendingHit = 130 (0.0202)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6340, Miss = 3407 (0.537), PendingHit = 147 (0.0232)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6748, Miss = 3507 (0.52), PendingHit = 175 (0.0259)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6781, Miss = 3431 (0.506), PendingHit = 145 (0.0214)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6581, Miss = 3485 (0.53), PendingHit = 161 (0.0245)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6501, Miss = 3524 (0.542), PendingHit = 162 (0.0249)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6220, Miss = 3323 (0.534), PendingHit = 140 (0.0225)
total_dl1_misses=49155
total_dl1_accesses=90327
total_dl1_miss_rate= 0.544189
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 
distro:
877, 815, 753, 692, 629, 629, 598, 567, 536, 474, 474, 443, 443, 412, 412, 383, 319, 319, 288, 226, 226, 226, 195, 164, 102, 71, 
gpgpu_n_tot_thrd_icount = 5134880
gpgpu_n_tot_w_icount = 160465
gpgpu_n_icache_hits = 87254
gpgpu_n_icache_misses = 465
gpgpu_n_l1dcache_read_hits = 39233
gpgpu_n_l1dcache_read_misses = 51094
gpgpu_n_l1dcache_write_accesses = 5416
gpgpu_n_l1dcache_wirte_misses = 5416
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 25108
gpgpu_n_ccache_misses = 596
gpgpu_n_stall_shd_mem = 185129
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 49155
gpgpu_n_mem_write_global = 5416
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 334
gpgpu_n_load_insn  = 922550
gpgpu_n_store_insn = 23896
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 324144
gpgpu_n_param_mem_insn = 1318422
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 9248
gpgpu_stall_shd_mem[c_mem][bk_conf] = 9248
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 175881
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:84127	W0_Idle:42787	W0_Scoreboard:913767	W1:31	W2:21	W3:27	W4:19	W5:30	W6:7	W7:12	W8:7	W9:13	W10:6	W11:18	W12:69	W13:8	W14:20	W15:7	W16:0	W17:7	W18:15	W19:13	W20:7	W21:3	W22:1	W23:8	W24:7	W25:2	W26:7	W27:5	W28:9	W29:22	W30:21	W31:11	W32:160032
maxmrqlatency = 175 
maxdqlatency = 0 
maxmflatency = 552 
averagemflatency = 211 
max_icnt2mem_latency = 239 
max_icnt2sh_latency = 45462 
mrq_lat_table:8932 	327 	296 	441 	488 	305 	145 	18 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	1638 	38322 	14928 	17 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:50 	29428 	4833 	3545 	3564 	4178 	5798 	3579 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	4365 	7030 	35610 	2482 	2 	0 	0 	0 	0 	0 	0 	0 	0 	1890 	3526 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	80 	9 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        32        32        32         9        31        22        30        32        58        55        24        22        17        26        26 
dram[1]:        32        30        31        32        18        32        23        30        32        65        47        27        22        19        23        24 
dram[2]:        24        31        32        32        19        31        23        32        32        49        57        25        21        17        24        24 
dram[3]:        32        26        32        30        13        31        22        31        32        53        64        20        19        20        25        26 
dram[4]:        29        32        32        32        11        32        18        31        32        50        33        23        20        19        21        26 
maximum service time to same row:
dram[0]:      7758      9044      8616      9974     10048     12028     14156      7372     13184     12320      7354      8870      7890     10426      7582      7778 
dram[1]:      8136      9126      9148     10050     10754     12024     13358      7538     13218      8738      7712      8724      7804     10672      7723      7866 
dram[2]:      8284      8550      8894      9974     10052     12644     14412     10042     13814      7502      7782      8870      8026     11154      7424      7730 
dram[3]:      7905      8658      8802      9514     10102     12538     14122      9262     13716      7568      7590      9576      7906     11348      7344      7630 
dram[4]:      8200      8912      8757     10070     10112     12664     15208      8291     14066      7366      7570      9208      8150     11514      7398      7960 
average row accesses per activate:
dram[0]:  6.894737  7.529412  7.222222  4.000000  2.930233  6.736842  3.150000  6.736842  4.923077  5.303030  3.920000  4.903226  2.976744  2.909091  4.266667  4.923077 
dram[1]: 10.000000  6.842105  6.500000  3.368421  2.415094  4.923077  2.930233  5.565217  4.129032  5.656250  3.288136  4.305555  4.266667  3.459460  3.764706  4.266667 
dram[2]:  7.588235  6.190476  6.450000  4.413793  2.560000  5.565217  3.000000  5.818182  5.120000  6.518518  3.362069  4.727273  4.129032  2.782609  4.129032  5.333333 
dram[3]:  6.842105  6.190476  8.000000  3.878788  2.723404  4.571429  3.351351  4.740741  4.740741  7.458333  3.213115  4.933333  2.782609  3.657143  3.878788  4.413793 
dram[4]:  6.095238  5.652174  9.142858  4.740741  2.909091  5.818182  3.073171  5.565217  5.120000  6.518518  3.145161  6.040000  2.909091  3.200000  4.266667  4.571429 
average row locality = 10952/2522 = 4.342585
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       131       128       130       128       126       128       126       128       128       140       160       140       128       128       128       128 
dram[1]:       130       130       130       128       128       128       126       128       128       140       160       140       128       128       128       128 
dram[2]:       129       130       129       128       128       128       126       128       128       140       160       141       128       128       128       128 
dram[3]:       130       130       128       128       128       128       124       128       128       142       160       138       128       128       128       128 
dram[4]:       128       130       128       128       128       128       126       128       128       142       160       138       128       128       128       128 
total reads: 10528
bank skew: 160/124 = 1.29
chip skew: 2108/2104 = 1.00
number of total write accesses:
dram[0]:         0         0         0         0         0         0         0         0         0        35        36        12         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0        41        34        15         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0        36        35        15         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0        37        36        10         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0        34        35        13         0         0         0         0 
total reads: 424
min_bank_accesses = 0!
chip skew: 90/82 = 1.10
average mf latency per bank:
dram[0]:        355       323       382       316       321       305      1729      5666      6412       756       626       452       307       294       324       313
dram[1]:        322       377       362       322       304       291      1880      5696      6066       599       606       470       327       306       335       318
dram[2]:        283       365       307       285       291       296      1528      4865      5733       648       637       433       309       279       288       287
dram[3]:        356       340       282       283       284       289      1827      4757      5200       598       588       424       312       280       307       282
dram[4]:        294       338       302       287       293       291      1562      4987      5590       600       632       438       317       286       292       288
maximum mf latency per bank:
dram[0]:        507       461       508       473       495       500       516       517       519       431       475       441       481       477       523       479
dram[1]:        487       497       488       460       479       444       486       486       499       552       483       494       475       463       541       503
dram[2]:        423       422       434       413       431       436       464       512       540       445       460       430       477       433       433       432
dram[3]:        443       459       399       404       477       461       459       514       517       425       450       431       469       454       494       416
dram[4]:        423       426       445       447       424       448       500       508       506       515       472       460       478       468       448       460

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=68194 n_nop=62914 n_act=491 n_pre=475 n_req=2188 n_rd=4210 n_write=104 bw_util=0.1265
n_activity=30751 dram_eff=0.2806
bk0: 262a 67430i bk1: 256a 67433i bk2: 260a 67510i bk3: 256a 67517i bk4: 252a 67409i bk5: 256a 67501i bk6: 252a 67519i bk7: 256a 67489i bk8: 256a 67425i bk9: 280a 67332i bk10: 320a 67248i bk11: 280a 67175i bk12: 256a 66828i bk13: 256a 66358i bk14: 256a 64787i bk15: 256a 57651i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.224111
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=68194 n_nop=62827 n_act=526 n_pre=510 n_req=2198 n_rd=4216 n_write=115 bw_util=0.127
n_activity=31416 dram_eff=0.2757
bk0: 260a 67341i bk1: 260a 67434i bk2: 260a 67453i bk3: 256a 67306i bk4: 256a 67428i bk5: 256a 67417i bk6: 252a 67456i bk7: 256a 67485i bk8: 256a 67472i bk9: 280a 67376i bk10: 320a 67172i bk11: 280a 66976i bk12: 256a 66849i bk13: 256a 66340i bk14: 256a 64708i bk15: 256a 57130i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.2176
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=68194 n_nop=62879 n_act=500 n_pre=484 n_req=2193 n_rd=4214 n_write=117 bw_util=0.127
n_activity=31049 dram_eff=0.279
bk0: 258a 67383i bk1: 260a 67317i bk2: 258a 67336i bk3: 256a 67353i bk4: 256a 67367i bk5: 256a 67390i bk6: 252a 67412i bk7: 256a 67498i bk8: 256a 67534i bk9: 280a 67426i bk10: 320a 67389i bk11: 282a 67118i bk12: 256a 66887i bk13: 256a 66532i bk14: 256a 65270i bk15: 256a 57304i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=15 avg=0.169194
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=68194 n_nop=62869 n_act=514 n_pre=498 n_req=2187 n_rd=4208 n_write=105 bw_util=0.1265
n_activity=31525 dram_eff=0.2736
bk0: 260a 67401i bk1: 260a 67370i bk2: 256a 67462i bk3: 256a 67519i bk4: 256a 67388i bk5: 256a 67495i bk6: 248a 67493i bk7: 256a 67538i bk8: 256a 67468i bk9: 284a 67349i bk10: 320a 67376i bk11: 276a 67161i bk12: 256a 66923i bk13: 256a 66128i bk14: 256a 64857i bk15: 256a 57335i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=15 avg=0.186732
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=68194 n_nop=62906 n_act=496 n_pre=480 n_req=2186 n_rd=4208 n_write=104 bw_util=0.1265
n_activity=30983 dram_eff=0.2783
bk0: 256a 67386i bk1: 260a 67376i bk2: 256a 67496i bk3: 256a 67462i bk4: 256a 67325i bk5: 256a 67421i bk6: 252a 67533i bk7: 256a 67403i bk8: 256a 67550i bk9: 284a 67418i bk10: 320a 67206i bk11: 276a 67143i bk12: 256a 66946i bk13: 256a 66465i bk14: 256a 64646i bk15: 256a 57645i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.218054
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 11266, Miss = 2105 (0.187), PendingHit = 64 (0.00568)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 11192, Miss = 2108 (0.188), PendingHit = 64 (0.00572)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 10923, Miss = 2107 (0.193), PendingHit = 57 (0.00522)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 10817, Miss = 2104 (0.195), PendingHit = 55 (0.00508)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 10777, Miss = 2104 (0.195), PendingHit = 40 (0.00371)
L2 Cache Total Miss Rate = 0.192

icnt_total_pkts_mem_to_simt=252543
icnt_total_pkts_simt_to_mem=65196

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 28.0832
% Accepted packets = 0 at node 0 (avg = 0.0311752)
lat(1) = 28.0832;
thru(1,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.145823 0.145703 0.143327 0.141094 0.141083 0 0 0 0 ];
% latency change    = 1
% throughput change = 1
Traffic 1 Stat
%=================================
% Average latency = 16.778
% Accepted packets = 0 at node 14 (avg = 0.12076)
lat(2) = 16.778;
thru(2,:) = [ 0.205675 0.192939 0.199769 0.213242 0.213308 0.186615 0.208589 0.18711 0.192378 0.19879 0.194303 0.197349 0.19956 0.187858 0 0 0 0 0 0 0 0 0 ];
% latency change    = 0.673809
% throughput change = 0.741842
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 28.0832 (1 samples)
Traffic[0]class0Overall average accepted rate = 0.0311752 (1 samples)
Traffic[0]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 30729 4790 1108 505 655 464 389 381 687 598 447 332 329 219 232 221 378 197 336 153 244 156 209 100 180 86 208 108 159 79 128 68 140 55 142 59 148 63 111 51 103 60 120 44 117 41 90 38 94 48 92 38 85 48 95 36 81 34 96 38 75 41 66 37 94 43 87 36 73 26 69 35 79 30 73 30 81 31 62 33 77 33 68 30 70 31 71 25 73 18 72 22 56 25 52 28 67 18 46 20 68 26 46 18 50 21 59 21 59 28 63 21 58 21 46 21 52 20 60 22 40 25 46 42 64 24 47 24 58 27 58 23 71 16 60 20 46 18 65 20 66 18 66 21 54 13 55 10 51 10 59 18 59 17 62 12 58 18 46 17 47 16 47 13 50 13 52 21 53 15 49 17 50 10 46 12 39 15 48 17 36 18 47 18 43 15 40 14 42 24 52 10 45 9 45 13 41 14 44 9 49 7 49 16 42 17 45 8 47 14 55 12 37 9 33 10 47 7 54 15 54 14 45 17 38 7 34 12 33 5 34 6 43 17 30 17 35 7 54 9 34 13 39 7 35 7 40 3 36 11 16 12 35 9 33 6 23 8 30 5 23 6 27 8 27 3 27 8 26 7 24 6 34 4 25 4 15 4 27 9 19 4 24 5 27 5 20 4 15 1 28 4 23 7 17 1 23 4 24 1 14 2 19 8 19 3 29 2 20 2 16 0 10 1 12 3 16 1 8 0 7 3 10 1 8 3 7 0 5 2 10 0 9 0 6 0 6 0 6 0 4 0 4 0 8 0 7 0 1 0 3 0 1 1 4 0 6 3 2 0 0 3 3 4 3 1 1 1 0 0 2 1 1 0 4 1 2 0 0 0 2 0 1 0 0 1 3 0 0 0 0 1 0 0 2 0 0 0 0 0 0 0 1 1 1 0 1 1 1 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (54975 samples)
traffic_manager/hop_stats_freq = [ 0 54975 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 16.778 (1 samples)
Traffic[1]class0Overall average accepted rate = 0.12076 (1 samples)
Traffic[1]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 1371 170 133 156 3788 748 467 1020 2210 848 772 850 816 1125 679 17720 1455 1165 1267 1285 7712 725 535 595 583 3014 325 265 262 253 1170 110 114 91 98 440 58 36 50 40 177 35 21 22 30 63 9 12 11 8 22 7 5 5 5 5 2 3 1 5 3 0 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (54975 samples)
traffic_manager/hop_stats_freq = [ 0 54975 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 15 sec (15 sec)
gpgpu_simulation_rate = 329453 (inst/sec)
gpgpu_simulation_rate = 3030 (cycle/sec)

kernel '_Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i' transfer to GPU hardware scheduler
kernel_name = _Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i 
kernel_launch_uid = 2 
gpu_sim_cycle = 42399
gpu_sim_insn = 4941796
gpu_ipc =     116.5545
gpu_tot_sim_cycle = 87862
gpu_tot_sim_insn = 9883592
gpu_tot_ipc =     112.4900
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 88768
gpu_stall_icnt2sh    = 403160
gpu_total_sim_rate=308862
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12600, Miss = 7289 (0.578), PendingHit = 274 (0.0217)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12384, Miss = 6818 (0.551), PendingHit = 241 (0.0195)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12941, Miss = 7184 (0.555), PendingHit = 244 (0.0189)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12513, Miss = 7167 (0.573), PendingHit = 284 (0.0227)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12879, Miss = 7238 (0.562), PendingHit = 295 (0.0229)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12981, Miss = 6985 (0.538), PendingHit = 310 (0.0239)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12818, Miss = 7250 (0.566), PendingHit = 169 (0.0132)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12931, Miss = 6926 (0.536), PendingHit = 262 (0.0203)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12551, Miss = 6759 (0.539), PendingHit = 267 (0.0213)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13019, Miss = 7074 (0.543), PendingHit = 298 (0.0229)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13331, Miss = 7104 (0.533), PendingHit = 275 (0.0206)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13227, Miss = 7092 (0.536), PendingHit = 291 (0.022)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13225, Miss = 6860 (0.519), PendingHit = 328 (0.0248)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13254, Miss = 6976 (0.526), PendingHit = 361 (0.0272)
total_dl1_misses=98722
total_dl1_accesses=180654
total_dl1_miss_rate= 0.546470
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 
distro:
877, 815, 753, 692, 629, 629, 598, 567, 536, 474, 474, 443, 443, 412, 412, 383, 319, 319, 288, 226, 226, 226, 195, 164, 102, 71, 908, 847, 753, 691, 629, 629, 598, 567, 536, 505, 443, 443, 443, 412, 381, 350, 352, 319, 288, 257, 226, 226, 195, 165, 133, 71, 71, 
gpgpu_n_tot_thrd_icount = 10269760
gpgpu_n_tot_w_icount = 320930
gpgpu_n_icache_hits = 174508
gpgpu_n_icache_misses = 465
gpgpu_n_l1dcache_read_hits = 78033
gpgpu_n_l1dcache_read_misses = 102621
gpgpu_n_l1dcache_write_accesses = 10832
gpgpu_n_l1dcache_wirte_misses = 10832
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 50763
gpgpu_n_ccache_misses = 645
gpgpu_n_stall_shd_mem = 353824
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 98722
gpgpu_n_mem_write_global = 10832
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 379
gpgpu_n_load_insn  = 1845100
gpgpu_n_store_insn = 47792
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 648288
gpgpu_n_param_mem_insn = 2636844
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 9248
gpgpu_stall_shd_mem[c_mem][bk_conf] = 9248
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 344576
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:128965	W0_Idle:58290	W0_Scoreboard:1813099	W1:62	W2:42	W3:54	W4:38	W5:60	W6:14	W7:24	W8:14	W9:26	W10:12	W11:36	W12:138	W13:16	W14:40	W15:14	W16:0	W17:14	W18:30	W19:26	W20:14	W21:6	W22:2	W23:16	W24:14	W25:4	W26:14	W27:10	W28:18	W29:44	W30:42	W31:22	W32:320064
maxmrqlatency = 175 
maxdqlatency = 0 
maxmflatency = 571 
averagemflatency = 210 
max_icnt2mem_latency = 320 
max_icnt2sh_latency = 87861 
mrq_lat_table:17645 	639 	544 	767 	875 	434 	175 	21 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	3043 	77275 	29588 	27 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:50 	58161 	9906 	7322 	7621 	8401 	11304 	7236 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	8131 	13868 	72183 	4914 	5 	0 	0 	0 	0 	0 	0 	0 	0 	1890 	4209 	4733 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	158 	16 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        32        32        32        22        31        22        30        32        58        55        24        22        20        26        26 
dram[1]:        32        32        31        32        18        32        23        30        32        65        47        27        22        19        23        24 
dram[2]:        27        31        32        32        19        31        23        32        32        49        57        25        21        18        24        24 
dram[3]:        32        26        32        30        13        31        22        31        32        53        64        20        19        20        25        26 
dram[4]:        29        32        32        32        14        32        18        31        32        50        33        23        20        19        21        26 
maximum service time to same row:
dram[0]:      7758      9354      8616     10298     10260     12516     14156      9154     13184     12320      7354     14739      7890     10426      8348      7778 
dram[1]:      8136      9126      9148     10050     10754     12024     13918      9668     13218      9776      7712     11458      7804     10672      7723      7998 
dram[2]:      8328      8632      9089      9974     10096     12644     14412     10042     13814      7502      7782     14178      8026     11154      7706      8232 
dram[3]:      8265      8658      9152      9514     10102     12538     14460      9916     13716      7568      7590     15388      7906     11348      7430      7630 
dram[4]:      8200      8912      9130     10070     10112     13338     15208      9378     14066      7366      7570     15366      8150     11514      7614      7960 
average row accesses per activate:
dram[0]:  7.400000  6.918919  6.666667  3.657143  2.769231  5.120000  2.813953  5.600000  4.072727  4.414286  3.076923  4.117647  2.876405  2.976744  3.938462  4.654545 
dram[1]:  8.896552  7.371428  6.341464  3.368421  2.392523  4.830189  2.813953  4.869565  3.500000  4.876923  3.040984  3.763158  3.506849  3.240506  3.764706  4.338983 
dram[2]:  6.945946  5.733333  6.972973  4.491228  2.666667  5.120000  2.915663  6.054054  4.571429  5.372881  2.936000  3.776316  3.282051  2.752688  4.654545  4.491228 
dram[3]:  6.641026  5.777778  8.258064  3.506849  2.666667  4.571429  3.012658  4.480000  4.226415  6.037037  2.833333  4.312500  2.813187  3.011765  3.938462  4.571429 
dram[4]:  6.918919  5.531915  9.481482  4.338983  2.782609  5.120000  2.962963  4.392157  4.666667  5.416667  2.735294  5.072727  2.723404  3.084337  4.063492  4.129032 
average row locality = 21100/5274 = 4.000759
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       259       256       260       256       252       256       242       224       224       256       300       268       256       256       256       256 
dram[1]:       258       258       260       256       256       256       242       224       224       257       304       269       256       256       256       256 
dram[2]:       257       258       258       256       256       256       242       224       224       258       302       270       256       256       256       256 
dram[3]:       259       260       256       256       256       256       238       224       224       264       299       266       256       256       256       256 
dram[4]:       256       260       256       256       256       256       240       224       224       264       304       266       256       256       256       256 
total reads: 20418
bank skew: 304/224 = 1.36
chip skew: 4088/4077 = 1.00
number of total write accesses:
dram[0]:         0         0         0         0         0         0         0         0         0        53        60        12         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0        60        67        17         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0        59        65        17         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0        62        58        10         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0        61        68        13         0         0         0         0 
total reads: 682
min_bank_accesses = 0!
chip skew: 144/125 = 1.15
average mf latency per bank:
dram[0]:        346       325       373       318       333       311      1871      6727      7511       867       698       503       323       302       330       318
dram[1]:        324       343       353       318       316       296      1991      6517      6886       669       634       488       325       302       324       310
dram[2]:        289       327       308       288       297       297      1626      5562      6387       705       669       459       304       279       288       287
dram[3]:        325       320       284       282       288       283      1935      5402      5867       642       631       447       310       287       305       285
dram[4]:        294       311       302       288       288       289      1673      5614      6247       644       643       463       312       283       291       292
maximum mf latency per bank:
dram[0]:        507       477       514       499       529       500       516       517       519       508       495       494       484       477       523       479
dram[1]:        515       497       505       464       551       497       486       486       499       552       571       494       498       463       541       503
dram[2]:        461       456       450       434       459       442       464       512       540       467       461       430       477       433       460       432
dram[3]:        443       459       426       414       480       461       459       514       517       451       450       431       469       454       494       426
dram[4]:        451       426       445       447       424       482       500       508       506       515       502       460       478       468       451       460

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=131792 n_nop=121373 n_act=1054 n_pre=1038 n_req=4202 n_rd=8154 n_write=173 bw_util=0.1264
n_activity=60841 dram_eff=0.2737
bk0: 518a 130320i bk1: 512a 130417i bk2: 520a 130458i bk3: 512a 130488i bk4: 504a 130436i bk5: 512a 130465i bk6: 484a 130538i bk7: 448a 130439i bk8: 448a 130447i bk9: 512a 130264i bk10: 600a 129882i bk11: 536a 129800i bk12: 512a 129117i bk13: 512a 128227i bk14: 512a 125103i bk15: 512a 109252i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.165147
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=131792 n_nop=121269 n_act=1081 n_pre=1065 n_req=4232 n_rd=8176 n_write=201 bw_util=0.1271
n_activity=62023 dram_eff=0.2701
bk0: 516a 130084i bk1: 516a 130274i bk2: 520a 130495i bk3: 512a 130265i bk4: 512a 130415i bk5: 512a 130392i bk6: 484a 130435i bk7: 448a 130397i bk8: 448a 130380i bk9: 514a 130280i bk10: 608a 129986i bk11: 538a 129437i bk12: 512a 129244i bk13: 512a 128068i bk14: 512a 124942i bk15: 512a 109197i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.17303
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=131792 n_nop=121359 n_act=1035 n_pre=1019 n_req=4226 n_rd=8170 n_write=209 bw_util=0.1272
n_activity=61943 dram_eff=0.2705
bk0: 514a 130304i bk1: 516a 130262i bk2: 516a 130370i bk3: 512a 130417i bk4: 512a 130391i bk5: 512a 130310i bk6: 484a 130417i bk7: 448a 130429i bk8: 448a 130357i bk9: 516a 130160i bk10: 604a 130143i bk11: 540a 129805i bk12: 512a 129300i bk13: 512a 128486i bk14: 512a 125539i bk15: 512a 109558i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.134485
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=131792 n_nop=121333 n_act=1064 n_pre=1048 n_req=4212 n_rd=8164 n_write=183 bw_util=0.1267
n_activity=62208 dram_eff=0.2684
bk0: 518a 130288i bk1: 520a 130173i bk2: 512a 130414i bk3: 512a 130598i bk4: 512a 130355i bk5: 512a 130520i bk6: 476a 130417i bk7: 448a 130371i bk8: 448a 130403i bk9: 528a 130336i bk10: 598a 130130i bk11: 532a 129820i bk12: 512a 129426i bk13: 512a 127924i bk14: 512a 125289i bk15: 512a 109294i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.136108
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=131792 n_nop=121343 n_act=1045 n_pre=1029 n_req=4228 n_rd=8172 n_write=203 bw_util=0.1271
n_activity=61449 dram_eff=0.2726
bk0: 512a 130231i bk1: 520a 130268i bk2: 512a 130368i bk3: 512a 130399i bk4: 512a 130309i bk5: 512a 130403i bk6: 480a 130598i bk7: 448a 130424i bk8: 448a 130436i bk9: 528a 130208i bk10: 608a 129897i bk11: 532a 129598i bk12: 512a 129430i bk13: 512a 128237i bk14: 512a 125152i bk15: 512a 109663i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.161444
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 22478, Miss = 4077 (0.181), PendingHit = 69 (0.00307)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 22356, Miss = 4088 (0.183), PendingHit = 70 (0.00313)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 21864, Miss = 4085 (0.187), PendingHit = 64 (0.00293)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 21703, Miss = 4082 (0.188), PendingHit = 56 (0.00258)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 21602, Miss = 4086 (0.189), PendingHit = 44 (0.00204)
L2 Cache Total Miss Rate = 0.186

icnt_total_pkts_mem_to_simt=505929
icnt_total_pkts_simt_to_mem=130445

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 28.1336
% Accepted packets = 0 at node 0 (avg = 0.0334557)
lat(3) = 28.1336;
thru(3,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.155727 0.155904 0.153899 0.152106 0.151847 0 0 0 0 ];
% latency change    = 0.403629
% throughput change = 2.60955
Traffic 1 Stat
%=================================
% Average latency = 16.9787
% Accepted packets = 0 at node 14 (avg = 0.129921)
lat(4) = 16.9787;
thru(4,:) = [ 0.219515 0.204927 0.21955 0.2035 0.207934 0.221862 0.213902 0.218253 0.202132 0.215022 0.221225 0.217557 0.202073 0.22073 0 0 0 0 0 0 0 0 0 ];
% latency change    = 0.656988
% throughput change = 0.742492
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 28.1084 (2 samples)
Traffic[0]class0Overall average accepted rate = 0.0323155 (2 samples)
Traffic[0]class0Overall min accepted rate = 0 (2 samples)
traffic_manager/latency_stat_0_freq = [ 0 30425 4918 1218 557 694 379 396 375 569 528 424 308 350 288 344 218 432 196 340 190 266 142 239 149 223 107 158 80 163 80 144 76 152 88 119 71 129 66 139 68 114 69 110 56 98 46 108 54 105 47 93 52 89 29 79 34 93 43 80 33 73 39 77 23 78 40 72 36 73 33 75 29 73 46 63 29 72 38 53 25 66 33 60 37 45 32 64 29 63 28 69 17 55 21 66 23 64 24 69 18 48 26 46 17 45 30 58 22 50 25 38 24 57 24 57 21 56 21 51 21 62 26 57 22 66 23 52 16 58 22 47 16 53 11 56 23 59 23 50 25 57 20 46 21 62 18 54 17 53 26 47 21 50 19 60 15 46 16 54 21 62 20 42 30 45 20 37 8 47 16 48 15 46 15 28 19 33 23 55 18 47 20 41 13 35 13 46 12 46 15 39 17 51 19 40 17 43 11 47 11 40 16 26 12 46 18 46 13 28 8 29 9 50 9 42 7 34 9 34 14 36 17 47 13 35 8 50 10 40 8 36 14 39 10 31 12 44 14 41 14 52 9 42 4 42 7 35 5 31 6 32 11 38 6 35 7 39 8 28 6 33 4 23 9 19 6 28 8 21 4 19 4 20 3 24 6 24 6 24 6 20 5 27 4 20 4 19 4 16 4 23 4 22 3 25 6 19 5 14 5 22 5 14 7 17 1 14 4 13 2 9 1 15 4 13 3 7 5 22 0 9 1 17 2 16 3 14 2 8 3 9 3 8 2 10 1 6 1 10 1 7 0 8 0 4 1 3 0 5 0 6 0 6 3 6 0 6 0 7 1 11 1 8 1 7 2 4 1 0 0 2 0 2 0 4 0 1 0 0 0 1 0 1 0 3 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (110003 samples)
traffic_manager/hop_stats_freq = [ 0 110003 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 16.8784 (2 samples)
Traffic[1]class0Overall average accepted rate = 0.125341 (2 samples)
Traffic[1]class0Overall min accepted rate = 0 (2 samples)
traffic_manager/latency_stat_0_freq = [ 0 1230 118 82 137 3308 646 444 923 2193 791 777 697 809 1293 758 18634 1387 1144 1204 1394 8012 632 563 534 580 3085 282 260 235 263 1140 119 111 81 115 420 63 55 42 48 189 14 21 21 25 55 19 7 8 12 30 2 2 3 2 2 1 1 1 1 0 0 0 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (110003 samples)
traffic_manager/hop_stats_freq = [ 0 110003 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 32 sec (32 sec)
gpgpu_simulation_rate = 308862 (inst/sec)
gpgpu_simulation_rate = 2745 (cycle/sec)
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
