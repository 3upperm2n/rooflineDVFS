

        *** GPGPU-Sim Simulator Version 3.2.1  [build 15629] ***


               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim: Configuration options:

-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   20 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  4:128:24,L:R:m:N,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 64:64:2,L:R:f:N,A:2:32,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     4:128:4,L:R:f:N,A:2:32,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     32:128:4,L:L:m:N,A:32:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                32768 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_shader_cta                       8 # Maximum number of concurrent CTAs in shader (default 8)
-gpgpu_n_clusters                      14 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_size                   16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   16 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_operand_collector_num_units_sp                    6 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_sfu                    8 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (default = 13, anything else is off for now)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths        2,1,1,2,1,1,2 # Pipeline widths ID_OC_SP,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_SFU,OC_EX_MEM,EX_WB
-gpgpu_num_sp_units                     2 # Number of SP units (default=1)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      lrr # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     64:128:16,L:B:m:W,A:32:4,4 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            5 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_mem_per_ctrlr                    2 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   16 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                    0 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=4:CCDL=3:RTPL=2 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-rop_latency                           60 # ROP queue latency (default 85)
-dram_latency                          50 # DRAM latency (default 30)
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.BBBBCCCC.CCSSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpuwattch_xml_file         gpuwattch.xml # GPUWattch XML file
-power_simulation_enabled                    1 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-power_trace_enabled                    1 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 300.0:600.0:300.0:900.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                    8 # maximum kernels that can run concurrently on GPU
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,19,25,145
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_initiation_int            1,2,2,1,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,4,4,32
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default fa4711d8f206ab718df3da419504ff2e  /tmp/tmp.NQ3n89cnHX/spmv__SIZE1_1
1,1,1,1,5
-ptx_opcode_initiation_dp         8,16,8,8,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    3 # column to column delay between accesses to different bank groups
RTPL                                    2 # read to precharge delay between accesses to different bank groups
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 000000000000f000 	high:16 low:12
addr_dec_mask[ROW]   = 000000000fff0000 	high:28 low:16
addr_dec_mask[COL]   = 0000000000000fff 	high:12 low:0
addr_dec_mask[BURST] = 000000000000003f 	high:6 low:0
*** Initializing Memory Statistics ***
self exe links to: /tmp/tmp.NQ3n89cnHX/spmv__SIZE1_1
Running md5sum using "md5sum /tmp/tmp.NQ3n89cnHX/spmv__SIZE1_1 "
Running cuobjdump using "$CUDA_INSTALL_PATH/bin/cuobjdump -ptx -elf -sass /tmp/tmp.NQ3n89cnHX/spmv__SIZE1_1 > _cuobjdump_complete_output_uolmvX"
Parsing file _cuobjdump_complete_output_uolmvX
######### cuobjdump parser ########
## Adding new section PTX
Adding ptx filename: _cuobjdump_1.ptx
Adding arch: sm_13
Adding identifier: benchmarks/spmv/spmv.cu
## Adding new section ELF
Adding arch: sm_13
Adding identifier: benchmarks/spmv/spmv.cu
Done parsing!!!
Adding _cuobjdump_1.ptx with cubin handle 1
Running: cat _ptx_LUMBBa | sed 's/.version 1.5/.version 1.4/' | sed 's/, texmode_independent//' | sed 's/\(\.extern \.const\[1\] .b8 \w\+\)\[\]/\1\[1\]/' | sed 's/const\[.\]/const\[0\]/g' > _ptx2_K1VRHn
GPGPU-Sim PTX registering constant jds_ptr_int (20000 bytes) to name mapping
GPGPU-Sim PTX registering constant sh_zcnt_int (20000 bytes) to name mapping
CUDA accelerated sparse matrix vector multiplication****
Original version by Li-Wen Chang <lchang20@illinois.edu> and Shengzhao Wu<wu14@illinois.edu>
This version maintained by Chris Rodrigues  ***********
Input file /home/cnugteren/software/parboil-2.5/datasets/spmv/medium/input/bcsstk18.mtx
Converting COO to JDS format (11948x11948)
149090 matrix entries, warp size = 32, row padding align = 1, pack size = 1

Padding data....11968 rows, 374 groups
Allocating data space: 150144 entries (0.701993% padding)
Finished converting.
JDS format has 11968 columns, 49 rows.
nz_count_len = 374
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread

kernel '_Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i' transfer to GPU hardware scheduler
kernel_name = _Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i 
kernel_launch_uid = 1 
gpu_sim_cycle = 35902
gpu_sim_insn = 4941796
gpu_ipc =     137.6468
gpu_tot_sim_cycle = 35902
gpu_tot_sim_insn = 4941796
gpu_tot_ipc =     137.6468
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 67323
gpu_stall_icnt2sh    = 220854
gpu_total_sim_rate=308862
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6381, Miss = 3485 (0.546), PendingHit = 197 (0.0309)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6074, Miss = 3282 (0.54), PendingHit = 124 (0.0204)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6552, Miss = 3715 (0.567), PendingHit = 197 (0.0301)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6561, Miss = 3788 (0.577), PendingHit = 139 (0.0212)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6392, Miss = 3632 (0.568), PendingHit = 135 (0.0211)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6510, Miss = 3248 (0.499), PendingHit = 174 (0.0267)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6249, Miss = 3515 (0.562), PendingHit = 140 (0.0224)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6294, Miss = 3218 (0.511), PendingHit = 182 (0.0289)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6633, Miss = 3427 (0.517), PendingHit = 132 (0.0199)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6619, Miss = 3066 (0.463), PendingHit = 171 (0.0258)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6840, Miss = 3515 (0.514), PendingHit = 192 (0.0281)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6559, Miss = 3557 (0.542), PendingHit = 147 (0.0224)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6297, Miss = 3452 (0.548), PendingHit = 116 (0.0184)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6366, Miss = 3200 (0.503), PendingHit = 189 (0.0297)
total_dl1_misses=48100
total_dl1_accesses=90327
total_dl1_miss_rate= 0.532510
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 
distro:
877, 815, 753, 692, 629, 629, 598, 567, 567, 536, 536, 537, 443, 412, 412, 381, 257, 226, 226, 226, 226, 226, 195, 196, 133, 133, 102, 103, 71, 71, 
gpgpu_n_tot_thrd_icount = 5134880
gpgpu_n_tot_w_icount = 160465
gpgpu_n_icache_hits = 87254
gpgpu_n_icache_misses = 465
gpgpu_n_l1dcache_read_hits = 39992
gpgpu_n_l1dcache_read_misses = 50335
gpgpu_n_l1dcache_write_accesses = 5416
gpgpu_n_l1dcache_wirte_misses = 5416
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 25113
gpgpu_n_ccache_misses = 591
gpgpu_n_stall_shd_mem = 165784
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 48100
gpgpu_n_mem_write_global = 5416
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 332
gpgpu_n_load_insn  = 922550
gpgpu_n_store_insn = 23896
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 324144
gpgpu_n_param_mem_insn = 1318422
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 4534
gpgpu_stall_shd_mem[c_mem][bk_conf] = 4534
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 161250
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:71678	W0_Idle:23867	W0_Scoreboard:700848	W1:31	W2:21	W3:27	W4:19	W5:30	W6:7	W7:12	W8:7	W9:13	W10:6	W11:18	W12:69	W13:8	W14:20	W15:7	W16:0	W17:7	W18:15	W19:13	W20:7	W21:3	W22:1	W23:8	W24:7	W25:2	W26:7	W27:5	W28:9	W29:22	W30:21	W31:11	W32:160032
maxmrqlatency = 90 
maxdqlatency = 0 
maxmflatency = 506 
averagemflatency = 178 
max_icnt2mem_latency = 356 
max_icnt2sh_latency = 35901 
mrq_lat_table:9810 	203 	393 	406 	103 	17 	1 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	12286 	35096 	6466 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:45 	11999 	3841 	4079 	6384 	9096 	12617 	5782 	75 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	1541 	4462 	40512 	1917 	0 	0 	0 	0 	0 	0 	0 	0 	126 	4071 	1219 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	8 	62 	1 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        30        31        32        19        30        22        30        32        53        42        24        18        16        25        25 
dram[1]:        32        31        31        32        12        31        23        30        32        60        40        24        17        15        23        22 
dram[2]:        25        28        32        32        10        31        22        32        32        47        42        24        17        17        24        23 
dram[3]:        31        24        30        30        10        24        21        31        32        51        52        20        17        14        23        26 
dram[4]:        28        30        31        32        11        31        18        31        32        50        30        21        20        16        22        26 
maximum service time to same row:
dram[0]:      6616      7423      7216      8416      7988     10661     11777      6101     10586      9343      6108      7669      6480      8742      6349      6520 
dram[1]:      6297      7406      7557      7995      7858     10248     11494      5937     10811      7219      5838      7595      5889      8682      6041      6409 
dram[2]:      6782      7315      7429      8317      8286     11117     12017      8498     11286      6676      5723      7734      5981      8912      6241      6678 
dram[3]:      6881      7419      7227      8059      8361     10395     12155      7351     11483      5551      6100      8151      6636      9092      6004      6927 
dram[4]:      6404      7366      6997      8428      8451     11163     12441      7097     11701      5858      6062      7815      6308      9167      5929      6572 
average row accesses per activate:
dram[0]:  6.238095  5.565217  5.416667  3.764706  2.571429  4.571429  2.739130  5.565217  4.266667  5.896552  2.814286  4.000000  2.723404  2.666667  4.000000  4.923077 
dram[1]:  6.842105  6.842105  5.416667  4.000000  2.245614  4.740741  2.800000  5.565217  4.000000  6.103448  2.924242  3.897436  2.415094  2.666667  3.200000  4.000000 
dram[2]:  5.608696  5.200000  7.166667  3.121951  2.844445  6.095238  3.000000  7.111111  4.129032  6.444445  3.196721  4.078948  2.415094  2.509804  3.200000  4.000000 
dram[3]:  4.851852  5.652174  5.333333  3.121951  2.612245  4.413793  3.351351  5.333333  5.120000  6.068965  2.909091  3.700000  3.047619  2.844445  4.571429  3.764706 
dram[4]:  6.736842  5.200000  9.142858  4.413793  2.612245  4.000000  2.423077  4.923077  4.571429  5.028572  2.785714  4.750000  3.047619  2.723404  3.047619  4.923077 
average row locality = 10933/2850 = 3.836140
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       131       128       130       128       126       128       126       128       128       140       161       140       128       128       128       128 
dram[1]:       130       130       130       128       128       128       126       128       128       140       160       140       128       128       128       128 
dram[2]:       129       130       129       128       128       128       126       128       128       140       160       141       128       128       128       128 
dram[3]:       131       130       128       128       128       128       124       128       128       142       160       138       128       128       128       128 
dram[4]:       128       130       128       128       128       128       126       128       128       142       160       139       128       128       128       128 
total reads: 10531
bank skew: 161/124 = 1.30
chip skew: 2108/2105 = 1.00
number of total write accesses:
dram[0]:         0         0         0         0         0         0         0         0         0        31        36        12         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0        37        33        12         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0        34        35        14         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0        34        32        10         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0        34        35        13         0         0         0         0 
total reads: 402
min_bank_accesses = 0!
chip skew: 83/76 = 1.09
average mf latency per bank:
dram[0]:        260       249       297       240       257       225      1590      4930      5781       610       532       356       236       231       240       232
dram[1]:        248       275       282       241       237       226      1748      4865      5252       483       510       350       233       206       233       219
dram[2]:        204       247       220       203       210       203      1315      3922      4572       490       479       319       222       201       208       206
dram[3]:        271       268       219       230       222       222      1710      4352      4687       472       480       314       228       217       227       212
dram[4]:        211       254       213       209       202       203      1288      3998      4392       431       471       309       226       212       212       204
maximum mf latency per bank:
dram[0]:        378       443       428       407       458       386       399       414       419       349       433       457       390       374       386       417
dram[1]:        384       381       416       452       414       374       387       455       416       379       479       406       352       361       445       372
dram[2]:        338       338       336       297       351       351       381       398       406       348       385       351       356       333       372       346
dram[3]:        326       343       332       363       322       367       382       388       407       339       370       427       357       378       417       354
dram[4]:        387       309       309       350       365       364       399       394       407       338       369       505       370       506       403       324

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=107704 n_nop=102274 n_act=569 n_pre=553 n_req=2185 n_rd=4212 n_write=96 bw_util=0.08
n_activity=35701 dram_eff=0.2413
bk0: 262a 107001i bk1: 256a 107038i bk2: 260a 107115i bk3: 256a 107068i bk4: 252a 107125i bk5: 256a 107108i bk6: 252a 107009i bk7: 256a 106942i bk8: 256a 106978i bk9: 280a 106873i bk10: 322a 106945i bk11: 280a 106656i bk12: 256a 106496i bk13: 256a 106094i bk14: 256a 104563i bk15: 256a 95374i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=9 avg=0.0572495
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=107704 n_nop=102228 n_act=587 n_pre=571 n_req=2190 n_rd=4216 n_write=102 bw_util=0.08018
n_activity=37747 dram_eff=0.2288
bk0: 260a 106968i bk1: 260a 107063i bk2: 260a 107165i bk3: 256a 107106i bk4: 256a 107148i bk5: 256a 107138i bk6: 252a 107085i bk7: 256a 107121i bk8: 256a 107073i bk9: 280a 106914i bk10: 320a 106914i bk11: 280a 106771i bk12: 256a 106617i bk13: 256a 105951i bk14: 256a 104768i bk15: 256a 94321i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=8 avg=0.0632103
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=107704 n_nop=102260 n_act=567 n_pre=551 n_req=2190 n_rd=4214 n_write=112 bw_util=0.08033
n_activity=36428 dram_eff=0.2375
bk0: 258a 106919i bk1: 260a 107155i bk2: 258a 107207i bk3: 256a 107028i bk4: 256a 107081i bk5: 256a 107120i bk6: 252a 107132i bk7: 256a 107018i bk8: 256a 107008i bk9: 280a 106921i bk10: 320a 106819i bk11: 282a 106735i bk12: 256a 106586i bk13: 256a 105979i bk14: 256a 104429i bk15: 256a 95106i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=6 avg=0.05257
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=107704 n_nop=102289 n_act=564 n_pre=548 n_req=2181 n_rd=4210 n_write=93 bw_util=0.0799
n_activity=35831 dram_eff=0.2402
bk0: 262a 106962i bk1: 260a 107063i bk2: 256a 107089i bk3: 256a 107116i bk4: 256a 107166i bk5: 256a 107181i bk6: 248a 107051i bk7: 256a 107109i bk8: 256a 107031i bk9: 284a 107019i bk10: 320a 106970i bk11: 276a 106680i bk12: 256a 106368i bk13: 256a 106078i bk14: 256a 104688i bk15: 256a 95041i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=6 avg=0.0412984
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=107704 n_nop=102269 n_act=568 n_pre=552 n_req=2187 n_rd=4210 n_write=105 bw_util=0.08013
n_activity=36140 dram_eff=0.2388
bk0: 256a 106968i bk1: 260a 107034i bk2: 256a 107086i bk3: 256a 107067i bk4: 256a 107086i bk5: 256a 107027i bk6: 252a 107051i bk7: 256a 107042i bk8: 256a 107008i bk9: 284a 106814i bk10: 320a 106747i bk11: 278a 106602i bk12: 256a 106602i bk13: 256a 106199i bk14: 256a 104799i bk15: 256a 94987i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=11 avg=0.063266
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 10996, Miss = 2106 (0.192), PendingHit = 44 (0.004)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 11008, Miss = 2108 (0.191), PendingHit = 51 (0.00463)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 10704, Miss = 2107 (0.197), PendingHit = 30 (0.0028)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 10697, Miss = 2105 (0.197), PendingHit = 35 (0.00327)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 10513, Miss = 2105 (0.2), PendingHit = 40 (0.0038)
L2 Cache Total Miss Rate = 0.195

icnt_total_pkts_mem_to_simt=247262
icnt_total_pkts_simt_to_mem=64139

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 58.1487
% Accepted packets = 0 at node 0 (avg = 0.0388381)
lat(1) = 58.1487;
thru(1,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.1809 0.181945 0.178449 0.177001 0.174981 0 0 0 0 ];
% latency change    = 1
% throughput change = 1
Traffic 1 Stat
%=================================
% Average latency = 17.7691
% Accepted packets = 0 at node 14 (avg = 0.149725)
lat(2) = 17.7691;
thru(2,:) = [ 0.249575 0.234241 0.265619 0.270786 0.258893 0.233002 0.251372 0.23023 0.245383 0.220607 0.252277 0.2547 0.247793 0.229186 0 0 0 0 0 0 0 0 0 ];
% latency change    = 2.27246
% throughput change = 0.740603
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 58.1487 (1 samples)
Traffic[0]class0Overall average accepted rate = 0.0388381 (1 samples)
Traffic[0]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 17369 3196 958 441 552 322 470 352 505 315 443 305 382 246 395 313 560 323 501 266 440 276 409 232 373 201 338 199 306 172 293 121 298 144 268 153 279 137 259 120 252 122 238 104 247 121 214 130 238 114 247 115 245 108 254 101 206 107 217 88 208 96 213 75 198 86 209 80 170 94 222 93 178 73 162 69 169 73 166 72 145 71 150 63 155 77 162 75 150 57 154 58 156 72 152 62 162 60 146 57 131 42 148 50 136 55 132 56 145 49 132 40 117 54 116 72 137 54 132 56 137 59 136 51 126 58 114 39 144 54 106 38 119 48 97 39 119 42 113 44 131 39 117 49 119 49 102 44 134 45 121 44 126 35 122 37 83 35 109 38 110 47 89 32 83 36 125 39 107 36 99 41 94 34 94 31 108 38 87 26 78 23 92 33 101 32 98 24 106 23 81 29 67 27 81 35 75 27 92 38 84 37 92 23 82 26 87 15 73 18 71 24 74 24 77 29 82 32 82 25 66 19 69 32 76 29 64 25 61 22 78 25 83 24 86 18 62 24 76 17 65 26 75 21 60 15 69 19 75 18 79 28 75 15 59 19 53 14 71 20 54 10 51 6 50 13 45 16 53 10 40 9 52 16 44 8 40 6 25 7 41 9 44 8 29 9 38 12 40 5 27 10 39 4 30 5 24 2 27 2 22 5 33 6 18 5 28 7 29 10 33 6 37 4 24 7 19 3 17 2 19 7 16 6 23 4 9 4 19 6 19 3 21 6 21 8 13 4 16 6 12 2 11 4 15 3 8 3 9 2 11 4 16 1 10 3 13 4 4 1 8 2 9 0 12 1 9 3 6 0 8 0 7 0 4 0 2 2 6 0 4 0 6 0 4 2 0 0 3 2 2 0 2 2 4 1 2 1 6 0 1 0 5 0 1 0 1 0 3 0 3 0 3 0 1 0 0 0 1 0 4 0 2 0 3 0 0 0 1 0 2 0 1 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (53918 samples)
traffic_manager/hop_stats_freq = [ 0 53918 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 17.7691 (1 samples)
Traffic[1]class0Overall average accepted rate = 0.149725 (1 samples)
Traffic[1]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 937 70 69 99 1312 336 210 526 1414 626 482 562 641 889 732 21339 1760 1341 1329 1611 8888 731 622 640 611 3062 274 250 270 242 970 149 96 81 91 306 44 24 32 32 96 14 13 10 12 29 6 9 5 3 15 2 1 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (53918 samples)
traffic_manager/hop_stats_freq = [ 0 53918 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 16 sec (16 sec)
gpgpu_simulation_rate = 308862 (inst/sec)
gpgpu_simulation_rate = 2243 (cycle/sec)

kernel '_Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i' transfer to GPU hardware scheduler
kernel_name = _Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i 
kernel_launch_uid = 2 
gpu_sim_cycle = 35134
gpu_sim_insn = 4941796
gpu_ipc =     140.6557
gpu_tot_sim_cycle = 71036
gpu_tot_sim_insn = 9883592
gpu_tot_ipc =     139.1350
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 133135
gpu_stall_icnt2sh    = 443022
gpu_total_sim_rate=329453
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12650, Miss = 6919 (0.547), PendingHit = 357 (0.0282)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12047, Miss = 6741 (0.56), PendingHit = 259 (0.0215)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13064, Miss = 7271 (0.557), PendingHit = 365 (0.0279)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13096, Miss = 7486 (0.572), PendingHit = 316 (0.0241)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12928, Miss = 7478 (0.578), PendingHit = 274 (0.0212)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12923, Miss = 6782 (0.525), PendingHit = 320 (0.0248)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12840, Miss = 6826 (0.532), PendingHit = 296 (0.0231)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12586, Miss = 6667 (0.53), PendingHit = 349 (0.0277)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13146, Miss = 6852 (0.521), PendingHit = 250 (0.019)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13242, Miss = 6391 (0.483), PendingHit = 327 (0.0247)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13426, Miss = 7168 (0.534), PendingHit = 332 (0.0247)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13302, Miss = 7025 (0.528), PendingHit = 301 (0.0226)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12877, Miss = 6896 (0.536), PendingHit = 275 (0.0214)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12527, Miss = 6434 (0.514), PendingHit = 342 (0.0273)
total_dl1_misses=96936
total_dl1_accesses=180654
total_dl1_miss_rate= 0.536584
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 
distro:
877, 815, 753, 692, 629, 629, 598, 567, 567, 536, 536, 537, 443, 412, 412, 381, 257, 226, 226, 226, 226, 226, 195, 196, 133, 133, 102, 103, 71, 71, 877, 815, 753, 691, 629, 629, 598, 567, 505, 474, 443, 443, 443, 412, 381, 350, 319, 288, 288, 226, 226, 195, 196, 164, 71, 71, 
gpgpu_n_tot_thrd_icount = 10269760
gpgpu_n_tot_w_icount = 320930
gpgpu_n_icache_hits = 174508
gpgpu_n_icache_misses = 465
gpgpu_n_l1dcache_read_hits = 79355
gpgpu_n_l1dcache_read_misses = 101299
gpgpu_n_l1dcache_write_accesses = 10832
gpgpu_n_l1dcache_wirte_misses = 10832
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 50777
gpgpu_n_ccache_misses = 631
gpgpu_n_stall_shd_mem = 328634
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 96936
gpgpu_n_mem_write_global = 10832
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 370
gpgpu_n_load_insn  = 1845100
gpgpu_n_store_insn = 47792
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 648288
gpgpu_n_param_mem_insn = 2636844
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 4534
gpgpu_stall_shd_mem[c_mem][bk_conf] = 4534
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 324100
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:124137	W0_Idle:33916	W0_Scoreboard:1402865	W1:62	W2:42	W3:54	W4:38	W5:60	W6:14	W7:24	W8:14	W9:26	W10:12	W11:36	W12:138	W13:16	W14:40	W15:14	W16:0	W17:14	W18:30	W19:26	W20:14	W21:6	W22:2	W23:16	W24:14	W25:4	W26:14	W27:10	W28:18	W29:44	W30:42	W31:22	W32:320064
maxmrqlatency = 90 
maxdqlatency = 0 
maxmflatency = 516 
averagemflatency = 180 
max_icnt2mem_latency = 378 
max_icnt2sh_latency = 71035 
mrq_lat_table:19273 	291 	654 	643 	183 	17 	1 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	23777 	70728 	13632 	1 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:45 	22278 	7589 	7871 	12752 	17733 	27114 	12562 	264 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	3008 	9199 	81443 	3653 	3 	0 	0 	0 	0 	0 	0 	0 	126 	4071 	4574 	2061 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	16 	124 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        31        31        32        19        30        22        30        32        53        42        24        18        17        25        26 
dram[1]:        32        31        31        32        12        31        23        30        32        60        40        24        21        16        23        24 
dram[2]:        29        28        32        32        10        31        22        32        32        47        42        24        19        17        24        24 
dram[3]:        31        26        31        30        11        29        21        31        32        51        52        20        17        18        25        26 
dram[4]:        28        31        31        32        11        31        18        31        32        50        30        21        20        16        22        26 
maximum service time to same row:
dram[0]:      6616      7623      7216      8583      8440     10661     12993      7883     10586      9343      6108     12845      6658      8742      6349      6520 
dram[1]:      6505      7406      7557      8202      8715     10248     11494      8221     11078      8281      6288     12268      6359      8682      6041      6741 
dram[2]:      6782      7315      7429      8317      8286     11117     12017      8498     11520      6676      5745     12947      6306      8982      6285      6835 
dram[3]:      6940      7419      7310      8059      8361     10395     12596      8093     11862      5551      6100     13036      6636      9419      6114      6927 
dram[4]:      6652      7366      7243      8428      8451     11163     12683      7996     11701      5858      6062     12660      6308      9252      6188      6572 
average row accesses per activate:
dram[0]:  5.755556  6.243902  5.652174  3.764706  2.652632  5.120000  2.750000  5.333333  3.862069  4.457143  2.506944  3.636364  2.723404  2.612245  3.938462  4.491228 
dram[1]:  6.972973  6.615385  5.531915  3.764706  2.133333  4.413793  2.688889  5.333333  3.500000  4.656716  2.882812  3.500000  2.612245  2.723404  3.506849  4.000000 
dram[2]:  5.244898  5.265306  6.789474  3.710145  2.485437  5.333333  2.847059  5.209302  4.072727  5.237288  2.928000  3.364706  2.415094  2.585859  3.240506  4.413793 
dram[3]:  5.777778  5.531915  5.688889  3.324675  2.560000  4.000000  3.012658  4.571429  4.765957  5.229508  2.767442  3.493671  2.844445  2.813187  4.196721  4.129032 
dram[4]:  6.400000  5.306122  6.918919  4.654545  2.370370  4.000000  2.696629  4.307693  3.612903  4.623188  2.656934  4.375000  2.639175  2.782609  3.160494  4.338983 
average row locality = 21062/5738 = 3.670617
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       259       256       260       256       252       256       242       224       224       259       301       268       256       256       256       256 
dram[1]:       258       258       260       256       256       256       242       224       224       257       304       268       256       256       256       256 
dram[2]:       257       258       258       256       256       256       242       224       224       257       302       270       256       256       256       256 
dram[3]:       260       260       256       256       256       256       238       224       224       263       300       266       256       256       256       256 
dram[4]:       256       260       256       256       256       256       240       224       224       263       301       267       256       256       256       256 
total reads: 20418
bank skew: 304/224 = 1.36
chip skew: 4087/4081 = 1.00
number of total write accesses:
dram[0]:         0         0         0         0         0         0         0         0         0        53        60        12         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0        55        65        12         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0        52        64        16         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0        56        57        10         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0        56        63        13         0         0         0         0 
total reads: 644
min_bank_accesses = 0!
chip skew: 132/123 = 1.07
average mf latency per bank:
dram[0]:        261       246       287       240       256       222      1635      5700      6608       680       578       384       237       225       249       234
dram[1]:        252       260       275       242       247       228      1841      5871      6268       572       554       398       244       219       244       228
dram[2]:        206       232       224       211       214       212      1344      4536      5274       568       525       349       222       205       207       209
dram[3]:        255       253       225       229       221       219      1778      5055      5511       531       519       351       229       222       231       222
dram[4]:        214       233       208       205       205       205      1331      4671      5101       489       499       343       227       209       216       208
maximum mf latency per bank:
dram[0]:        493       443       462       461       458       425       462       466       458       419       433       457       407       395       441       436
dram[1]:        431       428       416       452       429       426       459       469       450       397       479       406       376       373       445       400
dram[2]:        363       350       386       329       356       351       381       398       406       373       385       351       356       356       372       346
dram[3]:        459       448       516       381       358       380       438       399       439       412       370       427       357       378       417       391
dram[4]:        462       468       354       384       365       364       399       426       417       382       378       505       381       506       474       458

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=213104 n_nop=202508 n_act=1139 n_pre=1123 n_req=4206 n_rd=8162 n_write=172 bw_util=0.07822
n_activity=71150 dram_eff=0.2343
bk0: 518a 211769i bk1: 512a 211783i bk2: 520a 211995i bk3: 512a 212019i bk4: 504a 211951i bk5: 512a 211984i bk6: 484a 211841i bk7: 448a 211752i bk8: 448a 211767i bk9: 518a 211529i bk10: 602a 211536i bk11: 536a 211138i bk12: 512a 210910i bk13: 512a 210178i bk14: 512a 207267i bk15: 512a 188024i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=14 avg=0.0460949
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=213104 n_nop=202424 n_act=1171 n_pre=1155 n_req=4219 n_rd=8174 n_write=180 bw_util=0.0784
n_activity=73449 dram_eff=0.2275
bk0: 516a 211626i bk1: 516a 211850i bk2: 520a 212089i bk3: 512a 211984i bk4: 512a 212118i bk5: 512a 212027i bk6: 484a 211955i bk7: 448a 211911i bk8: 448a 211824i bk9: 514a 211813i bk10: 608a 211515i bk11: 536a 211338i bk12: 512a 210827i bk13: 512a 209964i bk14: 512a 207009i bk15: 512a 186738i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=14 avg=0.0513364
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=213104 n_nop=202455 n_act=1151 n_pre=1135 n_req=4216 n_rd=8168 n_write=195 bw_util=0.07849
n_activity=71714 dram_eff=0.2332
bk0: 514a 211679i bk1: 516a 211925i bk2: 516a 212065i bk3: 512a 211853i bk4: 512a 211984i bk5: 512a 211981i bk6: 484a 212008i bk7: 448a 211810i bk8: 448a 211767i bk9: 514a 211734i bk10: 604a 211651i bk11: 540a 211277i bk12: 512a 210801i bk13: 512a 210022i bk14: 512a 206870i bk15: 512a 187381i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=12 avg=0.0412991
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=213104 n_nop=202529 n_act=1127 n_pre=1111 n_req=4206 n_rd=8166 n_write=171 bw_util=0.07824
n_activity=70820 dram_eff=0.2354
bk0: 520a 211789i bk1: 520a 211909i bk2: 512a 211919i bk3: 512a 211989i bk4: 512a 212028i bk5: 512a 212140i bk6: 476a 211935i bk7: 448a 211982i bk8: 448a 211768i bk9: 526a 211745i bk10: 600a 211569i bk11: 532a 211163i bk12: 512a 210830i bk13: 512a 210247i bk14: 512a 207148i bk15: 512a 187766i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=12 avg=0.0354334
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=213104 n_nop=202457 n_act=1155 n_pre=1139 n_req=4215 n_rd=8166 n_write=187 bw_util=0.07839
n_activity=72339 dram_eff=0.2309
bk0: 512a 211808i bk1: 520a 211866i bk2: 512a 211972i bk3: 512a 212119i bk4: 512a 212022i bk5: 512a 211947i bk6: 480a 211875i bk7: 448a 211809i bk8: 448a 211840i bk9: 526a 211586i bk10: 602a 211472i bk11: 534a 211118i bk12: 512a 211006i bk13: 512a 210240i bk14: 512a 207412i bk15: 512a 186934i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.0498254
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 22030, Miss = 4081 (0.185), PendingHit = 45 (0.00204)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 22077, Miss = 4087 (0.185), PendingHit = 54 (0.00245)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 21475, Miss = 4084 (0.19), PendingHit = 31 (0.00144)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 21463, Miss = 4083 (0.19), PendingHit = 36 (0.00168)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 21163, Miss = 4083 (0.193), PendingHit = 42 (0.00198)
L2 Cache Total Miss Rate = 0.189

icnt_total_pkts_mem_to_simt=496972
icnt_total_pkts_simt_to_mem=128650

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 70.2128
% Accepted packets = 0 at node 0 (avg = 0.0399173)
lat(3) = 70.2128;
thru(3,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.185395 0.18679 0.183303 0.181852 0.180756 0 0 0 0 ];
% latency change    = 0.746925
% throughput change = 2.75087
Traffic 1 Stat
%=================================
% Average latency = 17.7664
% Accepted packets = 0 at node 14 (avg = 0.154512)
lat(4) = 17.7664;
thru(4,:) = [ 0.249808 0.251274 0.258048 0.268964 0.279324 0.256867 0.241824 0.25069 0.249794 0.242251 0.265918 0.252939 0.250633 0.235448 0 0 0 0 0 0 0 0 0 ];
% latency change    = 2.952
% throughput change = 0.741656
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 64.1807 (2 samples)
Traffic[0]class0Overall average accepted rate = 0.0393777 (2 samples)
Traffic[0]class0Overall min accepted rate = 0 (2 samples)
traffic_manager/latency_stat_0_freq = [ 0 14844 2761 884 486 570 375 452 280 464 381 474 267 378 218 363 291 600 338 457 301 417 245 409 259 407 191 357 156 305 191 302 152 301 167 250 125 224 122 262 133 273 113 247 130 247 119 244 100 221 133 214 127 223 96 202 93 206 103 217 96 206 92 200 94 205 93 233 87 227 93 167 93 179 88 187 78 170 80 192 80 180 71 207 72 198 87 172 65 168 82 176 67 176 65 168 81 144 68 183 67 165 62 169 51 148 64 184 59 134 51 152 55 137 57 158 54 130 63 155 56 143 48 155 48 146 51 137 74 155 52 161 47 145 50 143 70 159 66 146 50 149 63 142 39 148 42 152 71 158 55 130 55 130 57 140 65 118 46 125 41 112 54 130 46 137 45 133 52 136 42 141 44 121 39 122 43 121 47 128 39 140 56 132 37 104 32 124 54 107 47 131 46 136 32 97 35 104 39 105 32 107 37 110 38 93 34 94 34 101 33 101 37 97 32 102 34 112 34 106 35 105 42 85 27 86 34 77 34 102 35 96 24 75 35 99 25 86 25 84 25 82 26 83 23 74 14 74 20 69 24 74 21 82 17 72 26 65 17 65 17 46 14 58 11 56 9 44 12 61 16 46 17 43 19 53 13 41 10 44 16 44 12 33 16 46 10 29 9 38 12 35 13 43 13 37 9 45 9 35 10 38 4 36 6 33 10 26 7 34 4 32 7 26 14 35 8 34 13 35 14 30 10 37 7 20 4 13 5 29 6 24 3 20 6 25 2 22 4 23 9 15 3 21 4 25 2 19 6 10 6 29 3 12 7 15 2 19 4 15 3 13 3 10 6 9 2 16 4 18 3 19 0 9 6 9 0 8 3 14 2 12 1 4 2 7 1 12 2 8 0 5 0 2 1 8 1 8 0 5 2 4 0 1 0 4 0 4 0 7 0 3 1 5 0 3 0 1 0 1 1 3 1 2 1 2 1 2 1 1 1 3 0 6 1 8 1 4 0 1 0 2 1 3 1 2 0 1 0 0 2 1 1 6 0 4 1 3 0 4 0 3 0 1 0 2 1 0 0 2 0 1 0 2 0 1 0 0 0 2 0 1 0 2 1 1 0 1 0 0 0 0 0 3 0 1 0 0 2 1 0 1 0 0 0 0 0 1 0 0 0 1 0 3 0 1 1 0 1 0 0 2 0 1 0 2 0 0 0 3 1 1 0 0 0 0 1 1 0 1 0 2 1 2 0 0 0 1 0 2 0 1 0 2 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (108208 samples)
traffic_manager/hop_stats_freq = [ 0 108208 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 17.7677 (2 samples)
Traffic[1]class0Overall average accepted rate = 0.152118 (2 samples)
Traffic[1]class0Overall min accepted rate = 0 (2 samples)
traffic_manager/latency_stat_0_freq = [ 0 779 48 40 76 1213 356 217 511 1440 811 523 530 630 1021 856 21449 1993 1165 1407 1846 8865 727 503 637 686 3057 284 192 247 279 934 110 65 95 97 281 39 34 25 32 80 9 6 11 17 27 2 3 4 3 7 1 3 2 1 0 0 0 0 0 6 0 0 0 1 0 0 0 4 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (108208 samples)
traffic_manager/hop_stats_freq = [ 0 108208 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 30 sec (30 sec)
gpgpu_simulation_rate = 329453 (inst/sec)
gpgpu_simulation_rate = 2367 (cycle/sec)
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
