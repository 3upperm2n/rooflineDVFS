

        *** GPGPU-Sim Simulator Version 3.2.1  [build 15629] ***


               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim: Configuration options:

-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   20 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  4:128:24,L:R:m:N,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 64:64:2,L:R:f:N,A:2:32,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     4:128:4,L:R:f:N,A:2:32,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     32:128:4,L:L:m:N,A:32:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                32768 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_shader_cta                       8 # Maximum number of concurrent CTAs in shader (default 8)
-gpgpu_n_clusters                      14 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_size                   16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   16 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_operand_collector_num_units_sp                    6 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_sfu                    8 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (default = 13, anything else is off for now)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths        2,1,1,2,1,1,2 # Pipeline widths ID_OC_SP,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_SFU,OC_EX_MEM,EX_WB
-gpgpu_num_sp_units                     2 # Number of SP units (default=1)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      lrr # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     64:128:16,L:B:m:W,A:32:4,4 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            5 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_mem_per_ctrlr                    2 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   16 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                    0 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=4:CCDL=3:RTPL=2 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-rop_latency                           60 # ROP queue latency (default 85)
-dram_latency                          50 # DRAM latency (default 30)
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.BBBBCCCC.CCSSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpuwattch_xml_file         gpuwattch.xml # GPUWattch XML file
-power_simulation_enabled                    1 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-power_trace_enabled                    1 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 300.0:600.0:300.0:900.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                    8 # maximum kernels that can run concurrently on GPU
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,19,25,145
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_initiation_int            1,2,2,1,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,4,4,32
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default b97c341c6e98e0200dad08463887e5d2  /tmp/tmp.QnsWkkfsZJ/syrk__SIZE1_1
1,1,1,1,5
-ptx_opcode_initiation_dp         8,16,8,8,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    3 # column to column delay between accesses to different bank groups
RTPL                                    2 # read to precharge delay between accesses to different bank groups
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 000000000000f000 	high:16 low:12
addr_dec_mask[ROW]   = 000000000fff0000 	high:28 low:16
addr_dec_mask[COL]   = 0000000000000fff 	high:12 low:0
addr_dec_mask[BURST] = 000000000000003f 	high:6 low:0
*** Initializing Memory Statistics ***
self exe links to: /tmp/tmp.QnsWkkfsZJ/syrk__SIZE1_1
Running md5sum using "md5sum /tmp/tmp.QnsWkkfsZJ/syrk__SIZE1_1 "
Running cuobjdump using "$CUDA_INSTALL_PATH/bin/cuobjdump -ptx -elf -sass /tmp/tmp.QnsWkkfsZJ/syrk__SIZE1_1 > _cuobjdump_complete_output_cIHlXe"
Parsing file _cuobjdump_complete_output_cIHlXe
######### cuobjdump parser ########
## Adding new section PTX
Adding ptx filename: _cuobjdump_1.ptx
Adding arch: sm_13
Adding identifier: benchmarks/syrk/syrk.cu
## Adding new section ELF
Adding arch: sm_13
Adding identifier: benchmarks/syrk/syrk.cu
Done parsing!!!
Adding _cuobjdump_1.ptx with cubin handle 1
Running: cat _ptx_aurqiH | sed 's/.version 1.5/.version 1.4/' | sed 's/, texmode_independent//' | sed 's/\(\.extern \.const\[1\] .b8 \w\+\)\[\]/\1\[1\]/' | sed 's/const\[.\]/const\[0\]/g' > _ptx2_YiDvD9

kernel '_Z11syrk_kernelffPfS_' transfer to GPU hardware scheduler
kernel_name = _Z11syrk_kernelffPfS_ 
kernel_launch_uid = 1 
gpu_sim_cycle = 94659997
gpu_sim_insn = 1488453632
gpu_ipc =      15.7242
gpu_tot_sim_cycle = 94659997
gpu_tot_sim_insn = 1488453632
gpu_tot_ipc =      15.7242
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 1280981
gpu_stall_icnt2sh    = 250933590
gpu_total_sim_rate=49104
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9602530 (0.987), PendingHit = 121364 (0.0125)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9602170 (0.987), PendingHit = 122409 (0.0126)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10134952 (0.987), PendingHit = 129057 (0.0126)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10135940 (0.987), PendingHit = 128739 (0.0125)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9599800 (0.986), PendingHit = 123746 (0.0127)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10135193 (0.987), PendingHit = 129580 (0.0126)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9605458 (0.987), PendingHit = 119177 (0.0122)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9603442 (0.987), PendingHit = 121080 (0.0124)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10132183 (0.986), PendingHit = 131298 (0.0128)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9603456 (0.987), PendingHit = 121272 (0.0125)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9605775 (0.987), PendingHit = 118719 (0.0122)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9603413 (0.987), PendingHit = 121268 (0.0125)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9603130 (0.987), PendingHit = 121480 (0.0125)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9601443 (0.987), PendingHit = 122299 (0.0126)
total_dl1_misses=136568885
total_dl1_accesses=138420224
total_dl1_miss_rate= 0.986625
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 
distro:
5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 
gpgpu_n_tot_thrd_icount = 1488977920
gpgpu_n_tot_w_icount = 46530560
gpgpu_n_icache_hits = 25362432
gpgpu_n_icache_misses = 1380
gpgpu_n_l1dcache_read_hits = 119851
gpgpu_n_l1dcache_read_misses = 138300373
gpgpu_n_l1dcache_write_accesses = 4202496
gpgpu_n_l1dcache_wirte_misses = 4194328
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 15936
gpgpu_n_ccache_misses = 448
gpgpu_n_stall_shd_mem = 1266433952
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 136568885
gpgpu_n_mem_write_global = 4202496
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 14
gpgpu_n_load_insn  = 537395200
gpgpu_n_store_insn = 268959744
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 1048576
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 0
gpgpu_stall_shd_mem[c_mem][bk_conf] = 0
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 1266433952
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:1957319234	W0_Idle:557080276	W0_Scoreboard:1499504	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:46530560
maxmrqlatency = 50 
maxdqlatency = 0 
maxmflatency = 423 
averagemflatency = 74 
max_icnt2mem_latency = 298 
max_icnt2sh_latency = 94659996 
mrq_lat_table:1437587 	3695 	48292 	8783 	609 	41 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	138996649 	1774066 	680 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:27 	131674438 	7756108 	1130665 	142793 	57465 	9590 	360 	5 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	20844936 	48673718 	64866188 	2184025 	32 	0 	0 	0 	0 	203 	135 	187 	341 	573 	1150 	2430 	5119 	12219 	24330 	48536 	97532 	192017 	384837 	
mf_lat_pw_table:771392 	1536204 	1125291 	0 	0 	0 	188987 	330 	1 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        36        40        28        12        33        16        26        38        28        47        30        47        36        41        60        25 
dram[1]:        36        36        28        14        33        16        26        38        28        51        30        48        42        48        55        20 
dram[2]:        34        35        28        14        32        16        27        36        28        57        27        50        50        50        53        21 
dram[3]:        36        50        28        14        33        16        26        39        28        42        30        58        50        45        46        21 
dram[4]:        34        33        28        15        32        16        24        41        28        54        25        54        30        46        51        21 
maximum service time to same row:
dram[0]:   2304701   2304744   2304620    459622   1410875   1410954    326972   2256545   2256637    443095    952968   1224968    273725   1368803   2155579   1368836 
dram[1]:   2304627   2304534   2304571    695151   1411046   1411054    327007   2256525   2279185    509031    952943   1224995    268553   1368928   2155565   1368854 
dram[2]:   2337614   2304586   2304617    710341   1410939   1410959    326961   2256495   2256433    476388    952976   1224968    413241   1368811   2155569   1368829 
dram[3]:   2304703   2304632   2304630    794354   1410960   1410926    382719   2256540   2256624    418181    984425   1224986    414053   1368815   2155579   1368836 
dram[4]:   2304543   2304587   2304613    672242   1410934   1410881    446619   2324696   2256433    438550   1224952   1224952    389101   1368755   2155565   1368825 
average row accesses per activate:
dram[0]:  2.002764  2.023655  1.941227  1.324774  2.046819  2.045823  1.294762  1.953391  1.991852  1.837987  1.783415  1.853497  1.818566  2.080799  1.998405  1.943441 
dram[1]:  2.004115  1.988757  1.944643  1.933493  2.073956  1.960351  1.293493  2.027021  2.004571  1.261795  1.783282  1.936290  1.846351  2.007039  2.015245  2.033478 
dram[2]:  1.942427  1.987504  1.992786  1.942432  1.986647  1.951439  1.811696  2.039450  1.947837  1.261905  1.862504  1.958693  1.294325  2.021519  2.125071  2.047244 
dram[3]:  1.999448  1.951595  1.930323  1.334509  2.046120  1.938462  1.305061  1.958552  2.001110  1.254849  1.782867  1.842576  1.840250  1.994665  2.020693  1.927794 
dram[4]:  1.932571  1.986575  1.944682  1.925618  1.967812  1.945996  1.308054  2.020931  1.944432  1.255993  1.783162  1.949310  1.270209  1.999367  2.013364  2.025198 
average row locality = 1499007/829450 = 1.807230
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:     17538     16271     17349     16122     16957     15991     17325     16619     17401     16812     22663     21059     22269     17048     17506     16446 
dram[1]:     17472     16235     17307     16363     16919     16306     17210     16567     17333     19321     22553     21439     22189     17408     17395     16708 
dram[2]:     17266     16262     17074     16307     16529     16260     17393     16533     17225     19252     22151     21262     20145     17387     17382     16756 
dram[3]:     17545     16598     17343     16494     16899     16374     17300     16889     17368     19792     22686     21904     22274     17606     17578     16874 
dram[4]:     16904     16259     16663     16365     16511     16315     16815     16602     16772     19419     21831     21424     19742     17474     17136     16779 
total reads: 1433820
bank skew: 22686/15991 = 1.42
chip skew: 291524/283011 = 1.03
number of total write accesses:
dram[0]:       575       582       619       594       705       662       645       690       689       829       714      1094       965      1288      1293       666 
dram[1]:       547       747       609       586       720       653       582       687       646       951       701      1264       907      1412      1244       664 
dram[2]:       548       757       606       530       729       618       637       682       699       888       728      1214      1113      1401      1359       664 
dram[3]:       576       658       609       529       714       636       595       689       654      1041       707      1388      1007      1461      1366       667 
dram[4]:       493       758       598       540       729       621       692       681       724       962       726      1303       984      1470      1244       662 
total reads: 65187
bank skew: 1470/493 = 2.98
chip skew: 13297/12610 = 1.05
average mf latency per bank:
dram[0]:       6808      7303      6878      7370      6939      7368      6880      7118      6816      7858      6952      7318      6751      6754      6586      7279
dram[1]:       6851      7253      6899      7263      6957      7252      6957      7153      6866      6851      6998      7156      6814      6585      6650      7193
dram[2]:       6919      7235      6989      7304      7099      7273      6854      7163      6885      6892      7106      7222      7384      6594      6612      7190
dram[3]:       6814      7148      6906      7249      6964      7227      6910      7024      6847      6775      6963      6979      6764      6504      6548      7133
dram[4]:       7089      7240      7168      7288      7113      7271      7071      7136      7053      6916      7209      7139      7438      6546      6744      7181
maximum mf latency per bank:
dram[0]:        311       276       338       316       276       276       311       269       285       327       271       280       342       396       393       423
dram[1]:        274       264       333       268       259       269       305       278       258       334       291       291       338       377       385       406
dram[2]:        246       238       285       258       283       271       271       246       294       291       313       267       370       363       368       395
dram[3]:        290       270       301       288       276       308       314       269       280       298       278       269       389       383       373       409
dram[4]:        243       263       311       283       261       272       303       277       316       314       268       291       404       399       384       421

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=283979989 n_nop=283059441 n_act=162296 n_pre=162280 n_req=297986 n_rd=570752 n_write=25220 bw_util=0.004197
n_activity=9078977 dram_eff=0.1313
bk0: 35076a 283928067i bk1: 32542a 283930019i bk2: 34698a 283930645i bk3: 32244a 283929026i bk4: 33914a 283932088i bk5: 31982a 283929623i bk6: 34650a 283927927i bk7: 33238a 283927977i bk8: 34802a 283928209i bk9: 33624a 283924858i bk10: 45326a 283925374i bk11: 42118a 283919576i bk12: 44538a 283898548i bk13: 34096a 283869331i bk14: 35012a 283570158i bk15: 32892a 279786900i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=14 avg=0.000891556
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=283979989 n_nop=283047893 n_act=164411 n_pre=164395 n_req=301645 n_rd=577450 n_write=25840 bw_util=0.004249
n_activity=9153281 dram_eff=0.1318
bk0: 34944a 283925248i bk1: 32470a 283929908i bk2: 34614a 283929343i bk3: 32726a 283928772i bk4: 33838a 283932323i bk5: 32612a 283930280i bk6: 34420a 283928405i bk7: 33134a 283928531i bk8: 34666a 283929830i bk9: 38642a 283926150i bk10: 45106a 283927306i bk11: 42878a 283919001i bk12: 44378a 283897128i bk13: 34816a 283868762i bk14: 34790a 283553952i bk15: 33416a 279731611i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=15 avg=0.000935855
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=283979989 n_nop=283057351 n_act=162970 n_pre=162954 n_req=298357 n_rd=570368 n_write=26346 bw_util=0.004203
n_activity=9079455 dram_eff=0.1314
bk0: 34532a 283930551i bk1: 32524a 283931900i bk2: 34148a 283931544i bk3: 32614a 283929413i bk4: 33058a 283934168i bk5: 32520a 283931628i bk6: 34786a 283930383i bk7: 33066a 283929821i bk8: 34450a 283931784i bk9: 38504a 283928274i bk10: 44302a 283928669i bk11: 42524a 283920035i bk12: 40290a 283901395i bk13: 34774a 283871609i bk14: 34764a 283548849i bk15: 33512a 279756099i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=15 avg=0.000918107
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=283979989 n_nop=283026193 n_act=172085 n_pre=172069 n_req=304821 n_rd=583048 n_write=26594 bw_util=0.004294
n_activity=9404231 dram_eff=0.1297
bk0: 35090a 283916161i bk1: 33196a 283926899i bk2: 34686a 283925292i bk3: 32988a 283925990i bk4: 33798a 283927916i bk5: 32748a 283922763i bk6: 34600a 283926008i bk7: 33778a 283923603i bk8: 34736a 283921515i bk9: 39584a 283918309i bk10: 45372a 283922083i bk11: 43808a 283915186i bk12: 44548a 283891195i bk13: 35212a 283866672i bk14: 35156a 283583670i bk15: 33748a 279562458i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=15 avg=0.000882178
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=283979989 n_nop=283052229 n_act=167690 n_pre=167674 n_req=296198 n_rd=566022 n_write=26374 bw_util=0.004172
n_activity=9189772 dram_eff=0.1289
bk0: 33808a 283918615i bk1: 32518a 283928909i bk2: 33326a 283929751i bk3: 32730a 283929509i bk4: 33022a 283931058i bk5: 32630a 283925949i bk6: 33630a 283928972i bk7: 33204a 283928457i bk8: 33544a 283926998i bk9: 38838a 283923478i bk10: 43662a 283926232i bk11: 42848a 283919691i bk12: 39484a 283896962i bk13: 34948a 283870065i bk14: 34272a 283589343i bk15: 33558a 279657657i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=15 avg=0.00086405
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28145645, Miss = 285376 (0.0101), PendingHit = 107037 (0.0038)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28147178, Miss = 288725 (0.0103), PendingHit = 104148 (0.0037)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28148002, Miss = 285184 (0.0101), PendingHit = 103868 (0.00369)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28180151, Miss = 291524 (0.0103), PendingHit = 107902 (0.00383)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28150475, Miss = 283011 (0.0101), PendingHit = 100220 (0.00356)
L2 Cache Total Miss Rate = 0.010

icnt_total_pkts_mem_to_simt=687047243
icnt_total_pkts_simt_to_mem=157581435

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 1.46989
% Accepted packets = 0 at node 0 (avg = 0.0361893)
lat(1) = 1.46989;
thru(1,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.166421 0.166429 0.166433 0.166603 0.166468 0 0 0 0 ];
% latency change    = 1
% throughput change = 1
Traffic 1 Stat
%=================================
% Average latency = 13.7183
% Accepted packets = 0 at node 14 (avg = 0.157784)
lat(2) = 13.7183;
thru(2,:) = [ 0.255167 0.255157 0.269315 0.269341 0.255095 0.269321 0.255244 0.255191 0.269242 0.255191 0.255252 0.25519 0.255183 0.255138 0 0 0 0 0 0 0 0 0 ];
% latency change    = 0.892851
% throughput change = 0.77064
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 1.46989 (1 samples)
Traffic[0]class0Overall average accepted rate = 0.0361893 (1 samples)
Traffic[0]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 116959188 14147893 1663192 1198788 2030980 847320 445331 1184654 906015 695225 301065 167260 77051 52813 30671 24484 14212 7726 3983 2625 1712 1061 812 453 428 201 308 146 255 82 197 70 195 74 192 58 141 37 155 42 156 51 139 37 127 32 107 32 127 41 104 38 102 36 102 35 98 19 96 42 108 26 88 40 89 30 78 39 95 28 91 29 68 28 85 29 77 26 72 26 70 31 74 26 76 42 60 22 53 20 61 26 59 20 57 13 52 15 39 15 46 13 23 14 32 16 28 11 33 16 22 7 34 12 16 8 21 10 17 9 19 10 15 8 24 5 13 6 11 4 15 4 15 4 13 5 10 2 10 4 6 1 11 2 10 2 4 2 4 4 11 1 2 0 7 0 7 2 2 2 3 1 4 2 4 0 0 3 1 4 2 0 3 1 3 1 3 3 3 1 3 1 9 1 6 1 4 0 2 0 2 0 4 0 0 3 1 0 1 1 3 0 2 0 1 1 1 0 1 0 0 0 4 1 0 0 0 0 1 0 1 1 2 2 1 0 1 0 2 2 1 0 0 0 0 0 0 1 0 2 2 1 1 0 0 1 2 2 2 0 0 0 0 2 3 3 0 4 2 0 3 0 1 1 3 0 2 1 0 0 3 0 1 1 2 2 0 0 1 0 0 0 3 1 1 1 1 1 0 1 2 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (140771451 samples)
traffic_manager/hop_stats_freq = [ 0 140771451 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 13.7183 (1 samples)
Traffic[1]class0Overall average accepted rate = 0.157784 (1 samples)
Traffic[1]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 707361 212527 183424 153732 14714573 6506344 3936415 7665080 9824666 6353753 6014550 5847099 5348567 5971493 4949874 25742482 4578005 3370669 3436203 3706239 8804244 1783133 1263860 1284398 1369988 2998948 627567 438128 420833 459519 946827 202363 134883 126305 135748 259449 57365 36510 33387 35675 64605 14543 8795 7598 8190 13568 2973 1735 1506 1544 2365 493 288 230 236 348 69 35 24 25 45 11 9 6 6 11 3 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (140771451 samples)
traffic_manager/hop_stats_freq = [ 0 140771451 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 8 hrs, 25 min, 12 sec (30312 sec)
gpgpu_simulation_rate = 49104 (inst/sec)
gpgpu_simulation_rate = 3122 (cycle/sec)
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
GPU Runtime: 30311.749023s
