

        *** GPGPU-Sim Simulator Version 3.2.1  [build 15629] ***


               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim: Configuration options:

-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   20 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  4:128:24,L:R:m:N,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 64:64:2,L:R:f:N,A:2:32,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     4:128:4,L:R:f:N,A:2:32,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     32:128:4,L:L:m:N,A:32:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                32768 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_shader_cta                       8 # Maximum number of concurrent CTAs in shader (default 8)
-gpgpu_n_clusters                      14 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_size                   16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   16 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_operand_collector_num_units_sp                    6 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_sfu                    8 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (default = 13, anything else is off for now)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths        2,1,1,2,1,1,2 # Pipeline widths ID_OC_SP,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_SFU,OC_EX_MEM,EX_WB
-gpgpu_num_sp_units                     2 # Number of SP units (default=1)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      lrr # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     64:128:16,L:B:m:W,A:32:4,4 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            5 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_mem_per_ctrlr                    2 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   16 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                    0 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=4:CCDL=3:RTPL=2 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-rop_latency                           80 # ROP queue latency (default 85)
-dram_latency                          67 # DRAM latency (default 30)
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.BBBBCCCC.CCSSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpuwattch_xml_file         gpuwattch.xml # GPUWattch XML file
-power_simulation_enabled                    1 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-power_trace_enabled                    1 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 400.0:800.0:400.0:900.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                    8 # maximum kernels that can run concurrently on GPU
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,19,25,145
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_initiation_int            1,2,2,1,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,4,4,32
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 2ee285fd08ab884b7e14442886e297be  /tmp/tmp.uALJMfwDpC/spmv__SIZE1_1
1,1,1,1,5
-ptx_opcode_initiation_dp         8,16,8,8,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    3 # column to column delay between accesses to different bank groups
RTPL                                    2 # read to precharge delay between accesses to different bank groups
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 000000000000f000 	high:16 low:12
addr_dec_mask[ROW]   = 000000000fff0000 	high:28 low:16
addr_dec_mask[COL]   = 0000000000000fff 	high:12 low:0
addr_dec_mask[BURST] = 000000000000003f 	high:6 low:0
*** Initializing Memory Statistics ***
self exe links to: /tmp/tmp.uALJMfwDpC/spmv__SIZE1_1
Running md5sum using "md5sum /tmp/tmp.uALJMfwDpC/spmv__SIZE1_1 "
Running cuobjdump using "$CUDA_INSTALL_PATH/bin/cuobjdump -ptx -elf -sass /tmp/tmp.uALJMfwDpC/spmv__SIZE1_1 > _cuobjdump_complete_output_O7GZ1M"
Parsing file _cuobjdump_complete_output_O7GZ1M
######### cuobjdump parser ########
## Adding new section PTX
Adding ptx filename: _cuobjdump_1.ptx
Adding arch: sm_13
Adding identifier: benchmarks/spmv/spmv.cu
## Adding new section ELF
Adding arch: sm_13
Adding identifier: benchmarks/spmv/spmv.cu
Done parsing!!!
Adding _cuobjdump_1.ptx with cubin handle 1
Running: cat _ptx_eYIfOf | sed 's/.version 1.5/.version 1.4/' | sed 's/, texmode_independent//' | sed 's/\(\.extern \.const\[1\] .b8 \w\+\)\[\]/\1\[1\]/' | sed 's/const\[.\]/const\[0\]/g' > _ptx2_NRjwAI
GPGPU-Sim PTX registering constant jds_ptr_int (20000 bytes) to name mapping
GPGPU-Sim PTX registering constant sh_zcnt_int (20000 bytes) to name mapping
CUDA accelerated sparse matrix vector multiplication****
Original version by Li-Wen Chang <lchang20@illinois.edu> and Shengzhao Wu<wu14@illinois.edu>
This version maintained by Chris Rodrigues  ***********
Input file /home/cnugteren/software/parboil-2.5/datasets/spmv/medium/input/bcsstk18.mtx
Converting COO to JDS format (11948x11948)
149090 matrix entries, warp size = 32, row padding align = 1, pack size = 1

Padding data....11968 rows, 374 groups
Allocating data space: 150144 entries (0.701993% padding)
Finished converting.
JDS format has 11968 columns, 49 rows.
nz_count_len = 374
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread

kernel '_Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i' transfer to GPU hardware scheduler
kernel_name = _Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i 
kernel_launch_uid = 1 
gpu_sim_cycle = 38952
gpu_sim_insn = 4941796
gpu_ipc =     126.8689
gpu_tot_sim_cycle = 38952
gpu_tot_sim_insn = 4941796
gpu_tot_ipc =     126.8689
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 59320
gpu_stall_icnt2sh    = 212679
gpu_total_sim_rate=329453
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6185, Miss = 3493 (0.565), PendingHit = 85 (0.0137)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6232, Miss = 3184 (0.511), PendingHit = 158 (0.0254)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6393, Miss = 3362 (0.526), PendingHit = 149 (0.0233)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6502, Miss = 3730 (0.574), PendingHit = 115 (0.0177)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6317, Miss = 3359 (0.532), PendingHit = 157 (0.0249)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6504, Miss = 3232 (0.497), PendingHit = 183 (0.0281)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6419, Miss = 3525 (0.549), PendingHit = 102 (0.0159)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6341, Miss = 3330 (0.525), PendingHit = 177 (0.0279)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6496, Miss = 3242 (0.499), PendingHit = 154 (0.0237)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6922, Miss = 3793 (0.548), PendingHit = 239 (0.0345)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 7051, Miss = 3201 (0.454), PendingHit = 212 (0.0301)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6067, Miss = 3289 (0.542), PendingHit = 164 (0.027)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6194, Miss = 3328 (0.537), PendingHit = 113 (0.0182)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 6704, Miss = 4083 (0.609), PendingHit = 144 (0.0215)
total_dl1_misses=48151
total_dl1_accesses=90327
total_dl1_miss_rate= 0.533074
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 
distro:
877, 815, 753, 692, 629, 629, 598, 567, 536, 505, 505, 474, 443, 412, 414, 381, 319, 288, 257, 257, 258, 226, 195, 195, 71, 71, 71, 71, 
gpgpu_n_tot_thrd_icount = 5134880
gpgpu_n_tot_w_icount = 160465
gpgpu_n_icache_hits = 87254
gpgpu_n_icache_misses = 464
gpgpu_n_l1dcache_read_hits = 40024
gpgpu_n_l1dcache_read_misses = 50303
gpgpu_n_l1dcache_write_accesses = 5416
gpgpu_n_l1dcache_wirte_misses = 5416
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 25110
gpgpu_n_ccache_misses = 594
gpgpu_n_stall_shd_mem = 171223
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 48151
gpgpu_n_mem_write_global = 5416
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 332
gpgpu_n_load_insn  = 922550
gpgpu_n_store_insn = 23896
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 324144
gpgpu_n_param_mem_insn = 1318422
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 5964
gpgpu_stall_shd_mem[c_mem][bk_conf] = 5964
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 165259
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:76093	W0_Idle:27135	W0_Scoreboard:767415	W1:31	W2:21	W3:27	W4:19	W5:30	W6:7	W7:12	W8:7	W9:13	W10:6	W11:18	W12:69	W13:8	W14:20	W15:7	W16:0	W17:7	W18:15	W19:13	W20:7	W21:3	W22:1	W23:8	W24:7	W25:2	W26:7	W27:5	W28:9	W29:22	W30:21	W31:11	W32:160032
maxmrqlatency = 69 
maxdqlatency = 0 
maxmflatency = 493 
averagemflatency = 188 
max_icnt2mem_latency = 295 
max_icnt2sh_latency = 38951 
mrq_lat_table:9486 	205 	343 	541 	280 	77 	5 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	11704 	33596 	8599 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:42 	18391 	4393 	4004 	5377 	6649 	10203 	4894 	16 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	2555 	5846 	37879 	2200 	3 	0 	0 	0 	0 	0 	0 	0 	0 	3361 	2055 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	6 	69 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        30        29        32        13        26        22        30        32        55        51        27        22        14        25        26 
dram[1]:        31        25        31        32        10        26        23        30        32        60        47        28        16        12        22        24 
dram[2]:        22        26        30        32        10        27        23        32        32        39        56        27        20        20        25        24 
dram[3]:        31        26        31        30        13        31        22        31        32        48        60        23        20        18        17        26 
dram[4]:        25        26        32        32        16        30        15        31        32        51        30        22        20        16        20        22 
maximum service time to same row:
dram[0]:      6988      8304      7718      9107      8570     10617     12395      6770     10912      9685      6199      7663      7360      8784      6545      7053 
dram[1]:      7285      7487      7707      8705      8758     11005     11943      6745     11758      7576      6897      7590      6596      8701      6494      6891 
dram[2]:      7322      7761      7603      8787      8722     11295     13334      8868     11864      6247      6722      8399      6749      9754      6348      6968 
dram[3]:      7159      7736      7812      8381      9541     10970     13077      8222     12580      6605      6525      8419      6625      9701      6236      7344 
dram[4]:      7037      7919      7314      8868      8450     11570     12854      6742     12554      6102      6547      7961      6785     10204      6614      7221 
average row accesses per activate:
dram[0]:  6.894737  6.095238  6.500000  4.266667  2.571429  4.740741  2.863636  4.740741  4.413793  5.242424  2.680556  4.189189  3.555556  2.723404  3.657143  4.000000 
dram[1]:  8.666667  6.190476  7.222222  4.266667  2.370370  4.266667  3.230769  6.400000  7.529412  6.068965  3.216667  4.000000  2.976744  2.560000  3.282051  4.571429 
dram[2]:  5.160000  4.814815  5.160000  4.413793  2.560000  4.266667  2.930233  5.818182  5.565217  6.444445  3.147541  3.511111  2.909091  2.909091  3.459460  3.764706 
dram[3]:  4.851852  5.652174  6.400000  3.657143  2.612245  4.571429  2.952381  4.740741  4.740741  6.730769  3.031250  4.870968  2.560000  2.844445  3.459460  3.555556 
dram[4]:  5.818182  5.200000  6.400000  4.740741  2.560000  4.266667  2.423077  3.878788  4.571429  5.057143  2.953846  5.357143  2.976744  2.782609  3.764706  4.740741 
average row locality = 10937/2788 = 3.922884
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       131       128       130       128       126       128       126       128       128       140       160       140       128       128       128       128 
dram[1]:       130       130       130       128       128       128       126       128       128       140       160       140       128       128       128       128 
dram[2]:       129       130       129       128       128       128       126       128       128       140       160       141       128       128       128       128 
dram[3]:       131       130       128       128       128       128       124       128       128       142       160       138       128       128       128       128 
dram[4]:       128       130       128       128       128       128       126       128       128       142       160       138       128       128       128       128 
total reads: 10529
bank skew: 160/124 = 1.29
chip skew: 2108/2104 = 1.00
number of total write accesses:
dram[0]:         0         0         0         0         0         0         0         0         0        33        33        15         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0        36        33        16         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0        34        32        17         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0        33        34        13         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0        35        32        12         0         0         0         0 
total reads: 408
min_bank_accesses = 0!
chip skew: 85/79 = 1.08
average mf latency per bank:
dram[0]:        302       260       318       249       269       250      1591      5055      5947       622       548       367       267       241       269       256
dram[1]:        272       309       315       265       277       242      1757      5259      5611       515       529       379       282       243       267       254
dram[2]:        226       282       245       231       232       220      1266      4019      4529       534       528       349       230       216       219       226
dram[3]:        311       297       257       238       255       231      1770      4378      4812       510       510       332       249       237       261       241
dram[4]:        251       292       242       236       218       246      1391      4368      4948       496       524       365       262       234       238       242
maximum mf latency per bank:
dram[0]:        437       425       451       402       387       410       407       424       493       416       443       395       403       398       386       425
dram[1]:        392       399       389       412       439       379       416       432       410       373       380       399       415       359       406       391
dram[2]:        343       340       360       352       348       355       404       413       401       371       369       340       360       329       340       377
dram[3]:        382       381       384       344       406       353       367       386       391       385       393       360       372       373       410       379
dram[4]:        365       394       389       472       418       413       409       432       414       388       388       376       453       386       382       367

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=87640 n_nop=82228 n_act=559 n_pre=543 n_req=2186 n_rd=4210 n_write=100 bw_util=0.09836
n_activity=33094 dram_eff=0.2605
bk0: 262a 86860i bk1: 256a 86969i bk2: 260a 87026i bk3: 256a 86908i bk4: 252a 86846i bk5: 256a 86977i bk6: 252a 86949i bk7: 256a 86983i bk8: 256a 86818i bk9: 280a 86848i bk10: 320a 86741i bk11: 280a 86574i bk12: 256a 86395i bk13: 256a 85844i bk14: 256a 84364i bk15: 256a 75989i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=13 avg=0.1021
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=87640 n_nop=82265 n_act=534 n_pre=518 n_req=2193 n_rd=4216 n_write=107 bw_util=0.09865
n_activity=33140 dram_eff=0.2609
bk0: 260a 86892i bk1: 260a 86954i bk2: 260a 87149i bk3: 256a 86979i bk4: 256a 86953i bk5: 256a 86891i bk6: 252a 86973i bk7: 256a 86835i bk8: 256a 86932i bk9: 280a 86831i bk10: 320a 86803i bk11: 280a 86730i bk12: 256a 86416i bk13: 256a 85827i bk14: 256a 84407i bk15: 256a 76265i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=10 avg=0.0856572
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=87640 n_nop=82196 n_act=567 n_pre=551 n_req=2190 n_rd=4214 n_write=112 bw_util=0.09872
n_activity=34215 dram_eff=0.2529
bk0: 258a 86822i bk1: 260a 86902i bk2: 258a 86904i bk3: 256a 86909i bk4: 256a 87110i bk5: 256a 87027i bk6: 252a 86971i bk7: 256a 87028i bk8: 256a 86946i bk9: 280a 86825i bk10: 320a 86896i bk11: 282a 86644i bk12: 256a 86282i bk13: 256a 85707i bk14: 256a 84238i bk15: 256a 75262i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=11 avg=0.084733
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=87640 n_nop=82211 n_act=568 n_pre=552 n_req=2185 n_rd=4210 n_write=99 bw_util=0.09833
n_activity=34030 dram_eff=0.2532
bk0: 262a 86861i bk1: 260a 86873i bk2: 256a 86961i bk3: 256a 87059i bk4: 256a 87019i bk5: 256a 86956i bk6: 248a 86946i bk7: 256a 86973i bk8: 256a 86886i bk9: 284a 86757i bk10: 320a 86824i bk11: 276a 86659i bk12: 256a 86473i bk13: 256a 85860i bk14: 256a 84301i bk15: 256a 75435i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=10 avg=0.0967937
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=87640 n_nop=82219 n_act=565 n_pre=549 n_req=2183 n_rd=4208 n_write=99 bw_util=0.09829
n_activity=33796 dram_eff=0.2549
bk0: 256a 86855i bk1: 260a 86829i bk2: 256a 86976i bk3: 256a 86936i bk4: 256a 86921i bk5: 256a 87022i bk6: 252a 87024i bk7: 256a 86926i bk8: 256a 86900i bk9: 284a 86889i bk10: 320a 86764i bk11: 276a 86714i bk12: 256a 86485i bk13: 256a 85917i bk14: 256a 84399i bk15: 256a 75458i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=11 avg=0.0894226
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 11005, Miss = 2105 (0.191), PendingHit = 58 (0.00527)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 11019, Miss = 2108 (0.191), PendingHit = 56 (0.00508)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 10673, Miss = 2107 (0.197), PendingHit = 41 (0.00384)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 10673, Miss = 2105 (0.197), PendingHit = 41 (0.00384)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 10599, Miss = 2104 (0.199), PendingHit = 44 (0.00415)
L2 Cache Total Miss Rate = 0.195

icnt_total_pkts_mem_to_simt=247517
icnt_total_pkts_simt_to_mem=64190

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 45.6827
% Accepted packets = 0 at node 0 (avg = 0.0358254)
lat(1) = 45.6827;
thru(1,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.166851 0.167839 0.164078 0.162833 0.162384 0 0 0 0 ];
% latency change    = 1
% throughput change = 1
Traffic 1 Stat
%=================================
% Average latency = 17.4751
% Accepted packets = 0 at node 14 (avg = 0.138143)
lat(2) = 17.4751;
thru(2,:) = [ 0.230392 0.209481 0.221573 0.245437 0.221355 0.213884 0.232484 0.219738 0.214231 0.25052 0.212536 0.21717 0.219622 0.268863 0 0 0 0 0 0 0 0 0 ];
% latency change    = 1.61416
% throughput change = 0.740664
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 45.6827 (1 samples)
Traffic[0]class0Overall average accepted rate = 0.0358254 (1 samples)
Traffic[0]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 22443 3850 1082 546 626 402 414 336 481 397 473 318 410 315 360 288 574 276 424 227 365 210 346 171 293 158 270 152 254 140 231 115 201 107 197 103 195 94 196 98 171 72 163 73 193 85 167 60 189 86 161 73 143 88 168 82 171 74 130 54 144 64 144 65 158 56 122 71 130 51 145 68 146 62 137 56 137 58 119 42 135 58 122 56 136 58 115 39 124 39 115 51 106 41 123 51 75 43 119 40 94 39 120 54 121 43 114 48 108 51 106 42 94 38 88 31 95 36 92 30 96 33 94 39 99 48 105 35 99 39 111 36 97 43 81 34 107 21 97 33 85 32 89 27 99 28 86 28 99 29 84 27 92 26 100 39 91 25 76 25 84 20 76 27 92 18 87 36 81 30 99 22 74 24 78 30 70 34 70 23 86 31 82 21 76 22 89 23 64 18 72 21 64 19 90 23 79 28 83 17 79 19 82 25 85 34 79 22 70 20 65 17 73 15 64 24 71 17 69 27 72 21 69 26 72 20 71 14 46 17 62 20 64 10 54 13 51 12 57 8 61 17 56 6 58 18 61 10 53 9 58 7 48 12 49 15 42 14 40 11 59 11 50 16 34 11 39 5 43 11 42 5 46 3 37 12 37 9 29 11 22 6 27 6 45 8 25 11 27 5 34 10 23 3 29 6 23 4 22 4 17 5 24 3 21 4 12 3 18 2 15 9 19 1 27 3 26 4 15 4 10 2 10 5 13 0 10 0 9 2 4 1 10 1 8 0 16 0 5 2 14 1 10 7 11 2 4 1 12 2 8 1 11 1 4 1 5 1 5 1 3 1 7 1 5 0 4 0 4 0 5 0 2 0 2 0 2 0 1 0 0 0 2 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 2 0 2 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 4 1 0 2 0 1 0 2 0 2 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (53969 samples)
traffic_manager/hop_stats_freq = [ 0 53969 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 17.4751 (1 samples)
Traffic[1]class0Overall average accepted rate = 0.138143 (1 samples)
Traffic[1]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 914 87 102 125 2178 498 330 722 2150 820 515 541 685 1103 797 19379 1472 1319 1342 1590 7966 814 602 622 689 3124 325 226 243 246 1107 122 82 107 102 393 38 34 76 42 122 23 21 12 7 48 4 10 8 14 30 5 4 2 3 10 5 2 3 1 2 0 0 1 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (53969 samples)
traffic_manager/hop_stats_freq = [ 0 53969 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 15 sec (15 sec)
gpgpu_simulation_rate = 329453 (inst/sec)
gpgpu_simulation_rate = 2596 (cycle/sec)

kernel '_Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i' transfer to GPU hardware scheduler
kernel_name = _Z14spmv_jds_naivePfPKfPKiS3_S1_S3_i 
kernel_launch_uid = 2 
gpu_sim_cycle = 37714
gpu_sim_insn = 4941796
gpu_ipc =     131.0335
gpu_tot_sim_cycle = 76666
gpu_tot_sim_insn = 9883592
gpu_tot_ipc =     128.9175
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 119853
gpu_stall_icnt2sh    = 424850
gpu_total_sim_rate=340813
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12702, Miss = 6945 (0.547), PendingHit = 266 (0.0209)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12237, Miss = 6634 (0.542), PendingHit = 335 (0.0274)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12730, Miss = 7020 (0.551), PendingHit = 359 (0.0282)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12888, Miss = 7334 (0.569), PendingHit = 241 (0.0187)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12562, Miss = 6799 (0.541), PendingHit = 324 (0.0258)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13158, Miss = 7017 (0.533), PendingHit = 296 (0.0225)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13055, Miss = 7113 (0.545), PendingHit = 266 (0.0204)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12571, Miss = 6719 (0.534), PendingHit = 266 (0.0212)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12906, Miss = 6744 (0.523), PendingHit = 261 (0.0202)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13487, Miss = 7172 (0.532), PendingHit = 376 (0.0279)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13725, Miss = 6715 (0.489), PendingHit = 368 (0.0268)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 13092, Miss = 6676 (0.51), PendingHit = 444 (0.0339)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12730, Miss = 6663 (0.523), PendingHit = 263 (0.0207)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 12811, Miss = 7361 (0.575), PendingHit = 297 (0.0232)
total_dl1_misses=96912
total_dl1_accesses=180654
total_dl1_miss_rate= 0.536451
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 
distro:
877, 815, 753, 692, 629, 629, 598, 567, 536, 505, 505, 474, 443, 412, 414, 381, 319, 288, 257, 257, 258, 226, 195, 195, 71, 71, 71, 71, 877, 815, 753, 691, 629, 629, 598, 567, 536, 505, 443, 443, 443, 412, 412, 350, 319, 319, 288, 257, 257, 226, 226, 228, 133, 133, 102, 71, 71, 71, 
gpgpu_n_tot_thrd_icount = 10269760
gpgpu_n_tot_w_icount = 320930
gpgpu_n_icache_hits = 174508
gpgpu_n_icache_misses = 464
gpgpu_n_l1dcache_read_hits = 79380
gpgpu_n_l1dcache_read_misses = 101274
gpgpu_n_l1dcache_write_accesses = 10832
gpgpu_n_l1dcache_wirte_misses = 10832
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 50763
gpgpu_n_ccache_misses = 645
gpgpu_n_stall_shd_mem = 336025
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 96912
gpgpu_n_mem_write_global = 10832
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 373
gpgpu_n_load_insn  = 1845100
gpgpu_n_store_insn = 47792
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 648288
gpgpu_n_param_mem_insn = 2636844
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 5964
gpgpu_stall_shd_mem[c_mem][bk_conf] = 5964
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 330061
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:128026	W0_Idle:40220	W0_Scoreboard:1529260	W1:62	W2:42	W3:54	W4:38	W5:60	W6:14	W7:24	W8:14	W9:26	W10:12	W11:36	W12:138	W13:16	W14:40	W15:14	W16:0	W17:14	W18:30	W19:26	W20:14	W21:6	W22:2	W23:16	W24:14	W25:4	W26:14	W27:10	W28:18	W29:44	W30:42	W31:22	W32:320064
maxmrqlatency = 69 
maxdqlatency = 0 
maxmflatency = 513 
averagemflatency = 189 
max_icnt2mem_latency = 407 
max_icnt2sh_latency = 76665 
mrq_lat_table:18684 	347 	554 	940 	420 	117 	5 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	22427 	68139 	17550 	1 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:42 	35004 	8760 	8181 	10983 	13802 	21052 	10296 	67 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	4998 	11856 	76455 	3973 	3 	0 	0 	0 	0 	0 	0 	0 	0 	3361 	3964 	3507 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	12 	138 	3 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        31        31        32        20        29        22        30        32        55        51        27        22        18        26        26 
dram[1]:        32        28        31        32        10        26        23        30        32        60        47        28        21        17        23        24 
dram[2]:        32        26        30        32        10        27        23        32        32        39        56        27        22        20        25        24 
dram[3]:        31        26        31        30        15        31        22        31        32        48        60        23        20        19        24        26 
dram[4]:        28        30        32        32        16        30        15        31        32        51        30        22        20        19        21        26 
maximum service time to same row:
dram[0]:      6988      8304      7718      9363      8708     11699     13006      7699     11472      9685      6626     13832      7360      9185      6582      7108 
dram[1]:      7285      7943      7707      8953      9641     11005     12130      8553     11758      8965      6897     13234      6596      9352      6494      6891 
dram[2]:      7322      7761      7785      8787      8722     11295     13334      8918     12057      6247      6722     13430      6749     10192      6531      6970 
dram[3]:      7159      7736      8153      8381      9541     11023     13077      8682     12580      6605      6525     13601      6794     10076      6577      7344 
dram[4]:      7055      7919      7854      8868      8450     11806     13438      8869     12554      6102      6547     13596      6785     10204      6614      7221 
average row accesses per activate:
dram[0]:  6.317073  6.918919  7.428571  4.740741  2.495049  4.654545  2.915663  4.480000  3.862069  4.753846  2.489362  4.042857  3.282051  2.534653  4.129032  3.938462 
dram[1]:  8.322580  5.733333  6.190476  4.129032  2.370370  4.830189  2.915663  5.743590  4.571429  5.114754  3.016260  3.688312  3.240506  2.485437  3.459460  4.266667 
dram[2]:  5.976744  5.058824  5.733333  3.938462  2.415094  4.000000  3.063291  5.209302  4.226415  5.147541  2.678832  3.372093  3.084337  2.844445  3.459460  3.878788 
dram[3]:  5.200000  5.098039  6.243902  3.605634  2.560000  4.491228  2.975000  4.480000  4.765957  5.350000  2.816000  3.821918  2.639175  3.047619  3.555556  3.657143 
dram[4]:  5.333333  6.023256  7.757576  4.196721  2.560000  4.196721  2.553191  3.862069  4.392157  4.563380  2.506944  5.245283  2.813187  2.782609  3.657143  4.000000 
average row locality = 21067/5593 = 3.766673
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       259       256       260       256       252       256       242       224       224       257       298       268       256       256       256       256 
dram[1]:       258       258       260       256       256       256       242       224       224       257       304       268       256       256       256       256 
dram[2]:       257       258       258       256       256       256       242       224       224       258       303       270       256       256       256       256 
dram[3]:       260       260       256       256       256       256       238       224       224       264       298       266       256       256       256       256 
dram[4]:       256       259       256       256       256       256       240       224       224       264       301       266       256       256       256       256 
total reads: 20413
bank skew: 304/224 = 1.36
chip skew: 4087/4076 = 1.00
number of total write accesses:
dram[0]:         0         0         0         0         0         0         0         0         0        52        53        15         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0        55        67        16         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0        56        64        20         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0        57        54        13         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0        60        60        12         0         0         0         0 
total reads: 654
min_bank_accesses = 0!
chip skew: 140/120 = 1.17
average mf latency per bank:
dram[0]:        294       262       302       254       270       251      1682      5908      6862       709       602       404       271       239       275       257
dram[1]:        278       290       300       265       277       251      1890      6114      6500       591       568       424       278       250       273       254
dram[2]:        237       264       247       237       240       233      1412      4804      5463       599       561       385       235       223       226       234
dram[3]:        280       277       255       244       257       233      1832      5049      5548       554       562       371       254       241       256       244
dram[4]:        244       264       234       232       222       235      1437      4850      5460       534       546       382       253       233       239       235
maximum mf latency per bank:
dram[0]:        437       425       451       421       513       439       455       460       498       425       443       415       408       398       499       425
dram[1]:        430       478       470       412       439       500       481       432       434       409       471       403       415       418       434       473
dram[2]:        376       351       372       361       393       369       404       413       443       398       456       394       388       351       342       378
dram[3]:        410       381       398       388       406       386       393       386       400       390       438       372       381       373       410       379
dram[4]:        446       455       389       472       418       413       421       432       414       428       412       382       453       386       420       367

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=172495 n_nop=162001 n_act=1097 n_pre=1081 n_req=4196 n_rd=8152 n_write=164 bw_util=0.09642
n_activity=65529 dram_eff=0.2538
bk0: 518a 170956i bk1: 512a 171149i bk2: 520a 171418i bk3: 512a 171208i bk4: 504a 171235i bk5: 512a 171361i bk6: 484a 171322i bk7: 448a 171330i bk8: 448a 171045i bk9: 514a 170947i bk10: 596a 170852i bk11: 536a 170492i bk12: 512a 170119i bk13: 512a 169120i bk14: 512a 166242i bk15: 512a 149105i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=15 avg=0.0746978
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=172495 n_nop=161964 n_act=1091 n_pre=1075 n_req=4225 n_rd=8174 n_write=191 bw_util=0.09699
n_activity=65697 dram_eff=0.2547
bk0: 516a 171146i bk1: 516a 171143i bk2: 520a 171559i bk3: 512a 171257i bk4: 512a 171287i bk5: 512a 171114i bk6: 484a 171292i bk7: 448a 170958i bk8: 448a 171152i bk9: 514a 170987i bk10: 608a 170912i bk11: 536a 170645i bk12: 512a 170094i bk13: 512a 169029i bk14: 512a 166327i bk15: 512a 148979i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=14 avg=0.0702339
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=172495 n_nop=161836 n_act=1147 n_pre=1131 n_req=4226 n_rd=8172 n_write=209 bw_util=0.09717
n_activity=67361 dram_eff=0.2488
bk0: 514a 170968i bk1: 516a 171099i bk2: 516a 171167i bk3: 512a 171168i bk4: 512a 171371i bk5: 512a 171287i bk6: 484a 171258i bk7: 448a 171417i bk8: 448a 171244i bk9: 516a 170999i bk10: 606a 170960i bk11: 540a 170662i bk12: 512a 169890i bk13: 512a 168975i bk14: 512a 165855i bk15: 512a 147784i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=14 avg=0.0708542
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=172495 n_nop=161919 n_act=1129 n_pre=1113 n_req=4206 n_rd=8164 n_write=170 bw_util=0.09663
n_activity=66605 dram_eff=0.2503
bk0: 520a 171029i bk1: 520a 171122i bk2: 512a 171293i bk3: 512a 171386i bk4: 512a 171230i bk5: 512a 171103i bk6: 476a 171194i bk7: 448a 171162i bk8: 448a 171076i bk9: 528a 170844i bk10: 596a 170863i bk11: 532a 170561i bk12: 512a 170391i bk13: 512a 169254i bk14: 512a 166079i bk15: 512a 148195i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=15 avg=0.0790342
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=172495 n_nop=161892 n_act=1134 n_pre=1118 n_req=4214 n_rd=8164 n_write=187 bw_util=0.09683
n_activity=66653 dram_eff=0.2506
bk0: 512a 170888i bk1: 518a 171104i bk2: 512a 171310i bk3: 512a 171305i bk4: 512a 171204i bk5: 512a 171257i bk6: 480a 171324i bk7: 448a 171233i bk8: 448a 171127i bk9: 528a 171004i bk10: 602a 170777i bk11: 532a 170772i bk12: 512a 170223i bk13: 512a 169192i bk14: 512a 166112i bk15: 512a 147925i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.0755442
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 22046, Miss = 4076 (0.185), PendingHit = 60 (0.00272)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 22045, Miss = 4087 (0.185), PendingHit = 60 (0.00272)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 21484, Miss = 4086 (0.19), PendingHit = 48 (0.00223)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 21394, Miss = 4082 (0.191), PendingHit = 42 (0.00196)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 21218, Miss = 4082 (0.192), PendingHit = 47 (0.00222)
L2 Cache Total Miss Rate = 0.189

icnt_total_pkts_mem_to_simt=496861
icnt_total_pkts_simt_to_mem=128629

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 51.3485
% Accepted packets = 0 at node 0 (avg = 0.037145)
lat(3) = 51.3485;
thru(3,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.172805 0.173442 0.171294 0.168814 0.167979 0 0 0 0 ];
% latency change    = 0.659675
% throughput change = 2.71902
Traffic 1 Stat
%=================================
% Average latency = 17.16
% Accepted packets = 0 at node 14 (avg = 0.143731)
lat(4) = 17.16;
thru(4,:) = [ 0.234428 0.233699 0.247435 0.243895 0.232692 0.256344 0.243497 0.229483 0.237504 0.229099 0.238459 0.230557 0.226686 0.222032 0 0 0 0 0 0 0 0 0 ];
% latency change    = 1.99233
% throughput change = 0.741566
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 48.5156 (2 samples)
Traffic[0]class0Overall average accepted rate = 0.0364852 (2 samples)
Traffic[0]class0Overall min accepted rate = 0 (2 samples)
traffic_manager/latency_stat_0_freq = [ 0 20844 3778 1107 546 588 440 467 346 523 404 464 307 415 292 342 299 538 267 400 220 319 183 334 176 305 168 285 157 288 145 240 137 227 130 212 140 229 90 198 102 204 97 206 118 214 82 181 92 165 72 152 63 177 93 156 73 162 76 146 84 180 69 159 76 151 66 173 54 149 60 147 79 132 46 142 50 146 59 146 69 146 61 134 46 127 54 132 46 114 51 133 53 128 52 145 45 132 54 114 50 109 38 120 34 121 54 105 53 121 47 108 39 104 47 106 40 104 45 98 43 96 44 110 41 114 35 82 42 107 38 102 43 85 32 82 36 111 40 106 46 108 49 115 32 109 42 101 39 101 38 110 33 93 32 104 30 85 28 85 33 91 26 84 28 98 32 100 29 81 34 85 37 82 27 84 38 103 45 98 35 85 24 96 26 80 30 81 37 81 36 88 29 96 30 86 30 80 26 70 23 79 20 89 27 79 24 79 22 88 38 67 24 86 35 75 20 74 23 69 41 70 23 62 25 59 30 85 24 65 22 58 11 63 16 65 19 68 15 62 20 55 14 60 17 52 23 45 9 61 13 45 13 49 8 29 10 45 20 36 12 35 21 38 13 33 14 29 9 41 12 27 13 38 10 29 11 38 14 35 16 34 9 44 10 30 16 30 6 32 10 37 12 28 4 32 12 29 17 25 8 25 4 23 10 25 6 19 7 16 7 15 5 18 8 27 8 18 5 18 7 22 3 13 6 18 3 9 5 18 4 12 4 15 3 12 9 18 6 19 7 24 7 11 3 21 4 8 2 14 2 11 3 5 2 8 4 11 1 9 3 11 2 6 3 8 3 8 3 8 5 7 3 6 1 7 1 4 2 4 1 7 1 8 0 3 3 6 3 7 1 6 0 4 1 4 4 7 0 4 1 5 2 2 2 0 0 4 0 4 0 6 0 4 2 4 0 4 0 2 2 3 1 1 0 0 0 2 0 2 0 1 1 3 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 0 1 0 3 0 3 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (108187 samples)
traffic_manager/hop_stats_freq = [ 0 108187 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 17.3176 (2 samples)
Traffic[1]class0Overall average accepted rate = 0.140937 (2 samples)
Traffic[1]class0Overall min accepted rate = 0 (2 samples)
traffic_manager/latency_stat_0_freq = [ 0 1015 103 80 127 2128 472 329 752 2016 838 619 692 624 1287 685 20252 1729 1110 1277 1674 8208 776 506 554 699 2783 282 253 204 217 893 133 72 89 92 279 44 31 25 42 100 20 12 12 11 28 1 8 7 4 12 1 0 1 2 1 2 2 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (108187 samples)
traffic_manager/hop_stats_freq = [ 0 108187 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 29 sec (29 sec)
gpgpu_simulation_rate = 340813 (inst/sec)
gpgpu_simulation_rate = 2643 (cycle/sec)
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
