

        *** GPGPU-Sim Simulator Version 3.2.1  [build 15629] ***


               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim: Configuration options:

-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   20 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  4:128:24,L:R:m:N,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 64:64:2,L:R:f:N,A:2:32,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     4:128:4,L:R:f:N,A:2:32,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     32:128:4,L:L:m:N,A:32:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                32768 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_shader_cta                       8 # Maximum number of concurrent CTAs in shader (default 8)
-gpgpu_n_clusters                      14 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_size                   16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   16 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_operand_collector_num_units_sp                    6 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_sfu                    8 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (default = 13, anything else is off for now)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths        2,1,1,2,1,1,2 # Pipeline widths ID_OC_SP,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_SFU,OC_EX_MEM,EX_WB
-gpgpu_num_sp_units                     2 # Number of SP units (default=1)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      lrr # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     64:128:16,L:B:m:W,A:32:4,4 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            5 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_mem_per_ctrlr                    2 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   16 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                    0 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=4:CCDL=3:RTPL=2 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-rop_latency                           80 # ROP queue latency (default 85)
-dram_latency                          67 # DRAM latency (default 30)
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.BBBBCCCC.CCSSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpuwattch_xml_file         gpuwattch.xml # GPUWattch XML file
-power_simulation_enabled                    1 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-power_trace_enabled                    1 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 400.0:800.0:400.0:900.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                    8 # maximum kernels that can run concurrently on GPU
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,19,25,145
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_initiation_int            1,2,2,1,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,4,4,32
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default fa1a0c47687516d69fb2694029588972  /tmp/tmp.YxNHz1BGbJ/syrk__SIZE1_1
1,1,1,1,5
-ptx_opcode_initiation_dp         8,16,8,8,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    3 # column to column delay between accesses to different bank groups
RTPL                                    2 # read to precharge delay between accesses to different bank groups
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 000000000000f000 	high:16 low:12
addr_dec_mask[ROW]   = 000000000fff0000 	high:28 low:16
addr_dec_mask[COL]   = 0000000000000fff 	high:12 low:0
addr_dec_mask[BURST] = 000000000000003f 	high:6 low:0
*** Initializing Memory Statistics ***
self exe links to: /tmp/tmp.YxNHz1BGbJ/syrk__SIZE1_1
Running md5sum using "md5sum /tmp/tmp.YxNHz1BGbJ/syrk__SIZE1_1 "
Running cuobjdump using "$CUDA_INSTALL_PATH/bin/cuobjdump -ptx -elf -sass /tmp/tmp.YxNHz1BGbJ/syrk__SIZE1_1 > _cuobjdump_complete_output_jDJr1w"
Parsing file _cuobjdump_complete_output_jDJr1w
######### cuobjdump parser ########
## Adding new section PTX
Adding ptx filename: _cuobjdump_1.ptx
Adding arch: sm_13
Adding identifier: benchmarks/syrk/syrk.cu
## Adding new section ELF
Adding arch: sm_13
Adding identifier: benchmarks/syrk/syrk.cu
Done parsing!!!
Adding _cuobjdump_1.ptx with cubin handle 1
Running: cat _ptx_6MrVbc | sed 's/.version 1.5/.version 1.4/' | sed 's/, texmode_independent//' | sed 's/\(\.extern \.const\[1\] .b8 \w\+\)\[\]/\1\[1\]/' | sed 's/const\[.\]/const\[0\]/g' > _ptx2_vYCpmR

kernel '_Z11syrk_kernelffPfS_' transfer to GPU hardware scheduler
kernel_name = _Z11syrk_kernelffPfS_ 
kernel_launch_uid = 1 
gpu_sim_cycle = 116650976
gpu_sim_insn = 1488453632
gpu_ipc =      12.7599
gpu_tot_sim_cycle = 116650976
gpu_tot_sim_insn = 1488453632
gpu_tot_ipc =      12.7599
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 2309497
gpu_stall_icnt2sh    = 105167081
gpu_total_sim_rate=34886
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9602341 (0.987), PendingHit = 122159 (0.0126)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9601840 (0.987), PendingHit = 122202 (0.0126)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9602712 (0.987), PendingHit = 121765 (0.0125)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9600706 (0.986), PendingHit = 123897 (0.0127)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9602737 (0.987), PendingHit = 121361 (0.0125)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10135607 (0.987), PendingHit = 129131 (0.0126)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9599727 (0.986), PendingHit = 124011 (0.0127)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9603688 (0.987), PendingHit = 121110 (0.0124)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9603016 (0.987), PendingHit = 121764 (0.0125)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10135508 (0.987), PendingHit = 129121 (0.0126)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10131870 (0.986), PendingHit = 132418 (0.0129)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10136178 (0.987), PendingHit = 128581 (0.0125)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9600511 (0.986), PendingHit = 124267 (0.0128)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9601387 (0.987), PendingHit = 123006 (0.0126)
total_dl1_misses=136557828
total_dl1_accesses=138420224
total_dl1_miss_rate= 0.986545
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 
distro:
5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 
gpgpu_n_tot_thrd_icount = 1488977920
gpgpu_n_tot_w_icount = 46530560
gpgpu_n_icache_hits = 25362432
gpgpu_n_icache_misses = 1374
gpgpu_n_l1dcache_read_hits = 117603
gpgpu_n_l1dcache_read_misses = 138302621
gpgpu_n_l1dcache_write_accesses = 4202496
gpgpu_n_l1dcache_wirte_misses = 4194336
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 15936
gpgpu_n_ccache_misses = 448
gpgpu_n_stall_shd_mem = 1561168801
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 136557828
gpgpu_n_mem_write_global = 4202496
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 14
gpgpu_n_load_insn  = 537395200
gpgpu_n_store_insn = 268959744
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 1048576
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 0
gpgpu_stall_shd_mem[c_mem][bk_conf] = 0
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 1561168801
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:-1877783391	W0_Idle:686582597	W0_Scoreboard:1753250	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:46530560
maxmrqlatency = 86 
maxdqlatency = 0 
maxmflatency = 504 
averagemflatency = 92 
max_icnt2mem_latency = 248 
max_icnt2sh_latency = 116650975 
mrq_lat_table:1317128 	7641 	7154 	49751 	2516 	131 	4 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	138288586 	2447228 	24524 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:27 	132717257 	6742645 	1030980 	121477 	101577 	42461 	3970 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	39799648 	59286096 	35700490 	1771592 	16 	0 	0 	0 	0 	179 	72 	182 	332 	525 	804 	1732 	3452 	9578 	19826 	39776 	79510 	155627 	315283 	
mf_lat_pw_table:626317 	1254080 	1695221 	0 	0 	0 	229050 	4248 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        28        58        36        17        63        18        30        54        28        53        19        54        43        41        62        25 
dram[1]:        28        53        38        16        36        18        27        34        28        52        20        57        47        59        60        26 
dram[2]:        28        48        34        15        56        22        27        50        28        52        22        57        45        52        58        26 
dram[3]:        29        49        38        16        59        20        29        44        28        48        23        47        49        45        56        26 
dram[4]:        28        39        34        20        59        20        27        41        28        44        22        51        38        54        60        26 
maximum service time to same row:
dram[0]:   2763274   2763278   2787361    655603   1683269   1683362    551284   2781099   2781187    568037   1372923   1455177    712001   1664173   2660881   1664181 
dram[1]:   2763119   2763025   2787330    871819   1683534   1663732    542400   2781089   2781059    603621   1372887   1324481    372937   1578410   2660872   1578340 
dram[2]:   2763024   2784072   2787341    859627   1683420   1683362    540342   2786465   2780943    586323   1372923    977604    355905   1578243   2660870   1578252 
dram[3]:   2855654   2763178   2787364    986848   1683369   1622694    533460   2781099   2781266    383814   1372889   1372902    712842   1578258   2660884   1578284 
dram[4]:   2763041   2763126   2787341   1000426   1683417   1622544    574419   2781085   2780978    561104   1664231   1664230    712094   1578189   2660870   1578252 
average row accesses per activate:
dram[0]:  1.987111  2.044265  1.938427  1.330389  2.074140  2.047505  1.295977  1.970563  2.004816  1.839959  1.767650  1.834094  1.811397  2.118902  2.036697  1.954750 
dram[1]:  1.997237  2.013672  1.935450  1.935207  2.086240  1.962054  1.292040  2.033380  2.017768  1.264559  1.778501  1.924599  1.834795  2.034515  2.049684  2.039855 
dram[2]:  1.942055  2.012298  1.979619  1.943106  2.000125  1.961036  1.805787  2.047601  1.952016  1.261204  1.854205  1.940074  1.294832  2.040231  2.161234  2.036403 
dram[3]:  1.989264  1.977309  1.935717  1.349138  2.075712  1.942741  1.301896  1.972327  2.008479  1.257671  1.767684  1.847837  1.816107  2.022329  2.052737  1.931321 
dram[4]:  1.945835  2.004052  1.923604  1.930788  1.978734  1.948243  1.310058  2.036804  1.951509  1.258431  1.772893  1.951472  1.274237  2.025831  2.038861  2.045109 
average row locality = 1384325/764068 = 1.811782
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:     16149     15065     16038     14813     15629     14760     15962     15337     15992     15502     20973     19428     20651     15737     16027     15061 
dram[1]:     16136     14988     16086     15026     15567     15043     15885     15240     15958     17791     20895     19797     20501     15971     15948     15236 
dram[2]:     16037     14938     15762     14930     15243     15008     16054     15176     15877     17668     20489     19718     18650     15975     15967     15250 
dram[3]:     16181     15335     16070     15230     15680     15085     15880     15523     15959     18258     21018     20304     20689     16242     16118     15472 
dram[4]:     15621     15028     15463     14892     15318     14981     15569     15230     15422     17810     20190     19874     18186     16074     15665     15287 
total reads: 1321588
bank skew: 21018/14760 = 1.42
chip skew: 269044/260610 = 1.03
number of total write accesses:
dram[0]:       501       637       553       549       765       627       598       662       658       789       709      1068       901      1246      1289       577 
dram[1]:       491       771       555       535       762       624       542       659       622       884       696      1210       845      1359      1214       579 
dram[2]:       486       770       556       473       790       594       608       654       680       849       699      1196      1069      1369      1338       581 
dram[3]:       495       699       552       505       797       624       533       656       623      1007       698      1312       959      1419      1359       585 
dram[4]:       473       800       551       479       779       603       660       653       676       923       700      1278       925      1415      1229       581 
total reads: 62737
bank skew: 1419/473 = 3.00
chip skew: 12823/12129 = 1.06
average mf latency per bank:
dram[0]:       9159      9695      9214      9899      9243      9853      9220      9528      9165     10510      9272      9789      8985      9012      8841      9845
dram[1]:       9178      9660      9184      9756      9284      9694      9297      9587      9199      9176      9311      9558      9088      8832      8923      9750
dram[2]:       9223      9686      9361      9855      9449      9724      9168      9626      9210      9251      9480      9593      9814      8823      8848      9762
dram[3]:       9154      9507      9221      9680      9201      9673      9303      9430      9204      9048      9264      9294      8963      8674      8766      9611
dram[4]:       9465      9612      9535      9883      9413      9754      9410      9589      9470      9293      9615      9483      9949      8752      9060      9727
maximum mf latency per bank:
dram[0]:        425       418       385       357       385       382       372       362       366       392       385       355       405       460       469       504
dram[1]:        336       364       437       372       346       350       354       346       351       445       400       348       413       484       483       500
dram[2]:        355       347       364       409       354       354       368       333       341       367       346       377       420       485       487       502
dram[3]:        368       388       381       401       361       413       392       372       372       385       367       358       420       425       484       503
dram[4]:        351       346       371       358       366       346       379       397       358       409       360       365       408       427       456       482

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=262464695 n_nop=261615209 n_act=149498 n_pre=149482 n_req=275253 n_rd=526248 n_write=24258 bw_util=0.004195
n_activity=8171545 dram_eff=0.1347
bk0: 32298a 262410683i bk1: 30130a 262415361i bk2: 32076a 262413634i bk3: 29626a 262412256i bk4: 31258a 262417018i bk5: 29520a 262413585i bk6: 31924a 262411784i bk7: 30674a 262412111i bk8: 31984a 262412610i bk9: 31004a 262409115i bk10: 41946a 262410835i bk11: 38856a 262400713i bk12: 41302a 262382193i bk13: 31474a 262358448i bk14: 32054a 262063265i bk15: 30122a 258669993i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.00102034
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=262464695 n_nop=261604971 n_act=151454 n_pre=151438 n_req=278416 n_rd=532136 n_write=24696 bw_util=0.004243
n_activity=8225038 dram_eff=0.1354
bk0: 32272a 262408221i bk1: 29976a 262414060i bk2: 32172a 262414329i bk3: 30052a 262414158i bk4: 31134a 262417126i bk5: 30086a 262414706i bk6: 31770a 262413747i bk7: 30480a 262413245i bk8: 31916a 262414827i bk9: 35582a 262409662i bk10: 41790a 262410606i bk11: 39594a 262402829i bk12: 41002a 262383118i bk13: 31942a 262357124i bk14: 31896a 262044321i bk15: 30472a 258616014i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.00108832
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=262464695 n_nop=261613211 n_act=150296 n_pre=150280 n_req=275454 n_rd=525484 n_write=25424 bw_util=0.004198
n_activity=8151417 dram_eff=0.1352
bk0: 32074a 262413199i bk1: 29876a 262415345i bk2: 31524a 262415710i bk3: 29860a 262414368i bk4: 30486a 262418346i bk5: 30016a 262416877i bk6: 32108a 262415370i bk7: 30352a 262415092i bk8: 31754a 262416112i bk9: 35336a 262411583i bk10: 40978a 262412165i bk11: 39436a 262405015i bk12: 37300a 262386054i bk13: 31950a 262359511i bk14: 31934a 262036649i bk15: 30500a 258636268i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.00109888
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=262464695 n_nop=261583749 n_act=158614 n_pre=158598 n_req=281867 n_rd=538088 n_write=25646 bw_util=0.004296
n_activity=8459154 dram_eff=0.1333
bk0: 32362a 262397177i bk1: 30670a 262409254i bk2: 32140a 262408516i bk3: 30460a 262409187i bk4: 31360a 262412327i bk5: 30170a 262406819i bk6: 31760a 262409342i bk7: 31046a 262408040i bk8: 31918a 262406179i bk9: 36516a 262402896i bk10: 42036a 262405910i bk11: 40608a 262398773i bk12: 41378a 262376878i bk13: 32484a 262355184i bk14: 32236a 262070753i bk15: 30944a 258473032i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.00102584
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=262464695 n_nop=261609625 n_act=154208 n_pre=154192 n_req=273335 n_rd=521220 n_write=25450 bw_util=0.004166
n_activity=8269026 dram_eff=0.1322
bk0: 31242a 262400479i bk1: 30056a 262413627i bk2: 30926a 262412889i bk3: 29784a 262413378i bk4: 30636a 262415253i bk5: 29962a 262410591i bk6: 31138a 262415091i bk7: 30460a 262413293i bk8: 30844a 262411959i bk9: 35620a 262407786i bk10: 40380a 262410130i bk11: 39748a 262402990i bk12: 36372a 262382452i bk13: 32148a 262358850i bk14: 31330a 262084556i bk15: 30574a 258554330i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.000969327
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28144541, Miss = 263124 (0.00935), PendingHit = 105797 (0.00376)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28146655, Miss = 266068 (0.00945), PendingHit = 103344 (0.00367)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28143740, Miss = 262742 (0.00934), PendingHit = 103062 (0.00366)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28179529, Miss = 269044 (0.00955), PendingHit = 106769 (0.00379)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28145929, Miss = 260610 (0.00926), PendingHit = 98871 (0.00351)
L2 Cache Total Miss Rate = 0.009

icnt_total_pkts_mem_to_simt=686991958
icnt_total_pkts_simt_to_mem=157570378

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 1.41864
% Accepted packets = 0 at node 0 (avg = 0.0293649)
lat(1) = 1.41864;
thru(1,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.135043 0.135052 0.135039 0.135193 0.135066 0 0 0 0 ];
% latency change    = 1
% throughput change = 1
Traffic 1 Stat
%=================================
% Average latency = 11.1638
% Accepted packets = 0 at node 14 (avg = 0.128028)
lat(2) = 11.1638;
thru(2,:) = [ 0.207059 0.207048 0.207067 0.207024 0.207067 0.218558 0.207003 0.207088 0.207073 0.218556 0.218478 0.21857 0.20702 0.207038 0 0 0 0 0 0 0 0 0 ];
% latency change    = 0.872925
% throughput change = 0.770637
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 1.41864 (1 samples)
Traffic[0]class0Overall average accepted rate = 0.0293649 (1 samples)
Traffic[0]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 121223221 10958379 1180193 1001565 1945178 714419 396653 1190513 924400 680080 257823 126360 54941 36592 20950 15784 9182 4884 2585 1549 1185 642 633 311 379 192 323 133 258 102 244 85 217 72 245 76 217 64 223 63 193 53 182 52 176 52 171 62 164 47 156 50 134 54 150 58 136 49 164 57 141 45 124 53 131 49 152 45 124 45 117 38 124 38 120 41 124 50 115 47 126 22 113 31 94 41 110 52 104 39 100 39 84 33 91 42 115 34 87 42 93 34 86 40 105 42 86 36 98 41 103 39 107 38 104 37 106 52 92 34 105 38 108 43 92 30 91 33 87 36 67 26 60 26 100 34 79 29 72 34 80 34 73 20 63 17 59 27 57 23 44 23 47 13 45 35 38 15 50 15 33 15 37 22 28 29 15 16 28 8 31 12 19 15 23 11 19 6 15 6 17 3 19 8 18 6 12 8 19 7 16 4 10 6 10 3 9 6 10 8 4 5 4 4 8 6 10 5 15 3 8 3 3 3 5 3 8 0 3 2 2 4 3 1 1 2 4 1 6 2 6 0 3 0 2 0 2 1 5 0 2 2 2 3 2 0 2 0 1 2 2 0 1 1 1 1 2 0 1 2 3 2 7 2 2 2 6 0 1 1 2 2 2 1 1 1 2 0 3 1 0 0 0 1 0 2 1 0 0 1 1 0 1 0 2 0 1 1 2 0 2 1 0 0 0 0 0 0 1 0 2 0 1 1 1 0 0 0 0 2 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 2 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 0 0 0 0 2 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (140760394 samples)
traffic_manager/hop_stats_freq = [ 0 140760394 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 11.1638 (1 samples)
Traffic[1]class0Overall average accepted rate = 0.128028 (1 samples)
Traffic[1]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 1383396 329720 280112 195598 28697946 11574991 5050720 11711132 11833414 8255928 6984689 6149305 5262688 5680500 4175275 9725581 3034211 2411912 2412146 2340454 3809985 1320362 1055498 1129354 978175 1586723 507638 415306 385880 354868 591928 192997 152623 138389 123130 202276 65587 48936 43386 36775 56584 17676 12117 9889 8486 12379 3621 2322 1944 1605 2140 587 376 288 264 314 83 44 50 30 34 8 6 5 3 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (140760394 samples)
traffic_manager/hop_stats_freq = [ 0 140760394 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 11 hrs, 51 min, 5 sec (42665 sec)
gpgpu_simulation_rate = 34886 (inst/sec)
gpgpu_simulation_rate = 2734 (cycle/sec)
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
GPU Runtime: 42664.636853s
