

        *** GPGPU-Sim Simulator Version 3.2.1  [build 15629] ***


               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim: Configuration options:

-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   20 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  4:128:24,L:R:m:N,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 64:64:2,L:R:f:N,A:2:32,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     4:128:4,L:R:f:N,A:2:32,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     32:128:4,L:L:m:N,A:32:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                32768 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_shader_cta                       8 # Maximum number of concurrent CTAs in shader (default 8)
-gpgpu_n_clusters                      14 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_size                   16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   16 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_operand_collector_num_units_sp                    6 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_sfu                    8 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (default = 13, anything else is off for now)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths        2,1,1,2,1,1,2 # Pipeline widths ID_OC_SP,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_SFU,OC_EX_MEM,EX_WB
-gpgpu_num_sp_units                     2 # Number of SP units (default=1)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      lrr # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     64:128:16,L:B:m:W,A:32:4,4 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            5 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_mem_per_ctrlr                    2 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   16 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                    0 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=4:CCDL=3:RTPL=2 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-rop_latency                          120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.BBBBCCCC.CCSSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpuwattch_xml_file         gpuwattch.xml # GPUWattch XML file
-power_simulation_enabled                    1 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-power_trace_enabled                    1 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 600.0:1200.0:600.0:750.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                    8 # maximum kernels that can run concurrently on GPU
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,19,25,145
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_initiation_int            1,2,2,1,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,4,4,32
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Defaultb13796d87feb0a2344306967b15344c4  /tmp/tmp.1hFMAKSz32/syrk__SIZE1_1
 1,1,1,1,5
-ptx_opcode_initiation_dp         8,16,8,8,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    3 # column to column delay between accesses to different bank groups
RTPL                                    2 # read to precharge delay between accesses to different bank groups
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 000000000000f000 	high:16 low:12
addr_dec_mask[ROW]   = 000000000fff0000 	high:28 low:16
addr_dec_mask[COL]   = 0000000000000fff 	high:12 low:0
addr_dec_mask[BURST] = 000000000000003f 	high:6 low:0
*** Initializing Memory Statistics ***
self exe links to: /tmp/tmp.1hFMAKSz32/syrk__SIZE1_1
Running md5sum using "md5sum /tmp/tmp.1hFMAKSz32/syrk__SIZE1_1 "
Running cuobjdump using "$CUDA_INSTALL_PATH/bin/cuobjdump -ptx -elf -sass /tmp/tmp.1hFMAKSz32/syrk__SIZE1_1 > _cuobjdump_complete_output_DOE5rm"
Parsing file _cuobjdump_complete_output_DOE5rm
######### cuobjdump parser ########
## Adding new section PTX
Adding ptx filename: _cuobjdump_1.ptx
Adding arch: sm_13
Adding identifier: benchmarks/syrk/syrk.cu
## Adding new section ELF
Adding arch: sm_13
Adding identifier: benchmarks/syrk/syrk.cu
Done parsing!!!
Adding _cuobjdump_1.ptx with cubin handle 1
Running: cat _ptx_CXKQEj | sed 's/.version 1.5/.version 1.4/' | sed 's/, texmode_independent//' | sed 's/\(\.extern \.const\[1\] .b8 \w\+\)\[\]/\1\[1\]/' | sed 's/const\[.\]/const\[0\]/g' > _ptx2_gDFCRg

kernel '_Z11syrk_kernelffPfS_' transfer to GPU hardware scheduler
kernel_name = _Z11syrk_kernelffPfS_ 
kernel_launch_uid = 1 
gpu_sim_cycle = 165965540
gpu_sim_insn = 1488453632
gpu_ipc =       8.9685
gpu_tot_sim_cycle = 165965540
gpu_tot_sim_insn = 1488453632
gpu_tot_ipc =       8.9685
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 5299335
gpu_stall_icnt2sh    = 30592113
gpu_total_sim_rate=25830
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10136730 (0.987), PendingHit = 127790 (0.0124)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9601349 (0.987), PendingHit = 123184 (0.0127)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10135440 (0.987), PendingHit = 129458 (0.0126)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9603797 (0.987), PendingHit = 121180 (0.0125)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9600866 (0.986), PendingHit = 123991 (0.0127)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9604359 (0.987), PendingHit = 120760 (0.0124)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10135805 (0.987), PendingHit = 129327 (0.0126)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9604123 (0.987), PendingHit = 121204 (0.0125)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9606691 (0.987), PendingHit = 118347 (0.0122)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9601884 (0.987), PendingHit = 122945 (0.0126)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9604940 (0.987), PendingHit = 120435 (0.0124)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 10273376, Miss = 10138785 (0.987), PendingHit = 126455 (0.0123)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9602575 (0.987), PendingHit = 122592 (0.0126)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 9732672, Miss = 9600040 (0.986), PendingHit = 124331 (0.0128)
total_dl1_misses=136577384
total_dl1_accesses=138420224
total_dl1_miss_rate= 0.986687
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 
distro:
5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 5680, 
gpgpu_n_tot_thrd_icount = 1488977920
gpgpu_n_tot_w_icount = 46530560
gpgpu_n_icache_hits = 25362432
gpgpu_n_icache_misses = 1375
gpgpu_n_l1dcache_read_hits = 110841
gpgpu_n_l1dcache_read_misses = 138309383
gpgpu_n_l1dcache_write_accesses = 4202496
gpgpu_n_l1dcache_wirte_misses = 4194350
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 15936
gpgpu_n_ccache_misses = 448
gpgpu_n_stall_shd_mem = -2070147240
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 136577384
gpgpu_n_mem_write_global = 4202496
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 14
gpgpu_n_load_insn  = 537395200
gpgpu_n_store_insn = 268959744
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 1048576
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 0
gpgpu_stall_shd_mem[c_mem][bk_conf] = 0
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = -2070147240
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:-842204235	W0_Idle:978141810	W0_Scoreboard:2052303	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:46530560
maxmrqlatency = 140 
maxdqlatency = 0 
maxmflatency = 708 
averagemflatency = 131 
max_icnt2mem_latency = 414 
max_icnt2sh_latency = 165965539 
mrq_lat_table:1208192 	17563 	8800 	22573 	51457 	3086 	142 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	71389018 	67948785 	1440693 	1398 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:28 	133625054 	5815498 	929526 	121068 	87252 	164390 	36219 	915 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	72544689 	49940834 	13116600 	975266 	9 	0 	0 	0 	0 	124 	111 	151 	167 	415 	593 	1055 	2413 	5575 	14086 	28140 	56441 	111769 	220665 	
mf_lat_pw_table:440875 	882366 	1759285 	678265 	0 	0 	67740 	262141 	2048 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        40        41        28        20        38        24        15        40        28        55        26        58        47        58        54        20 
dram[1]:        38        56        28        18        54        26        14        39        28        55        27        56        40        59        59        20 
dram[2]:        38        56        28        20        52        26        36        35        28        56        27        57        45        53        54        23 
dram[3]:        36        47        28        16        51        26        15        43        28        53        27        59        40        57        57        20 
dram[4]:        38        54        28        12        58        26        13        39        28        55        27        57        36        61        61        23 
maximum service time to same row:
dram[0]:   4094057   4094149   4094107    746623   2409708   2409829    801455   4021700   4021926    539221   1966974   2403965    453918   2370905   3764928   2433754 
dram[1]:   4093918   4093878   4093847   1204186   2410074   2410100    779172   4021666   4021639    931998   1966868   2403978    503690   2371203   3764860   2433856 
dram[2]:   4093881   4093846   4093960   1170284   2409935   2409828    776402   4021645   4072339    773966   2110212   2403970    503704   2370906   3764860   2433755 
dram[3]:   4114366   4094103   4093980   1244056   2409828   2409841    906252   4021685   4021907    802644   1101581   2403966    453920   2370915   3764869   2433854 
dram[4]:   4093890   4093871   4093964   1352476   2409924   2409694    811306   4021644   4062691    800542   2403970   2403965    503704   2370780   3764856   2433744 
average row accesses per activate:
dram[0]:  1.989676  2.029857  1.936753  1.335294  2.077767  2.040988  1.289271  1.979640  2.004729  1.830929  1.775024  1.850194  1.811503  2.125524  2.050705  1.971743 
dram[1]:  2.003052  2.011528  1.943597  1.912797  2.078497  1.961589  1.289550  2.047268  2.016304  1.270111  1.776279  1.943485  1.821730  2.050086  2.046404  2.068063 
dram[2]:  1.952268  2.013160  1.979500  1.938278  1.985517  1.961185  1.796149  2.045786  1.945076  1.269683  1.856088  1.950348  1.303344  2.056890  2.153453  2.066648 
dram[3]:  1.994700  1.973953  1.948396  1.356518  2.067085  1.949672  1.299424  1.959784  1.997570  1.261041  1.771915  1.840107  1.823650  2.040627  2.060089  1.950192 
dram[4]:  1.946883  2.006605  1.944890  1.914636  1.972273  1.947723  1.307937  2.039776  1.945251  1.261443  1.771377  1.961550  1.278542  2.076160  2.042846  2.058310 
average row locality = 1311815/722779 = 1.814960
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:     15304     14170     15177     14021     14861     13984     15161     14366     15088     14583     19826     18474     19544     14995     15330     14283 
dram[1]:     15271     14126     15152     14298     14871     14240     15048     14373     15022     16796     19769     18915     19449     15306     15197     14527 
dram[2]:     15090     14118     14917     14171     14527     14174     15168     14280     14948     16660     19447     18722     17749     15201     15148     14478 
dram[3]:     15315     14435     15141     14385     14828     14328     15055     14651     15056     17314     19861     19292     19522     15509     15355     14690 
dram[4]:     14737     14154     14519     14224     14473     14223     14613     14317     14502     16889     19071     18925     17288     15311     14950     14502 
total reads: 1251760
bank skew: 19861/13984 = 1.42
chip skew: 254737/246698 = 1.03
number of total write accesses:
dram[0]:       500       583       532       511       662       556       581       608       597       773       656      1040       897      1244      1252       580 
dram[1]:       481       705       527       530       672       570       513       613       560       903       644      1237       856      1353      1164       574 
dram[2]:       493       721       533       463       690       529       595       599       634       821       660      1154      1040      1322      1285       561 
dram[3]:       493       646       528       496       671       548       516       602       561       961       656      1308       943      1418      1307       580 
dram[4]:       474       733       515       467       678       531       614       606       634       915       671      1277       921      1427      1213       571 
total reads: 60055
bank skew: 1427/463 = 3.08
chip skew: 12247/11572 = 1.06
average mf latency per bank:
dram[0]:      13744     14702     13843     14883     13907     14846     13795     14501     13869     15856     13976     14648     13459     13421     13157     14721
dram[1]:      13778     14614     13861     14565     13887     14594     13945     14473     13948     13760     14020     14198     13561     13078     13331     14504
dram[2]:      13921     14600     14065     14750     14176     14687     13801     14582     13941     13923     14228     14380     14620     13194     13281     14593
dram[3]:      13750     14404     13923     14564     13934     14537     13945     14239     13927     13572     13965     13897     13452     12887     13103     14344
dram[4]:      14248     14552     14438     14697     14242     14665     14249     14525     14340     13899     14476     14147     14824     13013     13481     14529
maximum mf latency per bank:
dram[0]:        653       579       598       599       594       574       632       615       592       615       611       559       596       573       586       628
dram[1]:        624       571       596       579       573       595       670       620       543       556       604       642       624       605       583       671
dram[2]:        546       557       538       619       572       546       539       590       540       636       616       563       674       654       708       686
dram[3]:        582       579       592       563       581       576       598       582       619       606       643       573       566       603       578       617
dram[4]:        571       530       536       545       556       548       620       541       531       537       638       651       631       623       605       632

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=207456925 n_nop=206652623 n_act=141420 n_pre=141404 n_req=260739 n_rd=498334 n_write=23144 bw_util=0.005027
n_activity=7450560 dram_eff=0.14
bk0: 30608a 207390541i bk1: 28340a 207403450i bk2: 30354a 207400050i bk3: 28042a 207401605i bk4: 29722a 207404536i bk5: 27968a 207401774i bk6: 30322a 207400467i bk7: 28732a 207400391i bk8: 30176a 207400055i bk9: 29166a 207395637i bk10: 39652a 207399566i bk11: 36948a 207389315i bk12: 39088a 207369977i bk13: 29990a 207345615i bk14: 30660a 207045317i bk15: 28566a 203966929i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.00161905
Cache L2_bank_001:
MSHR contents

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=207456925 n_nop=206641287 n_act=143565 n_pre=143549 n_req=264262 n_rd=504720 n_write=23804 bw_util=0.005095
n_activity=7498191 dram_eff=0.141
bk0: 30542a 207389219i bk1: 28252a 207402180i bk2: 30304a 207399913i bk3: 28596a 207400925i bk4: 29742a 207404700i bk5: 28480a 207400781i bk6: 30096a 207401392i bk7: 28746a 207401399i bk8: 30044a 207401089i bk9: 33592a 207396344i bk10: 39538a 207399883i bk11: 37830a 207390195i bk12: 38898a 207368691i bk13: 30612a 207342908i bk14: 30394a 207025450i bk15: 29054a 203913397i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.00183651
Cache L2_bank_002:
MSHR contents

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=207456925 n_nop=206650989 n_act=142078 n_pre=142062 n_req=260898 n_rd=497596 n_write=24200 bw_util=0.00503
n_activity=7416486 dram_eff=0.1407
bk0: 30180a 207395012i bk1: 28236a 207403332i bk2: 29834a 207402154i bk3: 28342a 207401948i bk4: 29054a 207406937i bk5: 28348a 207403816i bk6: 30336a 207402783i bk7: 28560a 207403542i bk8: 29896a 207403337i bk9: 33320a 207398469i bk10: 38894a 207400004i bk11: 37444a 207392761i bk12: 35498a 207372249i bk13: 30402a 207345472i bk14: 30296a 207018637i bk15: 28956a 203935106i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.00199074
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=207456925 n_nop=206623019 n_act=149990 n_pre=149974 n_req=266971 n_rd=509474 n_write=24468 bw_util=0.005147
n_activity=7703770 dram_eff=0.1386
bk0: 30630a 207370531i bk1: 28870a 207398979i bk2: 30282a 207395155i bk3: 28770a 207397356i bk4: 29656a 207399849i bk5: 28656a 207391618i bk6: 30110a 207398047i bk7: 29302a 207396739i bk8: 30112a 207392643i bk9: 34628a 207386951i bk10: 39722a 207395906i bk11: 38584a 207385268i bk12: 39044a 207362123i bk13: 31018a 207341397i bk14: 30710a 207055761i bk15: 29380a 203794834i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.00156459
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=207456925 n_nop=206647595 n_act=145728 n_pre=145712 n_req=258945 n_rd=493396 n_write=24494 bw_util=0.004993
n_activity=7537162 dram_eff=0.1374
bk0: 29474a 207377776i bk1: 28308a 207403518i bk2: 29038a 207401017i bk3: 28448a 207401063i bk4: 28946a 207404562i bk5: 28446a 207396812i bk6: 29226a 207402733i bk7: 28634a 207401906i bk8: 29004a 207400160i bk9: 33778a 207393349i bk10: 38142a 207400208i bk11: 37850a 207390457i bk12: 34576a 207368327i bk13: 30622a 207346224i bk14: 29900a 207064593i bk15: 29004a 203864452i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.00155484
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28148263, Miss = 249167 (0.00885), PendingHit = 111413 (0.00396)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28149389, Miss = 252360 (0.00897), PendingHit = 108851 (0.00387)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28150049, Miss = 248798 (0.00884), PendingHit = 108354 (0.00385)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28182271, Miss = 254737 (0.00904), PendingHit = 112393 (0.00399)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 28149978, Miss = 246698 (0.00876), PendingHit = 104321 (0.00371)
L2 Cache Total Miss Rate = 0.009

icnt_total_pkts_mem_to_simt=687089738
icnt_total_pkts_simt_to_mem=157589934

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 1.36944
% Accepted packets = 0 at node 0 (avg = 0.020642)
lat(1) = 1.36944;
thru(1,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.0949277 0.094931 0.094933 0.0950301 0.0949452 0 0 0 0 ];
% latency change    = 1
% throughput change = 1
Traffic 1 Stat
%=================================
% Average latency = 8.30319
% Accepted packets = 0 at node 14 (avg = 0.089999)
lat(2) = 8.30319;
thru(2,:) = [ 0.153633 0.145519 0.153614 0.145556 0.145512 0.145564 0.153619 0.145561 0.145599 0.145527 0.145573 0.153664 0.145537 0.145499 0 0 0 0 0 0 0 0 0 ];
% latency change    = 0.835071
% throughput change = 0.770641
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 1.36944 (1 samples)
Traffic[0]class0Overall average accepted rate = 0.020642 (1 samples)
Traffic[0]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 126515850 6817596 742912 766334 1865140 557877 341272 1205206 937659 646529 194850 77723 31859 20583 12278 8311 4760 2057 1518 793 819 371 607 222 464 162 466 157 401 129 380 116 380 116 363 95 330 113 309 107 332 90 281 77 268 85 251 82 276 85 257 67 249 66 255 65 223 78 231 70 211 67 187 51 201 56 206 56 174 64 189 53 156 53 158 57 183 50 153 62 181 53 143 44 163 50 157 58 174 49 150 56 142 57 154 48 133 51 149 43 148 41 142 55 167 51 144 46 149 36 119 35 138 41 142 47 144 42 149 65 114 39 140 57 131 43 137 48 139 55 147 58 126 37 164 41 129 42 134 32 159 40 155 48 128 55 156 44 157 47 136 54 132 46 139 51 133 38 168 47 155 44 129 56 142 42 140 55 145 47 132 44 166 47 135 54 163 49 177 49 144 60 145 65 155 66 142 57 143 56 176 51 155 56 162 54 140 58 182 52 157 72 128 49 126 56 123 51 108 44 134 44 110 59 111 47 109 35 111 47 110 35 89 18 104 36 102 39 75 36 84 25 81 29 81 30 79 29 64 32 78 32 73 22 56 25 50 23 57 25 54 21 55 21 42 18 37 19 43 16 42 21 35 14 36 20 31 14 45 12 30 16 26 10 29 8 24 11 29 13 24 4 26 7 12 10 24 12 24 14 23 11 24 9 25 8 9 11 22 2 11 5 11 9 12 4 13 7 10 4 14 0 9 1 8 4 9 6 11 4 13 3 9 4 5 4 7 3 12 2 4 5 7 5 12 4 5 2 5 0 9 6 8 6 5 1 6 3 8 2 9 4 5 3 6 4 2 3 5 3 6 2 4 3 6 4 4 3 4 1 1 2 3 4 8 5 2 0 4 1 3 2 1 1 6 2 3 5 8 2 5 1 2 2 5 3 5 1 7 2 6 4 4 0 9 1 8 3 6 3 4 4 12 4 4 6 7 3 8 3 6 4 1 1 6 2 4 2 3 2 3 0 2 5 8 1 4 2 2 2 2 3 2 1 5 3 3 2 1 0 3 1 7 2 6 2 0 0 0 1 2 1 0 2 3 1 1 0 2 2 0 2 3 2 1 0 1 2 1 0 1 2 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (140779950 samples)
traffic_manager/hop_stats_freq = [ 0 140779950 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 8.30319 (1 samples)
Traffic[1]class0Overall average accepted rate = 0.089999 (1 samples)
Traffic[1]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 2415221 357134 301025 151226 50217732 22685555 4770967 13303686 10512540 7065383 5022178 4033010 2732890 3198603 1853840 2499826 1191328 906313 922905 907417 1123969 576671 528611 622883 438939 584146 256047 218615 232943 186253 246382 121874 120421 102319 71704 104244 42857 33835 29724 21035 26397 10469 7489 5898 4654 5292 2111 1439 1144 788 927 326 231 162 119 123 48 19 11 19 17 5 4 2 1 2 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (140779950 samples)
traffic_manager/hop_stats_freq = [ 0 140779950 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 16 hrs, 0 min, 24 sec (57624 sec)
gpgpu_simulation_rate = 25830 (inst/sec)
gpgpu_simulation_rate = 2880 (cycle/sec)
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
GPU Runtime: 57624.548017s
