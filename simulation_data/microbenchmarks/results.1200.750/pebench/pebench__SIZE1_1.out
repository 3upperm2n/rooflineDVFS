

        *** GPGPU-Sim Simulator Version 3.2.1  [build 15629] ***


GPGPU-Sim PTX: simulation mode 0 (can change with PTX_SIM_MODE_FUNC environment variable:
               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim: Configuration options:

-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   20 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  4:128:24,L:R:m:N,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 64:64:2,L:R:f:N,A:2:32,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     4:128:4,L:R:f:N,A:2:32,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     32:128:4,L:L:m:N,A:32:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                32768 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_shader_cta                       8 # Maximum number of concurrent CTAs in shader (default 8)
-gpgpu_n_clusters                      14 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_size                   16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   16 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_operand_collector_num_units_sp                    6 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_sfu                    8 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (default = 13, anything else is off for now)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths        2,1,1,2,1,1,2 # Pipeline widths ID_OC_SP,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_SFU,OC_EX_MEM,EX_WB
-gpgpu_num_sp_units                     2 # Number of SP units (default=1)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      lrr # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     64:128:16,L:B:m:W,A:32:4,4 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            5 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_mem_per_ctrlr                    2 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   16 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                    0 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=4:CCDL=3:RTPL=2 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-rop_latency                          120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.BBBBCCCC.CCSSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpuwattch_xml_file         gpuwattch.xml # GPUWattch XML file
-power_simulation_enabled                    1 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-power_trace_enabled                    1 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 600.0:1200.0:600.0:750.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                    8 # maximum kernels that can run concurrently on GPU
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,19,25,145
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_initiation_int            1,2,2,1,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,4,4,32
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Defaulta52dd55510594b4836751c1e15d5e2f2  /tmp/tmp.QAYHIascAC/pebench__SIZE1_1
 1,1,1,1,5
-ptx_opcode_initiation_dp         8,16,8,8,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    3 # column to column delay between accesses to different bank groups
RTPL                                    2 # read to precharge delay between accesses to different bank groups
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 000000000000f000 	high:16 low:12
addr_dec_mask[ROW]   = 000000000fff0000 	high:28 low:16
addr_dec_mask[COL]   = 0000000000000fff 	high:12 low:0
addr_dec_mask[BURST] = 000000000000003f 	high:6 low:0
*** Initializing Memory Statistics ***
GPGPU-Sim PTX: __cudaRegisterFatBinary, fat_cubin_handle = 1, filename=benchmarks/pebench/pebench.cu
self exe links to: /tmp/tmp.QAYHIascAC/pebench__SIZE1_1
Running md5sum using "md5sum /tmp/tmp.QAYHIascAC/pebench__SIZE1_1 "
Running cuobjdump using "$CUDA_INSTALL_PATH/bin/cuobjdump -ptx -elf -sass /tmp/tmp.QAYHIascAC/pebench__SIZE1_1 > _cuobjdump_complete_output_qcsUYJ"
Parsing file _cuobjdump_complete_output_qcsUYJ
######### cuobjdump parser ########
## Adding new section PTX
Adding ptx filename: _cuobjdump_1.ptx
Adding arch: sm_13
Adding identifier: benchmarks/pebench/pebench.cu
## Adding new section ELF
Adding arch: sm_13
Adding identifier: benchmarks/pebench/pebench.cu
Done parsing!!!
GPGPU-Sim PTX: __cudaRegisterFunction _Z7pebenchPjS_ : hostFun 0x0x400dd0, fat_cubin_handle = 1
GPGPU-Sim PTX: instruction assembly for function '_Z7pebenchPjS_'...   done.
GPGPU-Sim PTX: finding reconvergence points for '_Z7pebenchPjS_'...
GPGPU-Sim PTX: Finding dominators for '_Z7pebenchPjS_'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z7pebenchPjS_'...
GPGPU-Sim PTX: Finding postdominators for '_Z7pebenchPjS_'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z7pebenchPjS_'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z7pebenchPjS_'...
GPGPU-Sim PTX: reconvergence points for _Z7pebenchPjS_...
GPGPU-Sim PTX: ... end of reconvergence points for _Z7pebenchPjS_
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z7pebenchPjS_'.
GPGPU-Sim PTX: finished parsing EMBEDDED .ptx file _1.ptx
Adding _cuobjdump_1.ptx with cubin handle 1
GPGPU-Sim PTX: extracting embedded .ptx to temporary file "_ptx_TSURAB"
Running: cat _ptx_TSURAB | sed 's/.version 1.5/.version 1.4/' | sed 's/, texmode_independent//' | sed 's/\(\.extern \.const\[1\] .b8 \w\+\)\[\]/\1\[1\]/' | sed 's/const\[.\]/const\[0\]/g' > _ptx2_yxTPct
GPGPU-Sim PTX: generating ptxinfo using "$CUDA_INSTALL_PATH/bin/ptxas --gpu-name=sm_20 -v _ptx2_yxTPct --output-file  /dev/null 2> _ptx_TSURABinfo"
GPGPU-Sim PTX: Kernel '_Z7pebenchPjS_' : regs=8, lmem=0, smem=0, cmem=48
GPGPU-Sim PTX: removing ptxinfo using "rm -f _ptx_TSURAB _ptx2_yxTPct _ptx_TSURABinfo"
GPGPU-Sim PTX: loading globals with explicit initializers... 
GPGPU-Sim PTX: finished loading globals (0 bytes total).
GPGPU-Sim PTX: loading constants with explicit initializers...  done.
event update

GPGPU-Sim PTX: cudaLaunch for 0x0x400dd0 (mode=performance simulation) on stream 0
GPGPU-Sim PTX: pushing kernel '_Z7pebenchPjS_' to stream 0, gridDim= (112,1,1) blockDim = (512,1,1) 
kernel '_Z7pebenchPjS_' transfer to GPU hardware scheduler
GPGPU-Sim PTX: 100000 instructions simulated : ctaid=(19,0,0) tid=(479,0,0)
GPGPU-Sim PTX: 200000 instructions simulated : ctaid=(41,0,0) tid=(479,0,0)
GPGPU-Sim PTX: 300000 instructions simulated : ctaid=(25,0,0) tid=(95,0,0)
GPGPU-Sim PTX: 400000 instructions simulated : ctaid=(27,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 500000 instructions simulated : ctaid=(33,0,0) tid=(415,0,0)
GPGPU-Sim PTX: 600000 instructions simulated : ctaid=(38,0,0) tid=(351,0,0)
GPGPU-Sim PTX: 700000 instructions simulated : ctaid=(18,0,0) tid=(63,0,0)
GPGPU-Sim PTX: 800000 instructions simulated : ctaid=(39,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 900000 instructions simulated : ctaid=(14,0,0) tid=(255,0,0)
GPGPU-Sim PTX: 1000000 instructions simulated : ctaid=(20,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 1100000 instructions simulated : ctaid=(16,0,0) tid=(415,0,0)
GPGPU-Sim PTX: 1200000 instructions simulated : ctaid=(8,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 1300000 instructions simulated : ctaid=(40,0,0) tid=(223,0,0)
GPGPU-Sim PTX: 1400000 instructions simulated : ctaid=(1,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 1500000 instructions simulated : ctaid=(35,0,0) tid=(479,0,0)
GPGPU-Sim PTX: 1600000 instructions simulated : ctaid=(3,0,0) tid=(95,0,0)
GPGPU-Sim PTX: 1700000 instructions simulated : ctaid=(9,0,0) tid=(351,0,0)
GPGPU-Sim PTX: 1800000 instructions simulated : ctaid=(27,0,0) tid=(415,0,0)
GPGPU-Sim PTX: 1900000 instructions simulated : ctaid=(8,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 2000000 instructions simulated : ctaid=(10,0,0) tid=(447,0,0)
GPGPU-Sim PTX: 2100000 instructions simulated : ctaid=(18,0,0) tid=(383,0,0)
GPGPU-Sim PTX: 2200000 instructions simulated : ctaid=(39,0,0) tid=(255,0,0)
GPGPU-Sim PTX: 2300000 instructions simulated : ctaid=(28,0,0) tid=(63,0,0)
GPGPU-Sim PTX: 2400000 instructions simulated : ctaid=(20,0,0) tid=(255,0,0)
GPGPU-Sim PTX: 2500000 instructions simulated : ctaid=(2,0,0) tid=(63,0,0)
GPGPU-Sim PTX: 2600000 instructions simulated : ctaid=(36,0,0) tid=(447,0,0)
GPGPU-Sim PTX: 2700000 instructions simulated : ctaid=(12,0,0) tid=(127,0,0)
GPGPU-Sim PTX: 2800000 instructions simulated : ctaid=(1,0,0) tid=(255,0,0)
GPGPU-Sim PTX: 2900000 instructions simulated : ctaid=(7,0,0) tid=(447,0,0)
GPGPU-Sim PTX: 3000000 instructions simulated : ctaid=(17,0,0) tid=(191,0,0)
GPGPU-Sim PTX: 3100000 instructions simulated : ctaid=(56,0,0) tid=(383,0,0)
GPGPU-Sim PTX: 3200000 instructions simulated : ctaid=(74,0,0) tid=(351,0,0)
GPGPU-Sim PTX: 3300000 instructions simulated : ctaid=(52,0,0) tid=(479,0,0)
GPGPU-Sim PTX: 3400000 instructions simulated : ctaid=(55,0,0) tid=(351,0,0)
GPGPU-Sim PTX: 3500000 instructions simulated : ctaid=(42,0,0) tid=(479,0,0)
GPGPU-Sim PTX: 3600000 instructions simulated : ctaid=(44,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 3700000 instructions simulated : ctaid=(81,0,0) tid=(415,0,0)
GPGPU-Sim PTX: 3800000 instructions simulated : ctaid=(51,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 3900000 instructions simulated : ctaid=(82,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 4000000 instructions simulated : ctaid=(43,0,0) tid=(223,0,0)
GPGPU-Sim PTX: 4100000 instructions simulated : ctaid=(83,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 4200000 instructions simulated : ctaid=(71,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 4300000 instructions simulated : ctaid=(49,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 4400000 instructions simulated : ctaid=(80,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 4500000 instructions simulated : ctaid=(56,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 4600000 instructions simulated : ctaid=(76,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 4700000 instructions simulated : ctaid=(68,0,0) tid=(383,0,0)
GPGPU-Sim PTX: 4800000 instructions simulated : ctaid=(42,0,0) tid=(511,0,0)
GPGPU-Sim PTX: 4900000 instructions simulated : ctaid=(44,0,0) tid=(127,0,0)
GPGPU-Sim PTX: 5000000 instructions simulated : ctaid=(81,0,0) tid=(63,0,0)
GPGPU-Sim PTX: 5100000 instructions simulated : ctaid=(47,0,0) tid=(319,0,0)
GPGPU-Sim PTX: 5200000 instructions simulated : ctaid=(78,0,0) tid=(63,0,0)
GPGPU-Sim PTX: 5300000 instructions simulated : ctaid=(43,0,0) tid=(447,0,0)
GPGPU-Sim PTX: 5400000 instructions simulated : ctaid=(73,0,0) tid=(447,0,0)
GPGPU-Sim PTX: 5500000 instructions simulated : ctaid=(71,0,0) tid=(511,0,0)
GPGPU-Sim PTX: 5600000 instructions simulated : ctaid=(60,0,0) tid=(127,0,0)
GPGPU-Sim PTX: 5700000 instructions simulated : ctaid=(64,0,0) tid=(383,0,0)
GPGPU-Sim PTX: 5800000 instructions simulated : ctaid=(46,0,0) tid=(511,0,0)
GPGPU-Sim PTX: 5900000 instructions simulated : ctaid=(68,0,0) tid=(383,0,0)
GPGPU-Sim PTX: 6000000 instructions simulated : ctaid=(74,0,0) tid=(63,0,0)
GPGPU-Sim PTX: 6100000 instructions simulated : ctaid=(92,0,0) tid=(351,0,0)
GPGPU-Sim PTX: 6200000 instructions simulated : ctaid=(89,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 6300000 instructions simulated : ctaid=(89,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 6400000 instructions simulated : ctaid=(95,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 6500000 instructions simulated : ctaid=(104,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 6600000 instructions simulated : ctaid=(107,0,0) tid=(223,0,0)
GPGPU-Sim PTX: 6700000 instructions simulated : ctaid=(108,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 6800000 instructions simulated : ctaid=(88,0,0) tid=(287,0,0)
GPGPU-Sim PTX: 6900000 instructions simulated : ctaid=(91,0,0) tid=(415,0,0)
GPGPU-Sim PTX: 7000000 instructions simulated : ctaid=(84,0,0) tid=(287,0,0)
GPGPU-Sim PTX: 7100000 instructions simulated : ctaid=(85,0,0) tid=(415,0,0)
GPGPU-Sim PTX: 7200000 instructions simulated : ctaid=(87,0,0) tid=(479,0,0)
GPGPU-Sim PTX: 7300000 instructions simulated : ctaid=(90,0,0) tid=(447,0,0)
GPGPU-Sim PTX: 7400000 instructions simulated : ctaid=(92,0,0) tid=(447,0,0)
GPGPU-Sim PTX: 7500000 instructions simulated : ctaid=(102,0,0) tid=(319,0,0)
GPGPU-Sim PTX: 7600000 instructions simulated : ctaid=(107,0,0) tid=(319,0,0)
GPGPU-Sim PTX: 7700000 instructions simulated : ctaid=(107,0,0) tid=(383,0,0)
GPGPU-Sim PTX: 7800000 instructions simulated : ctaid=(86,0,0) tid=(383,0,0)
GPGPU-Sim PTX: 7900000 instructions simulated : ctaid=(98,0,0) tid=(127,0,0)
GPGPU-Sim PTX: 8000000 instructions simulated : ctaid=(95,0,0) tid=(383,0,0)
kernel_name = _Z7pebenchPjS_ 
kernel_launch_uid = 1 
gpu_sim_cycle = 40012
gpu_sim_insn = 8085504
gpu_ipc =     202.0770
gpu_tot_sim_cycle = 40012
gpu_tot_sim_insn = 8085504
gpu_tot_ipc =     202.0770
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 9022
gpu_stall_icnt2sh    = 790
gpu_total_sim_rate=385024
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 96, Miss = 96 (1), PendingHit = 0 (0)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 112, Miss = 112 (1), PendingHit = 0 (0)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 112, Miss = 112 (1), PendingHit = 0 (0)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 128, Miss = 128 (1), PendingHit = 0 (0)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 112, Miss = 112 (1), PendingHit = 0 (0)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 128, Miss = 128 (1), PendingHit = 0 (0)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 96, Miss = 96 (1), PendingHit = 0 (0)
total_dl1_misses=1792
total_dl1_accesses=1792
total_dl1_miss_rate= 1.000000
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 
distro:
141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 
gpgpu_n_tot_thrd_icount = 8085504
gpgpu_n_tot_w_icount = 252672
gpgpu_n_icache_hits = 127232
gpgpu_n_icache_misses = 3185
gpgpu_n_l1dcache_read_hits = 0
gpgpu_n_l1dcache_read_misses = 1792
gpgpu_n_l1dcache_write_accesses = 1792
gpgpu_n_l1dcache_wirte_misses = 1792
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 3136
gpgpu_n_ccache_misses = 448
gpgpu_n_stall_shd_mem = 10903
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 1792
gpgpu_n_mem_write_global = 1792
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 14
gpgpu_n_load_insn  = 114688
gpgpu_n_store_insn = 114688
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 229376
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 2571
gpgpu_stall_shd_mem[c_mem][bk_conf] = 2571
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 8332
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:454873	W0_Idle:257664	W0_Scoreboard:37539	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:252672
maxmrqlatency = 600 
maxdqlatency = 0 
maxmflatency = 1105 
averagemflatency = 404 
max_icnt2mem_latency = 314 
max_icnt2sh_latency = 40011 
mrq_lat_table:1054 	279 	216 	424 	704 	823 	911 	801 	158 	16 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	513 	2456 	615 	14 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:80 	521 	1390 	373 	335 	472 	280 	265 	8 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	1185 	435 	150 	36 	0 	0 	0 	0 	0 	0 	0 	0 	672 	752 	368 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	9 	16 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:         3         0         0         0         0         0         0         0         0        12        32        32        32        32        32        32 
dram[1]:         2         0         0         0         0         0         0         0         0        12        32        32        32        32        32        32 
dram[2]:         2         0         0         0         0         0         0         0         0        12        32        32        32        32        32        32 
dram[3]:         2         0         0         0         0         0         0         0         0        14        32        32        32        32        32        32 
dram[4]:         1         0         0         0         0         0         0         0         0        14        32        32        32        32        32        32 
maximum service time to same row:
dram[0]:     14228     14517     26917     27228      8848      8772      8770      8762      8760     19211     19323     19317     19803     20048     19318     16827 
dram[1]:     14210     14499     26964     27251      8892      8775      8768      8770      8762     19184     19169     19421     19749     20050     19360     16901 
dram[2]:     14230     14526     26936     27201      8943      8775      8756      8772      8764     19108     19202     19415     19709     20053     19338     16609 
dram[3]:     14216     14506     26940     27227      8978      8772      8752      8783      8754     19235     19353     19396     19850     20106     19319     16706 
dram[4]:     14228     14522     26905     27213      8795      8775      8754      8784      8756     19137     19330     19285     19824     20041     19276     16937 
average row accesses per activate:
dram[0]: 35.000000 32.000000 32.000000 32.000000 38.000000 64.000000 64.000000 64.000000 64.000000 38.000000 48.000000 48.000000 48.000000 48.000000 48.000000 48.000000 
dram[1]: 34.000000 32.000000 32.000000 32.000000 38.000000 64.000000 64.000000 64.000000 64.000000 38.000000 48.000000 48.000000 48.000000 48.000000 48.000000 48.000000 
dram[2]: 34.000000 32.000000 32.000000 32.000000 38.000000 64.000000 64.000000 64.000000 64.000000 38.000000 48.000000 48.000000 48.000000 48.000000 48.000000 48.000000 
dram[3]: 34.000000 32.000000 32.000000 32.000000 38.000000 64.000000 64.000000 64.000000 64.000000 39.000000 48.000000 48.000000 48.000000 48.000000 48.000000 48.000000 
dram[4]: 33.000000 32.000000 32.000000 32.000000 40.000000 64.000000 64.000000 64.000000 64.000000 39.000000 48.000000 48.000000 48.000000 48.000000 48.000000 48.000000 
average row locality = 5386/115 = 46.834782
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:        35        32        32        32        32        32        32        32        32        44        64        64        64        64        64        64 
dram[1]:        34        32        32        32        32        32        32        32        32        44        64        64        64        64        64        64 
dram[2]:        34        32        32        32        32        32        32        32        32        44        64        64        64        64        64        64 
dram[3]:        34        32        32        32        32        32        32        32        32        46        64        64        64        64        64        64 
dram[4]:        33        32        32        32        32        32        32        32        32        46        64        64        64        64        64        64 
total reads: 3594
bank skew: 64/32 = 2.00
chip skew: 720/718 = 1.00
number of total write accesses:
dram[0]:         0         0         0         0         6        32        32        32        32        32        32        32        32        32        32        32 
dram[1]:         0         0         0         0         6        32        32        32        32        32        32        32        32        32        32        32 
dram[2]:         0         0         0         0         6        32        32        32        32        32        32        32        32        32        32        32 
dram[3]:         0         0         0         0         6        32        32        32        32        32        32        32        32        32        32        32 
dram[4]:         0         0         0         0         8        32        32        32        32        32        32        32        32        32        32        32 
total reads: 1792
min_bank_accesses = 0!
chip skew: 360/358 = 1.01
average mf latency per bank:
dram[0]:        398       260       469       406       341       236       251       275       303       209       277       294       310       266       224       188
dram[1]:        297       252       449       377       332       229       278       293       254       219       258       297       291       257       217       190
dram[2]:        336       263       396       352       314       227       270       327       250       192       257       287       285       268       234       208
dram[3]:        310       263       454       403       327       240       243       313       262       218       279       285       310       261       214       194
dram[4]:        324       257       452       400       292       235       249       323       270       205       278       273       307       263       223       196
maximum mf latency per bank:
dram[0]:        379       342       570       475       526       831       915      1074      1094       576       649       830       884       719       472       361
dram[1]:        376       283       569       481       534       790      1040      1039       947       623       575       902       804       653       482       353
dram[2]:        399       325       489       453       519       795       900      1105       927       571       643       820       731       624       468       394
dram[3]:        392       352       547       545       508       828       829      1095       913       592       634       764       767       681       442       376
dram[4]:        368       330       557       518       508       804       876      1100      1041       645       630       747       833       643       472       378

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=50014 n_nop=47828 n_act=24 n_pre=8 n_req=1077 n_rd=1438 n_write=716 bw_util=0.08614
n_activity=9353 dram_eff=0.4606
bk0: 70a 48777i bk1: 64a 48686i bk2: 64a 48727i bk3: 64a 48752i bk4: 64a 48710i bk5: 64a 48745i bk6: 64a 48677i bk7: 64a 48672i bk8: 64a 48665i bk9: 88a 48623i bk10: 128a 48597i bk11: 128a 48710i bk12: 128a 48537i bk13: 128a 48514i bk14: 128a 48459i bk15: 128a 48527i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=1.73851
Cache L2_bank_001:
MSHR contents
MSHR: tag=0x80068480, atomic=0 1 entries : 0x2afd3b31a2c0 :  mf: uid=153555, sid04:w25, part=1, addr=0x80068480, load , size=128, unknown  status = IN_PARTITION_L2_FILL_QUEUE (40011), 

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=50014 n_nop=47830 n_act=24 n_pre=8 n_req=1076 n_rd=1436 n_write=716 bw_util=0.08606
n_activity=9286 dram_eff=0.4635
bk0: 68a 48748i bk1: 64a 48735i bk2: 64a 48780i bk3: 64a 48723i bk4: 64a 48694i bk5: 64a 48697i bk6: 64a 48663i bk7: 64a 48643i bk8: 64a 48675i bk9: 88a 48668i bk10: 128a 48671i bk11: 128a 48633i bk12: 128a 48519i bk13: 128a 48586i bk14: 128a 48573i bk15: 128a 48570i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=1.70796
Cache L2_bank_002:
MSHR contents
MSHR: tag=0x80068580, atomic=0 1 entries : 0x2afd1537e3a0 :  mf: uid=153556, sid04:w27, part=2, addr=0x80068580, load , size=128, unknown  status = IN_PARTITION_DRAM (40011), 

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=50014 n_nop=47832 n_act=24 n_pre=8 n_req=1076 n_rd=1434 n_write=716 bw_util=0.08598
n_activity=9316 dram_eff=0.4616
bk0: 68a 48776i bk1: 64a 48782i bk2: 64a 48756i bk3: 64a 48778i bk4: 64a 48730i bk5: 64a 48738i bk6: 64a 48801i bk7: 64a 48789i bk8: 64a 48772i bk9: 88a 48680i bk10: 128a 48653i bk11: 128a 48667i bk12: 128a 48472i bk13: 128a 48447i bk14: 126a 48564i bk15: 128a 48551i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=1.73447
Cache L2_bank_003:
MSHR contents

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=50014 n_nop=47826 n_act=24 n_pre=8 n_req=1078 n_rd=1440 n_write=716 bw_util=0.08622
n_activity=9520 dram_eff=0.4529
bk0: 68a 48714i bk1: 64a 48753i bk2: 64a 48800i bk3: 64a 48790i bk4: 64a 48734i bk5: 64a 48681i bk6: 64a 48715i bk7: 64a 48682i bk8: 64a 48729i bk9: 92a 48770i bk10: 128a 48754i bk11: 128a 48663i bk12: 128a 48542i bk13: 128a 48526i bk14: 128a 48455i bk15: 128a 48528i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=1.67067
Cache L2_bank_004:
MSHR contents

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=50014 n_nop=47824 n_act=24 n_pre=8 n_req=1079 n_rd=1438 n_write=720 bw_util=0.0863
n_activity=9418 dram_eff=0.4583
bk0: 66a 48712i bk1: 64a 48753i bk2: 64a 48769i bk3: 64a 48728i bk4: 64a 48763i bk5: 64a 48808i bk6: 64a 48740i bk7: 64a 48709i bk8: 64a 48684i bk9: 92a 48640i bk10: 128a 48688i bk11: 128a 48643i bk12: 128a 48495i bk13: 128a 48442i bk14: 128a 48383i bk15: 128a 48435i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=1.67077
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 758, Miss = 719 (0.949), PendingHit = 9 (0.0119)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 744, Miss = 718 (0.965), PendingHit = 6 (0.00806)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 744, Miss = 718 (0.965), PendingHit = 6 (0.00806)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 746, Miss = 720 (0.965), PendingHit = 6 (0.00804)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 732, Miss = 719 (0.982), PendingHit = 3 (0.0041)
L2 Cache Total Miss Rate = 0.965

icnt_total_pkts_mem_to_simt=11424
icnt_total_pkts_simt_to_mem=10892

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 28.2355
% Accepted packets = 0 at node 0 (avg = 0.00591794)
lat(1) = 28.2355;
thru(1,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.0273675 0.0271925 0.0271925 0.0272175 0.0271425 0 0 0 0 ];
% latency change    = 1
% throughput change = 1
Traffic 1 Stat
%=================================
% Average latency = 4.72959
% Accepted packets = 0 at node 14 (avg = 0.00620699)
lat(2) = 4.72959;
thru(2,:) = [ 0.0113969 0.0113969 0.0113969 0.00779786 0.0113969 0.0113969 0.0113969 0.00899753 0.0113969 0.00899753 0.0101972 0.00899753 0.0101972 0.00779786 0 0 0 0 0 0 0 0 0 ];
% latency change    = 4.96997
% throughput change = 0.0465686
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 28.2355 (1 samples)
Traffic[0]class0Overall average accepted rate = 0.00591794 (1 samples)
Traffic[0]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 1007 130 43 35 791 106 60 184 94 66 43 45 42 23 24 28 26 20 25 14 35 12 24 21 21 10 25 13 29 10 18 8 19 17 17 13 26 5 15 11 17 9 17 3 7 5 19 5 16 1 9 4 9 1 6 4 12 4 4 3 4 2 2 5 5 4 4 1 8 1 5 4 1 10 7 0 3 2 3 4 2 4 2 3 8 1 0 3 1 3 1 2 5 0 2 0 3 0 0 0 3 0 1 0 1 0 4 1 1 0 1 2 3 0 2 3 4 3 3 0 0 4 4 0 1 0 0 0 3 1 2 0 3 0 1 0 3 0 2 0 2 0 0 1 2 0 1 0 2 2 1 0 0 0 1 0 0 2 3 1 2 6 4 3 2 2 0 0 2 1 0 1 1 1 3 1 2 1 5 2 5 2 3 0 2 1 2 0 1 0 2 2 3 3 1 1 2 0 0 2 3 0 1 0 2 0 2 0 4 0 0 1 1 1 1 0 3 0 1 3 5 0 1 1 1 0 3 0 1 0 2 0 0 0 0 2 2 0 2 0 1 0 4 1 0 0 0 0 0 0 2 0 1 0 1 0 2 0 3 1 2 0 2 0 2 1 3 1 0 1 1 0 3 1 2 1 2 1 1 0 2 0 3 1 1 0 1 1 1 0 0 0 3 1 2 0 2 0 0 0 2 0 4 2 2 0 1 0 4 0 8 0 1 0 1 0 2 0 3 0 2 0 1 0 0 0 3 0 0 0 0 0 1 0 0 1 1 0 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 2 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (3724 samples)
traffic_manager/hop_stats_freq = [ 0 3724 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 4.72959 (1 samples)
Traffic[1]class0Overall average accepted rate = 0.00620699 (1 samples)
Traffic[1]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 1733 40 4 2 1059 135 70 143 162 75 27 29 29 20 24 23 5 14 13 12 20 7 10 4 5 15 1 3 2 3 5 3 7 2 3 3 1 2 0 1 1 1 0 0 1 2 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (3724 samples)
traffic_manager/hop_stats_freq = [ 0 3724 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 21 sec (21 sec)
gpgpu_simulation_rate = 385024 (inst/sec)
gpgpu_simulation_rate = 1905 (cycle/sec)
event update
GPGPU-Sim API: cudaEventSynchronize ** waiting for event
GPGPU-Sim API: cudaEventSynchronize ** event detected
Execution time: 21000.000 ms 
Bandwidth: 0.000 GB/s 
