

        *** GPGPU-Sim Simulator Version 3.2.1  [build 15629] ***


GPGPU-Sim PTX: simulation mode 0 (can change with PTX_SIM_MODE_FUNC environment variable:
               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim: Configuration options:

-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   20 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  4:128:24,L:R:m:N,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 64:64:2,L:R:f:N,A:2:32,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     4:128:4,L:R:f:N,A:2:32,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     32:128:4,L:L:m:N,A:32:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                32768 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_shader_cta                       8 # Maximum number of concurrent CTAs in shader (default 8)
-gpgpu_n_clusters                      14 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_size                   16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   16 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_operand_collector_num_units_sp                    6 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_sfu                    8 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    2 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (default = 13, anything else is off for now)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths        2,1,1,2,1,1,2 # Pipeline widths ID_OC_SP,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_SFU,OC_EX_MEM,EX_WB
-gpgpu_num_sp_units                     2 # Number of SP units (default=1)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      lrr # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     64:128:16,L:B:m:W,A:32:4,4 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            5 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_mem_per_ctrlr                    2 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   16 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                    0 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=4:CCDL=3:RTPL=2 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-rop_latency                          100 # ROP queue latency (default 85)
-dram_latency                          83 # DRAM latency (default 30)
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.BBBBCCCC.CCSSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpuwattch_xml_file         gpuwattch.xml # GPUWattch XML file
-power_simulation_enabled                    1 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-power_trace_enabled                    1 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 500.0:1000.0:500.0:900.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                    8 # maximum kernels that can run concurrently on GPU
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,19,25,145
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_initiation_int            1,2,2,1,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV>Default 1,1,4,4,32
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Defaultee99eb53ff4e3bcabab60c4957d1887d  /tmp/tmp.SK2LHjbBLS/pebench__SIZE1_1
 1,1,1,1,5
-ptx_opcode_initiation_dp         8,16,8,8,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    3 # column to column delay between accesses to different bank groups
RTPL                                    2 # read to precharge delay between accesses to different bank groups
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 000000000000f000 	high:16 low:12
addr_dec_mask[ROW]   = 000000000fff0000 	high:28 low:16
addr_dec_mask[COL]   = 0000000000000fff 	high:12 low:0
addr_dec_mask[BURST] = 000000000000003f 	high:6 low:0
*** Initializing Memory Statistics ***
GPGPU-Sim PTX: __cudaRegisterFatBinary, fat_cubin_handle = 1, filename=benchmarks/pebench/pebench.cu
self exe links to: /tmp/tmp.SK2LHjbBLS/pebench__SIZE1_1
Running md5sum using "md5sum /tmp/tmp.SK2LHjbBLS/pebench__SIZE1_1 "
Running cuobjdump using "$CUDA_INSTALL_PATH/bin/cuobjdump -ptx -elf -sass /tmp/tmp.SK2LHjbBLS/pebench__SIZE1_1 > _cuobjdump_complete_output_trSldy"
Parsing file _cuobjdump_complete_output_trSldy
######### cuobjdump parser ########
## Adding new section PTX
Adding ptx filename: _cuobjdump_1.ptx
Adding arch: sm_13
Adding identifier: benchmarks/pebench/pebench.cu
## Adding new section ELF
Adding arch: sm_13
Adding identifier: benchmarks/pebench/pebench.cu
Done parsing!!!
GPGPU-Sim PTX: __cudaRegisterFunction _Z7pebenchPjS_ : hostFun 0x0x400dd0, fat_cubin_handle = 1
GPGPU-Sim PTX: instruction assembly for function '_Z7pebenchPjS_'...   done.
GPGPU-Sim PTX: finding reconvergence points for '_Z7pebenchPjS_'...
GPGPU-Sim PTX: Finding dominators for '_Z7pebenchPjS_'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z7pebenchPjS_'...
GPGPU-Sim PTX: Finding postdominators for '_Z7pebenchPjS_'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z7pebenchPjS_'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z7pebenchPjS_'...
GPGPU-Sim PTX: reconvergence points for _Z7pebenchPjS_...
GPGPU-Sim PTX: ... end of reconvergence points for _Z7pebenchPjS_
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z7pebenchPjS_'.
GPGPU-Sim PTX: finished parsing EMBEDDED .ptx file _1.ptx
Adding _cuobjdump_1.ptx with cubin handle 1
GPGPU-Sim PTX: extracting embedded .ptx to temporary file "_ptx_2gVJ3n"
Running: cat _ptx_2gVJ3n | sed 's/.version 1.5/.version 1.4/' | sed 's/, texmode_independent//' | sed 's/\(\.extern \.const\[1\] .b8 \w\+\)\[\]/\1\[1\]/' | sed 's/const\[.\]/const\[0\]/g' > _ptx2_Hyw8Td
GPGPU-Sim PTX: generating ptxinfo using "$CUDA_INSTALL_PATH/bin/ptxas --gpu-name=sm_20 -v _ptx2_Hyw8Td --output-file  /dev/null 2> _ptx_2gVJ3ninfo"
GPGPU-Sim PTX: Kernel '_Z7pebenchPjS_' : regs=8, lmem=0, smem=0, cmem=48
GPGPU-Sim PTX: removing ptxinfo using "rm -f _ptx_2gVJ3n _ptx2_Hyw8Td _ptx_2gVJ3ninfo"
GPGPU-Sim PTX: loading globals with explicit initializers... 
GPGPU-Sim PTX: finished loading globals (0 bytes total).
GPGPU-Sim PTX: loading constants with explicit initializers...  done.
event update

GPGPU-Sim PTX: cudaLaunch for 0x0x400dd0 (mode=performance simulation) on stream 0
GPGPU-Sim PTX: pushing kernel '_Z7pebenchPjS_' to stream 0, gridDim= (112,1,1) blockDim = (512,1,1) 
kernel '_Z7pebenchPjS_' transfer to GPU hardware scheduler
GPGPU-Sim PTX: 100000 instructions simulated : ctaid=(33,0,0) tid=(95,0,0)
GPGPU-Sim PTX: 200000 instructions simulated : ctaid=(19,0,0) tid=(447,0,0)
GPGPU-Sim PTX: 300000 instructions simulated : ctaid=(31,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 400000 instructions simulated : ctaid=(24,0,0) tid=(351,0,0)
GPGPU-Sim PTX: 500000 instructions simulated : ctaid=(14,0,0) tid=(223,0,0)
GPGPU-Sim PTX: 600000 instructions simulated : ctaid=(19,0,0) tid=(95,0,0)
GPGPU-Sim PTX: 700000 instructions simulated : ctaid=(37,0,0) tid=(223,0,0)
GPGPU-Sim PTX: 800000 instructions simulated : ctaid=(4,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 900000 instructions simulated : ctaid=(12,0,0) tid=(415,0,0)
GPGPU-Sim PTX: 1000000 instructions simulated : ctaid=(15,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 1100000 instructions simulated : ctaid=(6,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 1200000 instructions simulated : ctaid=(11,0,0) tid=(287,0,0)
GPGPU-Sim PTX: 1300000 instructions simulated : ctaid=(22,0,0) tid=(191,0,0)
GPGPU-Sim PTX: 1400000 instructions simulated : ctaid=(41,0,0) tid=(351,0,0)
GPGPU-Sim PTX: 1500000 instructions simulated : ctaid=(30,0,0) tid=(127,0,0)
GPGPU-Sim PTX: 1600000 instructions simulated : ctaid=(35,0,0) tid=(223,0,0)
GPGPU-Sim PTX: 1700000 instructions simulated : ctaid=(3,0,0) tid=(511,0,0)
GPGPU-Sim PTX: 1800000 instructions simulated : ctaid=(9,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 1900000 instructions simulated : ctaid=(0,0,0) tid=(191,0,0)
GPGPU-Sim PTX: 2000000 instructions simulated : ctaid=(5,0,0) tid=(127,0,0)
GPGPU-Sim PTX: 2100000 instructions simulated : ctaid=(23,0,0) tid=(63,0,0)
GPGPU-Sim PTX: 2200000 instructions simulated : ctaid=(4,0,0) tid=(191,0,0)
GPGPU-Sim PTX: 2300000 instructions simulated : ctaid=(26,0,0) tid=(63,0,0)
GPGPU-Sim PTX: 2400000 instructions simulated : ctaid=(15,0,0) tid=(191,0,0)
GPGPU-Sim PTX: 2500000 instructions simulated : ctaid=(20,0,0) tid=(63,0,0)
GPGPU-Sim PTX: 2600000 instructions simulated : ctaid=(11,0,0) tid=(383,0,0)
GPGPU-Sim PTX: 2700000 instructions simulated : ctaid=(22,0,0) tid=(511,0,0)
GPGPU-Sim PTX: 2800000 instructions simulated : ctaid=(13,0,0) tid=(191,0,0)
GPGPU-Sim PTX: 2900000 instructions simulated : ctaid=(30,0,0) tid=(447,0,0)
GPGPU-Sim PTX: 3000000 instructions simulated : ctaid=(26,0,0) tid=(191,0,0)
GPGPU-Sim PTX: 3100000 instructions simulated : ctaid=(60,0,0) tid=(447,0,0)
GPGPU-Sim PTX: 3200000 instructions simulated : ctaid=(75,0,0) tid=(447,0,0)
GPGPU-Sim PTX: 3300000 instructions simulated : ctaid=(75,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 3400000 instructions simulated : ctaid=(42,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 3500000 instructions simulated : ctaid=(55,0,0) tid=(287,0,0)
GPGPU-Sim PTX: 3600000 instructions simulated : ctaid=(45,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 3700000 instructions simulated : ctaid=(74,0,0) tid=(415,0,0)
GPGPU-Sim PTX: 3800000 instructions simulated : ctaid=(48,0,0) tid=(415,0,0)
GPGPU-Sim PTX: 3900000 instructions simulated : ctaid=(59,0,0) tid=(159,0,0)
GPGPU-Sim PTX: 4000000 instructions simulated : ctaid=(73,0,0) tid=(479,0,0)
GPGPU-Sim PTX: 4100000 instructions simulated : ctaid=(57,0,0) tid=(95,0,0)
GPGPU-Sim PTX: 4200000 instructions simulated : ctaid=(78,0,0) tid=(351,0,0)
GPGPU-Sim PTX: 4300000 instructions simulated : ctaid=(44,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 4400000 instructions simulated : ctaid=(60,0,0) tid=(415,0,0)
GPGPU-Sim PTX: 4500000 instructions simulated : ctaid=(76,0,0) tid=(31,0,0)
GPGPU-Sim PTX: 4600000 instructions simulated : ctaid=(74,0,0) tid=(479,0,0)
GPGPU-Sim PTX: 4700000 instructions simulated : ctaid=(52,0,0) tid=(383,0,0)
GPGPU-Sim PTX: 4800000 instructions simulated : ctaid=(52,0,0) tid=(319,0,0)
GPGPU-Sim PTX: 4900000 instructions simulated : ctaid=(43,0,0) tid=(511,0,0)
GPGPU-Sim PTX: 5000000 instructions simulated : ctaid=(54,0,0) tid=(383,0,0)
GPGPU-Sim PTX: 5100000 instructions simulated : ctaid=(62,0,0) tid=(511,0,0)
GPGPU-Sim PTX: 5200000 instructions simulated : ctaid=(49,0,0) tid=(63,0,0)
GPGPU-Sim PTX: 5300000 instructions simulated : ctaid=(72,0,0) tid=(255,0,0)
GPGPU-Sim PTX: 5400000 instructions simulated : ctaid=(71,0,0) tid=(511,0,0)
GPGPU-Sim PTX: 5500000 instructions simulated : ctaid=(77,0,0) tid=(383,0,0)
GPGPU-Sim PTX: 5600000 instructions simulated : ctaid=(51,0,0) tid=(255,0,0)
GPGPU-Sim PTX: 5700000 instructions simulated : ctaid=(58,0,0) tid=(511,0,0)
GPGPU-Sim PTX: 5800000 instructions simulated : ctaid=(45,0,0) tid=(319,0,0)
GPGPU-Sim PTX: 5900000 instructions simulated : ctaid=(65,0,0) tid=(191,0,0)
GPGPU-Sim PTX: 6000000 instructions simulated : ctaid=(69,0,0) tid=(447,0,0)
GPGPU-Sim PTX: 6100000 instructions simulated : ctaid=(79,0,0) tid=(63,0,0)
GPGPU-Sim PTX: 6200000 instructions simulated : ctaid=(111,0,0) tid=(479,0,0)
GPGPU-Sim PTX: 6300000 instructions simulated : ctaid=(95,0,0) tid=(223,0,0)
GPGPU-Sim PTX: 6400000 instructions simulated : ctaid=(110,0,0) tid=(415,0,0)
GPGPU-Sim PTX: 6500000 instructions simulated : ctaid=(95,0,0) tid=(287,0,0)
GPGPU-Sim PTX: 6600000 instructions simulated : ctaid=(110,0,0) tid=(287,0,0)
GPGPU-Sim PTX: 6700000 instructions simulated : ctaid=(95,0,0) tid=(351,0,0)
GPGPU-Sim PTX: 6800000 instructions simulated : ctaid=(90,0,0) tid=(479,0,0)
GPGPU-Sim PTX: 6900000 instructions simulated : ctaid=(107,0,0) tid=(415,0,0)
GPGPU-Sim PTX: 7000000 instructions simulated : ctaid=(99,0,0) tid=(479,0,0)
GPGPU-Sim PTX: 7100000 instructions simulated : ctaid=(85,0,0) tid=(223,0,0)
GPGPU-Sim PTX: 7200000 instructions simulated : ctaid=(94,0,0) tid=(415,0,0)
GPGPU-Sim PTX: 7300000 instructions simulated : ctaid=(88,0,0) tid=(63,0,0)
GPGPU-Sim PTX: 7400000 instructions simulated : ctaid=(103,0,0) tid=(255,0,0)
GPGPU-Sim PTX: 7500000 instructions simulated : ctaid=(90,0,0) tid=(127,0,0)
GPGPU-Sim PTX: 7600000 instructions simulated : ctaid=(85,0,0) tid=(319,0,0)
GPGPU-Sim PTX: 7700000 instructions simulated : ctaid=(109,0,0) tid=(383,0,0)
GPGPU-Sim PTX: 7800000 instructions simulated : ctaid=(107,0,0) tid=(447,0,0)
GPGPU-Sim PTX: 7900000 instructions simulated : ctaid=(108,0,0) tid=(255,0,0)
GPGPU-Sim PTX: 8000000 instructions simulated : ctaid=(84,0,0) tid=(63,0,0)
kernel_name = _Z7pebenchPjS_ 
kernel_launch_uid = 1 
gpu_sim_cycle = 39347
gpu_sim_insn = 8085504
gpu_ipc =     205.4923
gpu_tot_sim_cycle = 39347
gpu_tot_sim_insn = 8085504
gpu_tot_ipc =     205.4923
gpu_tot_issued_cta = 0
gpu_stall_dramfull = 4954
gpu_stall_icnt2sh    = 1260
gpu_total_sim_rate=385024
Cache L1D_000:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_001:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_002:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_003:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_004:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_005:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_006:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_007:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_008:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 144, Miss = 144 (1), PendingHit = 0 (0)
Cache L1D_009:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 96, Miss = 96 (1), PendingHit = 0 (0)
Cache L1D_010:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 96, Miss = 96 (1), PendingHit = 0 (0)
Cache L1D_011:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 112, Miss = 112 (1), PendingHit = 0 (0)
Cache L1D_012:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 96, Miss = 96 (1), PendingHit = 0 (0)
Cache L1D_013:	Size = 16384 B (32 Set x 4-way x 128 byte line)
		Access = 96, Miss = 96 (1), PendingHit = 0 (0)
total_dl1_misses=1792
total_dl1_accesses=1792
total_dl1_miss_rate= 1.000000
Shader 0 dynamic_warp_id issue ditsribution:
dynamic_warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 
distro:
141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 141, 
gpgpu_n_tot_thrd_icount = 8085504
gpgpu_n_tot_w_icount = 252672
gpgpu_n_icache_hits = 127232
gpgpu_n_icache_misses = 3105
gpgpu_n_l1dcache_read_hits = 0
gpgpu_n_l1dcache_read_misses = 1792
gpgpu_n_l1dcache_write_accesses = 1792
gpgpu_n_l1dcache_wirte_misses = 1792
gpgpu_n_tcache_hits = 0
gpgpu_n_tcache_misses = 0
gpgpu_n_ccache_hits = 3136
gpgpu_n_ccache_misses = 448
gpgpu_n_stall_shd_mem = 8204
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 1792
gpgpu_n_mem_write_global = 1792
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 14
gpgpu_n_load_insn  = 114688
gpgpu_n_store_insn = 114688
gpgpu_n_shmem_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 229376
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 1997
gpgpu_stall_shd_mem[c_mem][bk_conf] = 1997
gpgpu_stall_shd_mem[c_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[c_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[t_mem][mshr_rc] = 0
gpgpu_stall_shd_mem[t_mem][icnt_rc] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 6207
gpgpu_stall_shd_mem[g_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[g_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[g_mem_st][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_ld][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpgpu_stall_shd_mem[l_mem_st][mshr_rc] = 0
gpgpu_stall_shd_mem[l_mem_st][icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_icnt_rc] = 0
gpgpu_stall_shd_mem[l_mem_ld][wb_rsrv_fail] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:458908	W0_Idle:252795	W0_Scoreboard:18497	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:252672
maxmrqlatency = 419 
maxdqlatency = 0 
maxmflatency = 852 
averagemflatency = 293 
max_icnt2mem_latency = 166 
max_icnt2sh_latency = 39346 
mrq_lat_table:1263 	313 	318 	627 	745 	869 	849 	385 	17 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	1625 	1836 	137 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:91 	857 	1436 	340 	311 	376 	237 	76 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	754 	691 	308 	53 	0 	0 	0 	0 	0 	0 	0 	13 	659 	746 	374 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	11 	8 	1 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:         3         0         0         0         0         0         0         0         0        12        32        32        32        32        32        32 
dram[1]:         2         0         0         0         0         0         0         0         0        12        32        32        32        32        32        32 
dram[2]:         2         0         0         0         0         0         0         0         0        12        32        32        32        32        32        32 
dram[3]:         2         0         0         0         0         0         0         0         0        14        32        32        32        32        32        32 
dram[4]:         1         0         0         0         0         0         0         0         0        14        32        32        32        32        32        32 
maximum service time to same row:
dram[0]:     13927     14082     26429     26641      8192      8154      8176      8202      8174     18947     19066     19230     19293     19591     18841     16455 
dram[1]:     13906     14002     26382     26621      8196      8174      8206      8203      8172     18982     19101     19336     19374     19624     19108     16612 
dram[2]:     13891     14011     26414     26621      8201      8162      8186      8174      8176     19066     19100     19316     19342     19640     19107     16654 
dram[3]:     13891     13997     26390     26601      8206      8161      8188      8164      8179     18960     19059     19273     19341     19625     19162     16615 
dram[4]:     13903     13997     26389     26582      8188      8166      8206      8168      8186     18762     19075     19289     19337     19627     19009     16552 
average row accesses per activate:
dram[0]: 35.000000 32.000000 32.000000 32.000000 38.000000 64.000000 64.000000 64.000000 64.000000 38.000000 48.000000 48.000000 48.000000 48.000000 48.000000 48.000000 
dram[1]: 34.000000 32.000000 32.000000 32.000000 38.000000 64.000000 64.000000 64.000000 64.000000 38.000000 48.000000 48.000000 48.000000 48.000000 48.000000 48.000000 
dram[2]: 34.000000 32.000000 32.000000 32.000000 38.000000 64.000000 64.000000 64.000000 64.000000 38.000000 48.000000 48.000000 48.000000 48.000000 48.000000 48.000000 
dram[3]: 34.000000 32.000000 32.000000 32.000000 38.000000 64.000000 64.000000 64.000000 64.000000 39.000000 48.000000 48.000000 48.000000 48.000000 48.000000 48.000000 
dram[4]: 33.000000 32.000000 32.000000 32.000000 40.000000 64.000000 64.000000 64.000000 64.000000 39.000000 48.000000 48.000000 48.000000 48.000000 48.000000 48.000000 
average row locality = 5386/115 = 46.834782
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:        35        32        32        32        32        32        32        32        32        44        64        64        64        64        64        64 
dram[1]:        34        32        32        32        32        32        32        32        32        44        64        64        64        64        64        64 
dram[2]:        34        32        32        32        32        32        32        32        32        44        64        64        64        64        64        64 
dram[3]:        34        32        32        32        32        32        32        32        32        46        64        64        64        64        64        64 
dram[4]:        33        32        32        32        32        32        32        32        32        46        64        64        64        64        64        64 
total reads: 3594
bank skew: 64/32 = 2.00
chip skew: 720/718 = 1.00
number of total write accesses:
dram[0]:         0         0         0         0         6        32        32        32        32        32        32        32        32        32        32        32 
dram[1]:         0         0         0         0         6        32        32        32        32        32        32        32        32        32        32        32 
dram[2]:         0         0         0         0         6        32        32        32        32        32        32        32        32        32        32        32 
dram[3]:         0         0         0         0         6        32        32        32        32        32        32        32        32        32        32        32 
dram[4]:         0         0         0         0         8        32        32        32        32        32        32        32        32        32        32        32 
total reads: 1792
min_bank_accesses = 0!
chip skew: 360/358 = 1.01
average mf latency per bank:
dram[0]:        309       240       284       296       235       176       184       207       199       150       201       219       229       193       161       166
dram[1]:        223       213       262       286       236       183       183       217       199       152       193       209       207       196       180       154
dram[2]:        213       213       271       265       218       173       188       193       202       170       206       224       218       188       161       156
dram[3]:        203       204       250       257       215       175       191       182       183       153       197       218       206       190       156       150
dram[4]:        224       208       222       218       186       175       193       193       201       137       193       212       211       186       167       161
maximum mf latency per bank:
dram[0]:        286       298       314       348       342       564       587       639       627       404       430       444       636       488       335       298
dram[1]:        252       243       287       348       366       561       611       738       852       425       456       469       502       473       387       290
dram[2]:        245       229       302       317       355       558       614       633       820       450       452       609       529       467       325       304
dram[3]:        233       214       272       307       351       575       612       585       635       378       469       598       504       469       320       301
dram[4]:        249       233       244       262       357       531       596       624       655       387       447       435       470       460       345       310

Number of Memory Banks Accessed per Memory Operation per Warp (from 0):
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	
Average # of Memory Banks Accessed per Memory Operation per Warp=-nan

position of mrq chosen
0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	

average position of mrq chosen = -nan
gpgpu_l2_write_miss = 0
gpgpu_l2_write_access = 0
gpgpu_l2_read_miss = 0
gpgpu_l2_read_access = 0
Cache L2_bank_000:
MSHR contents

DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=70823 n_nop=68637 n_act=24 n_pre=8 n_req=1077 n_rd=1438 n_write=716 bw_util=0.06083
n_activity=9533 dram_eff=0.4519
bk0: 70a 69668i bk1: 64a 69544i bk2: 64a 69724i bk3: 64a 69681i bk4: 64a 69643i bk5: 64a 69666i bk6: 64a 69628i bk7: 64a 69573i bk8: 64a 69450i bk9: 88a 69492i bk10: 128a 69523i bk11: 128a 69440i bk12: 128a 69495i bk13: 128a 69367i bk14: 128a 69346i bk15: 128a 69474i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=1.03105
Cache L2_bank_001:
MSHR contents
MSHR: tag=0x8006ed80, atomic=0 1 entries : 0x2b65db25b1e0 :  mf: uid=150173, sid05:w11, part=1, addr=0x8006ed80, load , size=128, unknown  status = IN_PARTITION_DRAM (39346), 
MSHR: tag=0x80066b80, atomic=0 1 entries : 0x2b65db100b90 :  mf: uid=150145, sid04:w39, part=1, addr=0x80066b80, load , size=128, unknown  status = IN_PARTITION_DRAM (39343), 

DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=70823 n_nop=68639 n_act=24 n_pre=8 n_req=1076 n_rd=1436 n_write=716 bw_util=0.06077
n_activity=9187 dram_eff=0.4685
bk0: 68a 69659i bk1: 64a 69514i bk2: 64a 69428i bk3: 64a 69440i bk4: 64a 69458i bk5: 64a 69487i bk6: 64a 69394i bk7: 64a 69485i bk8: 64a 69553i bk9: 88a 69541i bk10: 128a 69460i bk11: 128a 69410i bk12: 128a 69366i bk13: 128a 69332i bk14: 128a 69334i bk15: 128a 69369i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=1.11601
Cache L2_bank_002:
MSHR contents
MSHR: tag=0x8006ee80, atomic=0 1 entries : 0x2b65db2506e0 :  mf: uid=150175, sid05:w13, part=2, addr=0x8006ee80, load , size=128, unknown  status = IN_PARTITION_DRAM (39346), 

DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=70823 n_nop=68641 n_act=24 n_pre=8 n_req=1076 n_rd=1434 n_write=716 bw_util=0.06071
n_activity=9276 dram_eff=0.4636
bk0: 68a 69580i bk1: 64a 69549i bk2: 64a 69597i bk3: 64a 69609i bk4: 64a 69473i bk5: 64a 69442i bk6: 64a 69384i bk7: 64a 69408i bk8: 64a 69402i bk9: 88a 69462i bk10: 128a 69471i bk11: 128a 69428i bk12: 128a 69305i bk13: 128a 69274i bk14: 128a 69233i bk15: 126a 69335i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=1.17569
Cache L2_bank_003:
MSHR contents
MSHR: tag=0x8006ef80, atomic=0 1 entries : 0x2b65db1d0480 :  mf: uid=150174, sid05:w15, part=3, addr=0x8006ef80, load , size=128, unknown  status = IN_PARTITION_DRAM (39346), 

DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=70823 n_nop=68636 n_act=24 n_pre=8 n_req=1078 n_rd=1439 n_write=716 bw_util=0.06086
n_activity=9413 dram_eff=0.4579
bk0: 68a 69576i bk1: 64a 69627i bk2: 64a 69722i bk3: 64a 69610i bk4: 64a 69603i bk5: 64a 69569i bk6: 64a 69444i bk7: 64a 69420i bk8: 64a 69499i bk9: 92a 69521i bk10: 128a 69487i bk11: 128a 69425i bk12: 128a 69349i bk13: 128a 69238i bk14: 128a 69234i bk15: 127a 69327i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=1.02238
Cache L2_bank_004:
MSHR contents
MSHR: tag=0x8006eb80, atomic=0 1 entries : 0x2b65d8d989a0 :  mf: uid=150171, sid05:w07, part=4, addr=0x8006eb80, load , size=128, unknown  status = IN_PARTITION_L2_FILL_QUEUE (39346), 

DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=2 tCCD=6, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=70823 n_nop=68633 n_act=24 n_pre=8 n_req=1079 n_rd=1438 n_write=720 bw_util=0.06094
n_activity=9685 dram_eff=0.4456
bk0: 66a 69563i bk1: 64a 69600i bk2: 64a 69593i bk3: 64a 69593i bk4: 64a 69589i bk5: 64a 69628i bk6: 64a 69576i bk7: 64a 69588i bk8: 64a 69513i bk9: 92a 69633i bk10: 128a 69552i bk11: 128a 69466i bk12: 128a 69467i bk13: 128a 69439i bk14: 128a 69390i bk15: 128a 69395i 
dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=16 avg=0.994352
Cache L2_bank_000:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 758, Miss = 719 (0.949), PendingHit = 9 (0.0119)
Cache L2_bank_001:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 744, Miss = 718 (0.965), PendingHit = 6 (0.00806)
Cache L2_bank_002:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 744, Miss = 718 (0.965), PendingHit = 6 (0.00806)
Cache L2_bank_003:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 746, Miss = 720 (0.965), PendingHit = 6 (0.00804)
Cache L2_bank_004:	Size = 131072 B (64 Set x 16-way x 128 byte line)
		Access = 732, Miss = 719 (0.982), PendingHit = 3 (0.0041)
L2 Cache Total Miss Rate = 0.965

icnt_total_pkts_mem_to_simt=11424
icnt_total_pkts_simt_to_mem=10892

LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
Traffic 0 Stat
%=================================
% Average latency = 16.6676
% Accepted packets = 0 at node 0 (avg = 0.00601796)
lat(1) = 16.6676;
thru(1,:) = [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.02783 0.0276521 0.0276521 0.0276775 0.0276013 0 0 0 0 ];
% latency change    = 1
% throughput change = 1
Traffic 1 Stat
%=================================
% Average latency = 5.99409
% Accepted packets = 0 at node 14 (avg = 0.0063119)
lat(2) = 5.99409;
thru(2,:) = [ 0.0115895 0.0115895 0.0115895 0.0115895 0.0115895 0.0115895 0.0115895 0.0115895 0.0115895 0.00792965 0.00792965 0.0091496 0.00792965 0.00792965 0 0 0 0 0 0 0 0 0 ];
% latency change    = 1.78066
% throughput change = 0.0465686
----------------------------Interconnect-DETAILS---------------------------------=======Traffic[0]class0 ======
Traffic[0]class0Overall average latency = 16.6676 (1 samples)
Traffic[0]class0Overall average accepted rate = 0.00601796 (1 samples)
Traffic[0]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 1178 149 37 32 733 105 57 219 119 70 54 42 40 31 27 23 29 15 21 14 28 20 15 5 22 26 31 12 14 6 29 20 14 2 10 11 38 1 10 4 22 9 15 2 12 21 13 1 16 3 17 6 8 2 9 6 15 0 7 1 7 11 2 1 1 2 1 1 1 1 9 5 1 2 4 4 5 1 3 0 0 1 0 0 1 3 0 0 0 0 1 0 1 0 0 0 1 1 1 1 3 1 2 0 0 0 2 1 2 0 4 0 1 0 1 0 2 1 4 1 1 1 4 0 5 1 1 0 1 0 0 0 3 0 1 0 4 1 2 0 3 1 2 1 4 0 5 1 3 0 3 0 2 1 1 0 0 0 0 0 2 0 1 0 2 0 1 0 2 0 4 0 0 0 3 0 4 0 6 0 2 0 5 0 6 1 3 0 6 0 1 0 0 0 0 0 3 2 2 0 2 0 3 0 5 0 3 0 2 0 1 0 0 0 1 0 0 0 1 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[0]class1Average hops = 1 (3724 samples)
traffic_manager/hop_stats_freq = [ 0 3724 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
=======Traffic[1]class0 ======
Traffic[1]class0Overall average latency = 5.99409 (1 samples)
Traffic[1]class0Overall average accepted rate = 0.0063119 (1 samples)
Traffic[1]class0Overall min accepted rate = 0 (1 samples)
traffic_manager/latency_stat_0_freq = [ 0 1704 42 10 4 631 134 90 158 192 117 70 66 75 51 48 82 20 23 14 16 29 9 14 15 4 22 8 7 9 5 12 4 3 2 3 7 1 1 1 0 6 0 1 1 1 4 0 0 1 1 0 1 2 0 0 2 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
Traffic[1]class1Average hops = 1 (3724 samples)
traffic_manager/hop_stats_freq = [ 0 3724 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ];
----------------------------END-of-Interconnect-DETAILS-------------------------

gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 21 sec (21 sec)
gpgpu_simulation_rate = 385024 (inst/sec)
gpgpu_simulation_rate = 1873 (cycle/sec)
event update
GPGPU-Sim API: cudaEventSynchronize ** waiting for event
GPGPU-Sim API: cudaEventSynchronize ** event detected
Execution time: 21000.000 ms 
Bandwidth: 0.000 GB/s 
